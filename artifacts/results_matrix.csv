id,question,GT_Value,GT_Ref,GT_Explanation,answer_unit,mistral7b-bench_Value,mistral7b-bench_Ref,mistral7b-bench_ValCorrect,mistral7b-bench_RefScore,mistral7b-bench_NACorrect,mixtral-8x7b-bench_Value,mixtral-8x7b-bench_Ref,mixtral-8x7b-bench_ValCorrect,mixtral-8x7b-bench_RefScore,mixtral-8x7b-bench_NACorrect,phi3-mini-bench_Value,phi3-mini-bench_Ref,phi3-mini-bench_ValCorrect,phi3-mini-bench_RefScore,phi3-mini-bench_NACorrect,qwen1.5b-bench_Value,qwen1.5b-bench_Ref,qwen1.5b-bench_ValCorrect,qwen1.5b-bench_RefScore,qwen1.5b-bench_NACorrect,qwen14b-bench_Value,qwen14b-bench_Ref,qwen14b-bench_ValCorrect,qwen14b-bench_RefScore,qwen14b-bench_NACorrect,qwen32b-bench_Value,qwen32b-bench_Ref,qwen32b-bench_ValCorrect,qwen32b-bench_RefScore,qwen32b-bench_NACorrect,qwen3b-bench_Value,qwen3b-bench_Ref,qwen3b-bench_ValCorrect,qwen3b-bench_RefScore,qwen3b-bench_NACorrect,qwen72b-bench_Value,qwen72b-bench_Ref,qwen72b-bench_ValCorrect,qwen72b-bench_RefScore,qwen72b-bench_NACorrect,qwen7b-bench_Value,qwen7b-bench_Ref,qwen7b-bench_ValCorrect,qwen7b-bench_RefScore,qwen7b-bench_NACorrect
q003,What is the name of the benchmark suite presented in a recent paper for measuring inference energy consumption?,ML.ENERGY Benchmark,['chung2025'],Quote,is_blank,is_blank,"[""chung2025""]",False,1.0,True,is_blank,"[""is_blank""]",False,0.0,True,ML.ENERGY Benchmark,"[""chung2025""]",True,1.0,True,1,"[""chung2025""]",False,1.0,True,is_blank,"[""is_blank""]",False,0.0,True,ML.ENERGY Benchmark,"[""chung2025""]",True,1.0,True,is_blank,"[""chung2025""]",False,1.0,True,ML.ENERGY Benchmark,"[""chung2025""]",True,1.0,True,ML.ENERGY Benchmark,"[""chung2025""]",True,1.0,True
q009,What were the net CO2e emissions from training the GShard-600B model?,4.3,['patterson2021'],Quote,tCO2e,4.3,"[""patterson2021""]",True,1.0,True,4.3,"[""patterson2021""]",True,1.0,True,4.3,"[""patterson2021""]",True,1.0,True,4.3,"[""patterson2021""]",True,1.0,True,4.3,"[""patterson2021""]",True,1.0,True,4.3,"[""patterson2021""]",True,1.0,True,4.3,"[""patterson2021""]",True,1.0,True,4.3,"[""patterson2021""]",True,1.0,True,4.3,"[""patterson2021""]",True,1.0,True
q054,What is the model size in gigabytes (GB) for the LLaMA-33B model?,64.7,['chen2024'],Table 3,GB,64.7,"[""chen2024""]",True,1.0,True,0,"[""samsi2024""]",False,0.0,True,64.7,"[""chen2024"", ""samsi2024"", ""luccioni2025c"", ""han2024""]",True,0.25,True,64.7,"[""chen2024""]",True,1.0,True,64.7,"[""chen2024""]",True,1.0,True,64.7,"[""chen2024""]",True,1.0,True,64.7,"[""chen2024""]",True,1.0,True,64.7,"[""chen2024""]",True,1.0,True,64.7,"[""chen2024""]",True,1.0,True
q062,"What was the total electricity consumption of all Google Cloud TPU pods worldwide in 2023, in megawatt-hours?",is_blank,is_blank,is_blank,MWh,is_blank,"[""patterson2021""]",True,0.0,True,is_blank,"[""is_blank""]",True,1.0,True,is_blank,"[""is_blank""]",True,1.0,True,is_blank,"[""patterson2021"", ""li2025b""]",True,0.0,True,is_blank,"[""is_blank""]",True,1.0,True,is_blank,"[""is_blank""]",True,1.0,True,12.2,"[""patterson2021""]",True,0.0,False,is_blank,"[""is_blank""]",True,1.0,True,is_blank,"[""patterson2021""]",True,0.0,True
q075,True or False: Hyperscale data centers in 2020 achieved more than 40% higher efficiency compared to traditional data centers.,1,"['wu2021b','patterson2021']","The >40% statement is explicit in Wu. Patterson's PUE numbers (1.59 vs 1.11) provide a numeric example consistent with ""more than 40% higher efficiency.""",is_blank,1,"[""wu2021b""]",True,0.5,True,1,"[""wu2021b""]",True,0.5,True,1,"[""wu2021b"", ""patterson2021""]",True,1.0,True,0,"[""w2021b""]",False,0.0,True,1,"[""wu2021b""]",True,0.5,True,1,"[""wu2021b""]",True,0.5,True,1,"[""wu2021b""]",True,0.5,True,1,"[""wu2021b""]",True,0.5,True,1,"[""wu2021b""]",True,0.5,True
q078,"For every medium-length GPT-3 completion (prompt= 800 words; response 150 - 300 words), roughly how many 500 mL bottles of water does the model 'drink'?","[0.02,0.1]",['li2025b'],"The paper states that one 500ml bottle is consumed for every 10 to 50 responses. Therefore, one response consumes 1/50 to 1/10 of a bottle, which is 0.02 to 0.1 bottles.",500 mL bottles,50,"[""li2025b""]",False,1.0,True,1,"[""li2025b""]",False,1.0,True,,[],False,0.0,True,1,"[""li2025b""]",False,1.0,True,1,"[""li2025b""]",False,1.0,True,is_blank,"[""li2025b""]",False,1.0,True,500,"[""li2025b""]",False,1.0,True,10 - 50,"[""li2025b""]",False,1.0,True,500,"[""li2025b""]",False,1.0,True
q091,"From a sample of 60 papers from top AI conferences, what is the difference between the percentage of CVPR papers that target accuracy and the percentage of CVPR papers that target efficiency?",55,['schwartz2019'],Requires calculation (75-20),percent,is_blank,"[""schwartz2019""]",False,1.0,True,is_blank,"[""schwartz2019""]",False,1.0,True,75,"[""schwartz2019"", ""schwartz2019"", ""schwartz2019"", ""schwartz2019"", ""schwartz2019"", ""schwartz2019"", ""schwartz2019"", ""schwartz2019"", ""schwartz2019""]",False,1.0,True,22,"[""schwartz2019""]",False,1.0,True,55,"[""schwartz2019""]",True,1.0,True,55,"[""schwartz2019""]",True,1.0,True,75,"[""schwartz2019""]",False,1.0,True,55,"[""schwartz2019""]",True,1.0,True,55,"[""schwartz2019""]",True,1.0,True
q102,"True or False: The AI Act makes energy consumption data from providers publicly available to NGOs, analysts, and the general public.",0,['ebert2024'],Quote,is_blank,is_blank,"[""ebert2024""]",False,1.0,True,0,"[""ebert2024""]",True,1.0,True,1,"[""ebert2024""]",False,1.0,True,0,"[""ebert2024""]",True,1.0,True,is_blank,"[""is_blank""]",False,0.0,True,0,"[""ebert2024""]",True,1.0,True,0,"[""ebert2024""]",True,1.0,True,0,"[""ebert2024""]",True,1.0,True,0,"[""ebert2024""]",True,1.0,True
q105,What is the projected maximum batch size (in samples) for fine-tuning a Mixtral model with a projected GPU capacity of 100?,28,['xia2024'],Figure,samples,28,"[""xia2024""]",True,1.0,True,28,"[""xia2024""]",True,1.0,True,"28, 35","[""xia2024""]",False,1.0,True,28,"[""xia2024""]",True,1.0,True,28,"[""xia2024""]",True,1.0,True,28,"[""xia2024""]",True,1.0,True,28,"[""xia2024""]",True,1.0,True,28,"[""xia2024""]",True,1.0,True,28,"[""[ref_id=xia2024]""]",True,0.0,True
q106,What was the approximate speedup in inference throughput for LLaMA-7B when using NVIDIA A100 GPUs compared to V100 GPUs?,2,['samsi2024'],Quote,multiplier,is_blank,"[""samsi2024""]",False,1.0,True,is_blank,"[""is_blank""]",False,0.0,True,1.25 to 2,"[""samsi2024""]",False,1.0,True,is_blank,"[""samsi2024""]",False,1.0,True,2,"[""samsi2024""]",True,1.0,True,2,"[""samsi2024""]",True,1.0,True,2 to 1.25,"[""samsi2024""]",False,1.0,True,2,"[""samsi2024""]",True,1.0,True,2,"[""samsi2024""]",True,1.0,True
q124,"What is the estimated total operational water consumption for training GPT-3 in Microsoft's U.S. data centers, in million liters?",5439000,['li2025b'],Table,liters,is_blank,"[""li2025b""]",False,1.0,True,is_blank,"[""is_blank""]",False,0.0,True,2200,"[""li2025b""]",False,1.0,True,1,"[""li2025b""]",False,1.0,True,3.142,"[""li2025b""]",False,1.0,True,16.904,"[""li2025b""]",False,1.0,True,29.6,"[""li2025b""]",False,1.0,True,5.439,"[""li2025b""]",False,1.0,True,4.731,"[""li2025b""]",False,1.0,True
q135,True or False: The authors propose that sustainability impact assessments (SIAs) should apply not just to high-risk AI but across all AI systems.,1,['ebert2024'],Quote,is_blank,1,"[""ebert2024""]",True,1.0,True,is_blank,"[""luccioni2025b""]",False,0.0,True,,[],False,0.0,True,1,"[""ebert2024"", ""luccioni2025b""]",True,0.5,True,1,"[""ebert2024""]",True,1.0,True,1,"[""ebert2024""]",True,1.0,True,1,"[""ebert2024""]",True,1.0,True,1,"[""ebert2024""]",True,1.0,True,1,"[""ebert2024""]",True,1.0,True
q139,"As of 2023, what was the water use effectiveness (WUE) for AWS data centers, in L/kWh?",0.18,['amazon2023'],Quote,L/kWh,0.18,"[""amazon2023""]",True,1.0,True,0.18,"[""amazon2023""]",True,1.0,True,0.18,"[""amazon2023"", ""ebert2024"", ""li2025b""]",True,0.3333333333333333,True,1,"[""amazon2023""]",False,1.0,True,0.18,"[""amazon2023""]",True,1.0,True,0.18,"[""amazon2023""]",True,1.0,True,0.18,"[""amazon2023""]",True,1.0,True,0.18,"[""amazon2023""]",True,1.0,True,0.18,"[""amazon2023""]",True,1.0,True
q146,True or False: Local inference was emphasized as a sustainability measure because it reduces both network overhead and carbon footprint when deploying large language models.,1,['khan2025'],Quote,is_blank,1,"[""khan2025""]",True,1.0,True,1,"[""khan2025""]",True,1.0,True,1,"[""khan2025""]",True,1.0,True,1,"[""khan2025""]",True,1.0,True,is_blank,"[""is_blank""]",False,0.0,True,1,"[""khan2025""]",True,1.0,True,1,"[""khan2025""]",True,1.0,True,1,"[""khan2025""]",True,1.0,True,1,"[""khan2025""]",True,1.0,True
q153,True or False: Tracking the runtime of a training job is an important step for estimating compute cost in GPU-based or cloud environments.,1,['strubell2019'],Quote,is_blank,is_blank,"[""luccioni2023""]",False,0.0,True,is_blank,"[""is_blank""]",False,0.0,True,1,"[""luccioni2023"", ""strubell2019"", ""erben2023"", ""cottier2024"", ""kim2025""]",True,0.2,True,1,"[""luccioni2023"", ""strubell2019""]",True,0.5,True,is_blank,"[""is_blank""]",False,0.0,True,1,"[""strubell2019"", ""cottier2024""]",True,0.5,True,1,"[""luccioni2023""]",True,0.0,True,1,"[""luccioni2023""]",True,0.0,True,,[],False,0.0,True
q158,"For the LLaMA-65B model, what was the maximum performance improvement (latency reduction) achieved by enabling the automated resource utilization overlapping feature in the 2025 Chen et al. study?",13.2,['chen2024'],Quote,percent,13.2,"[""chen2024""]",True,1.0,True,is_blank,"[""chen2024""]",False,1.0,True,13.2,"[""chen2024""]",True,1.0,True,1,"[""chen2024""]",False,1.0,True,13.2,"[""chen2024""]",True,1.0,True,13.2,"[""chen2024""]",True,1.0,True,13.2,"[""chen2024""]",True,1.0,True,13.2,"[""chen2024""]",True,1.0,True,13.2,"[""chen2024""]",True,1.0,True
q164,How much does an elephant weigh?,is_blank,is_blank,is_blank,lbs,is_blank,"[""morrison2025""]",True,0.0,True,is_blank,"[""is_blank""]",True,1.0,True,is_blank,"[""morrison2025, amazon2023, amazon2023, morrison2025, wu2021a""]",True,0.0,True,13000,"[""morrison2025""]",True,0.0,False,is_blank,"[""is_blank""]",True,1.0,True,is_blank,"[""is_blank""]",True,1.0,True,is_blank,"[""wu2021a""]",True,0.0,True,is_blank,"[""is_blank""]",True,1.0,True,is_blank,"[""is_blank""]",True,1.0,True
q166,"Which of the following five large NLP DNNs has the highest energy consumption: Meena, T5, GPT-3, GShard-600B, or Switch Transformer?",GPT-3,['patterson2021'],Figure,is_blank,is_blank,"[""patterson2021""]",False,1.0,True,,[],False,0.0,True,is_blank,"[""patterson2021,jegham2025,zschache2025""]",False,0.0,True,1,"[""patterson2021"", ""zschache2025""]",False,0.5,True,is_blank,"[""is_blank""]",False,0.0,True,is_blank,"[""is_blank""]",False,0.0,True,GPT-3,"[""patterson2021""]",True,1.0,True,GPT-3,"[""patterson2021""]",True,1.0,True,1,"[""patterson2021""]",False,1.0,True
q170,How many days of CO₂ emissions from an average American life are equivalent to training BERT base?,14.4,['strubell2019'],1438 lbs / 99.8 lbs/day = 14.4 ,days,is_blank,"[""strubell2019""]",False,1.0,True,is_blank,"[""luccioni2025b"", ""strubell2019""]",False,0.5,True,4,"[""luccioni2025b"", ""strubell2019""]",False,0.5,True,103593,"[""strubell2019""]",False,1.0,True,,[],False,0.0,True,is_blank,"[""is_blank""]",False,0.0,True,4,"[""luccioni2025b"", ""strubell2019""]",False,0.5,True,is_blank,"[""luccioni2025b"", ""strubell2019""]",False,0.5,True,626155,"[""strubell2019""]",False,1.0,True
q200,True or False: The Transformer architecture eventuallly outperforms the Evolved Transformers architecture on the WMT'24 EN-DE BLUE task as the model sizes grow.,0,['patterson2021'],Figure,is_blank,is_blank,"[""patterson2021""]",False,1.0,True,is_blank,"[""is_blank""]",False,0.0,True,,[],False,0.0,True,1,"[""patterson2021""]",False,1.0,True,is_blank,"[""is_blank""]",False,0.0,True,is_blank,"[""is_blank""]",False,0.0,True,is_blank,"[""patterson2021""]",False,1.0,True,is_blank,"[""is_blank""]",False,0.0,True,is_blank,"[""patterson2021"", ""strubell2019""]",False,0.5,True
q202,"What dataset of 5,842 labeled entries was used to test energy-efficient large language models in the financial domain?",Financial Sentiment Analysis,['khan2025'],Quote,is_blank,is_blank,"[""fernandez2025""]",False,0.0,True,is_blank,"[""is_blank""]",False,0.0,True,4,"[""fernandez2025"", ""zschache2025""]",False,0.0,True,1,"[""fernandez2025""]",False,0.0,True,is_blank,"[""is_blank""]",False,0.0,True,is_blank,"[""is_blank""]",False,0.0,True,BurstGPT,"[""fernandez2025""]",False,0.0,True,is_blank,"[""is_blank""]",False,0.0,True,is_blank,"[""is_blank""]",False,0.0,True
q203,True or False: Eight T4 spot instances could be more cost-efficient than a DGX-2 node for distributed training.,1,['erben2023'],Quote,is_blank,1,"[""erben2023""]",True,1.0,True,,[],False,0.0,True,1,"[""erben2023""]",True,1.0,True,1,"[""erben2023""]",True,1.0,True,1,"[""erben2023""]",True,1.0,True,1,"[""erben2023""]",True,1.0,True,1,"[""erben2023""]",True,1.0,True,1,"[""erben2023""]",True,1.0,True,1,"[""erben2023""]",True,1.0,True
q207,True or False: The 2023 US Executive Order regarding AI mentioned the greenhouse gas emissions or energy usage of AI.,0,luccioni2025b,Quote,is_blank,1,"[""luccioni2025b""]",False,1.0,True,0,"[""luccioni2025b""]",True,1.0,True,is_blank,"[""luccioni2025b"", ""ebert2024"", ""dodge2022"", ""luccioni2025a""]",False,0.25,True,0,"[""luccioni2025b""]",True,1.0,True,0,"[""luccioni2025b""]",True,1.0,True,0,"[""luccioni2025b""]",True,1.0,True,0,"[""luccioni2025b""]",True,1.0,True,0,"[""luccioni2025b""]",True,1.0,True,0,"[""luccioni2025b""]",True,1.0,True
q211,"True or False: Under Germany's 2023 Energy Efficiency Act, data centers must run on 100% renewable energy by January 1, 2027.",1,['ebert2024'],Quote,is_blank,1,"[""ebert2024""]",True,1.0,True,100,"[""ebert2024""]",False,1.0,True,100%,"[""ebert2024"", ""ebert2024""]",False,1.0,True,0,"[""ebert2024""]",False,1.0,True,0,"[""ebert2024""]",False,1.0,True,1,"[""ebert2024""]",True,1.0,True,2027,"[""ebert2024""]",False,1.0,True,1,"[""ebert2024""]",True,1.0,True,0,"[""ebert2024""]",False,1.0,True
q215,"Out of a sample of 60 papers from top AI conferences, how many papers from ACL targeted both accuracy and efficiency?",2,['schwartz2019'],Figure,papers,is_blank,"[""schwartz2019""]",False,1.0,True,is_blank,"[""schwartz2019""]",False,1.0,True,10,"[""schwartz2019"", ""schwartz2019"", ""schwartz2019"", ""schwartz2019"", ""schwartz2019"", ""schwartz2019"", ""schwartz2019"", ""schwartz2019"", ""schwartz2019""]",False,1.0,True,1,"[""schwartz2019""]",False,1.0,True,6,"[""schwartz2019""]",False,1.0,True,is_blank,"[""is_blank""]",False,0.0,True,9,"[""schwartz2019""]",False,1.0,True,is_blank,"[""schwartz2019""]",False,1.0,True,6,"[""schwartz2019""]",False,1.0,True
q221,"According to recent estimates, what percentage of a model's total lifecycle energy use can inference account for?",90,['jegham2025'],Quote,percent,90,"[""jegham2025""]",True,1.0,True,90,"[""jegham2025""]",True,1.0,True,1,"[""jegham2025""]",False,1.0,True,1,"[""jegham2025""]",False,1.0,True,90,"[""jegham2025""]",True,1.0,True,90,"[""jegham2025""]",True,1.0,True,90,"[""jegham2025""]",True,1.0,True,90,"[""jegham2025""]",True,1.0,True,90,"[""jegham2025""]",True,1.0,True
q230,True or False: The AI Act requires providers to report both training and inference energy consumption for general-purpose AI models.,0,['ebert2024'],Quote,is_blank,is_blank,"[""ebert2024""]",False,1.0,True,is_blank,"[""is_blank""]",False,0.0,True,1,"[""ebert2024""]",False,1.0,True,0,"[""ebert2024""]",True,1.0,True,is_blank,"[""is_blank""]",False,0.0,True,0,"[""ebert2024""]",True,1.0,True,0,"[""ebert2024""]",True,1.0,True,0,"[""ebert2024""]",True,1.0,True,is_blank,"[""ebert2024""]",False,1.0,True
q231,True or False: The AI Act currently requires providers to report energy use during the inference phase of AI models.,0,['ebert2024'],Quote,is_blank,0,"[""ebert2024""]",True,1.0,True,0,"[""ebert2024""]",True,1.0,True,0,"[""ebert2024""]",True,1.0,True,0,"[""ebert2024""]",True,1.0,True,0,"[""ebert2024""]",True,1.0,True,0,"[""ebert2024""]",True,1.0,True,0,"[""ebert2024""]",True,1.0,True,0,"[""ebert2024""]",True,1.0,True,0,"[""ebert2024""]",True,1.0,True
q246,True or False: New AI data centers often rely on air cooling due to high server power densities.,0,['li2025b'],Quote,is_blank,1,"[""li2025b""]",False,1.0,True,is_blank,"[""is_blank""]",False,0.0,True,Liquid cooling,"[""li2025b""]",False,1.0,True,0,"[""li2025b""]",True,1.0,True,0,"[""li2025b""]",True,1.0,True,0,"[""li2025b""]",True,1.0,True,0,"[""li2025b""]",True,1.0,True,0,"[""li2025b""]",True,1.0,True,,[],False,0.0,True
q253,By what factor did platform-level caching improve the power efficiency of the inference workload for the cross-lingual Transformer language model described in Wu et al. (2021)?,6.7,['wu2021a'],Quote,multiplier,is_blank,"[""wu2021a""]",False,1.0,True,is_blank,"[""is_blank""]",False,0.0,True,,[],False,0.0,True,800,"[""w2021a""]",False,0.0,True,6.7,"[""wu2021a""]",True,1.0,True,6.7,"[""wu2021a""]",True,1.0,True,800,"[""wu2021a""]",False,1.0,True,6.7,"[""wu2021a""]",True,1.0,True,6.7,"[""[ref_id=wu2021a]""]",True,0.0,True
q262,What is the estimated CO2 emissions in pounds from training a BERT base model for 79 hours using  64 V100 GPUs?,1438,['strubell2019'],Table,lbs,is_blank,"[""strubell2019"", ""luccioni2025b""]",False,0.5,True,is_blank,"[""strubell2019, jegham2025""]",False,0.0,True,,[],False,0.0,True,1438,"[""jegham2025"", ""strubell2019""]",True,0.5,True,1438,"[""strubell2019""]",True,1.0,True,1438,"[""strubell2019""]",True,1.0,True,1438,"[""jegham2025""]",True,0.0,True,1438,"[""strubell2019""]",True,1.0,True,1438,"[""strubell2019""]",True,1.0,True
q263,"According to a recent paper, what percentage of total compute demand does ML inference reportedly account for?","[80,90]",['chung2025'],Quote,percent,80-90,"[""chung2025"", ""patterson2021"", ""luccioni2024""]",False,0.3333333333333333,True,80-90,"[""chung2025""]",False,1.0,True,80-90,"[""chung2025"", ""patterson2021"", ""luccioni2024"", ""fernandez2025"", ""luccioni2023""]",False,0.2,True,80,"[""chung2025"", ""patterson2021""]",True,0.5,True,80–90,"[""chung2025""]",False,1.0,True,80–90,"[""chung2025""]",False,1.0,True,80-90,"[""chung2025""]",False,1.0,True,80-90,"[""chung2025"", ""patterson2021"", ""luccioni2024"", ""fernandez2025""]",False,0.25,True,80-90,"[""chung2025"", ""patterson2021"", ""luccioni2024""]",False,0.3333333333333333,True
q272,How many U.S. household-years of electricity consumption is training a 6.1B-parameter language model equivalent to?,1.3,"['dodge2022','strubell2019']",13.8 MWh ÷ 10.7 MWh/yr ≈ 1.3 household-years.,household-years,1.26,"[""dodge2022""]",False,0.5,True,is_blank,"[""dodge2022""]",False,0.5,True,"103,500","[""dodge2022""]",False,0.5,True,103500,"[""dodge2022""]",False,0.5,True,273,"[""dodge2022""]",False,0.5,True,is_blank,"[""is_blank""]",False,0.0,True,103500,"[""dodge2022""]",False,0.5,True,is_blank,"[""dodge2022""]",False,0.5,True,13.8,"[""dodge2022""]",False,0.5,True
q278,True or False: Egress costs in geo-distributed NLP experiments could account for more than 90% of the total cost per VM.,1,['erben2023'],"Figure, Quote",is_blank,1,"[""erben2023""]",True,1.0,True,1,"[""erben2023""]",True,1.0,True,,[],False,0.0,True,1,"[""erben2023""]",True,1.0,True,1,"[""erben2023""]",True,1.0,True,1,"[""erben2023""]",True,1.0,True,1,"[""erben2023""]",True,1.0,True,1,"[""erben2023""]",True,1.0,True,1,"[""erben2023""]",True,1.0,True
q280,"Given the total pre-training GPU hours and the number of GPUs used, estimate the total wall-clock time in days required to pre-train the JetMoE-8B model.",13,['shen2024'],"Math: wall_clock_hours ≈ 30,000 GPUh ÷ 96 GPUs = 312.5 h; days ≈ 312.5 ÷ 24 ≈ 13.0 days (pretraining; alignment 60 GPUh is separate).",days,is_blank,"[""shen2024""]",False,1.0,True,is_blank,"[""is_blank""]",False,0.0,True,is_blank,"[""shen2024""]",False,1.0,True,1,"[""shen2024""]",False,1.0,True,is_blank,"[""is_blank""]",False,0.0,True,is_blank,"[""is_blank""]",False,0.0,True,30,"[""shen2024""]",False,1.0,True,31.25,"[""shen2024""]",False,1.0,True,is_blank,"[""is_blank""]",False,0.0,True
q282,"What is the term for the amount of water evaporated, transpired, or incorporated into products, and is defined as 'water withdrawal minus water discharge'?",Water consumption,['li2025b'],Quote,is_blank,is_blank,"[""li2025b""]",False,1.0,True,Water consumption,"[""li2025b""]",True,1.0,True,1,"[""li2025b""]",False,1.0,True,1,"[""li2025b""]",False,1.0,True,Water consumption,"[""li2025b""]",True,1.0,True,Water consumption,"[""li2025b""]",True,1.0,True,Water consumption,"[""li2025b""]",True,1.0,True,Water consumption,"[""li2025b""]",True,1.0,True,Water consumption,"[""li2025b""]",True,1.0,True
q296,What was the observed range of inference energy per second for LLaMA-65B across GPU shard configurations?,"[300,1000]",['samsi2024'],Quote,W,300-1000,"[""samsi2024""]",False,1.0,True,1,"[""samsi2024""]",False,1.0,True,300-10000,"[""samsi2024""]",False,1.0,True,1,"[""samsi2024""]",False,1.0,True,300 Watts to 1 Kilowatt,"[""samsi2024""]",False,1.0,True,300 Watts to 1 Kilowatt,"[""samsi2024""]",False,1.0,True,300,"[""samsi2024""]",True,1.0,True,300 to 1000,"[""samsi2024""]",False,1.0,True,300-1000,"[""samsi2024""]",False,1.0,True
q297,"When comparing small and large versions of Qwen models in zero-shot classification, how many times more energy did the 72B version consume than the 7B version?",8.720430108,['zschache2025'], 48.66/5.58 ,multiplier,7,"[""zschache2025""]",False,1.0,True,is_blank,"[""zschache2025""]",False,1.0,True,7,"[""zschache2025"", ""chung2025"", ""jegham2025"", ""luccioni2024""]",False,0.25,True,7,"[""zschache2025""]",False,1.0,True,7,"[""zschache2025""]",False,1.0,True,7,"[""zschache2025""]",False,1.0,True,7,"[""zschache2025""]",False,1.0,True,7,"[""zschache2025""]",False,1.0,True,7,"[""zschache2025""]",False,1.0,True
q304,By what percentage did Qwen's carbon emissions fall when applying quantization and local inference for sentiment classification?,55.6,['khan2025'],0.009→0.004=55.6%,percent,0.004,"[""khan2025""]",False,1.0,True,0.005,"[""khan2025""]",False,1.0,True,,[],False,0.0,True,1,"[""khan2025""]",False,1.0,True,55.56,"[""khan2025""]",True,1.0,True,55.56,"[""khan2025""]",True,1.0,True,,[],False,0.0,True,55.56,"[""khan2025""]",True,1.0,True,55.56,"[""khan2025""]",True,1.0,True
q306,How many widely used model architectures across different tasks were included in the latest iteration of the ML.ENERGY Benchmark?,40,['chung2025'],Quote,models,is_blank,"[""chung2025""]",False,1.0,True,is_blank,"[""is_blank""]",False,0.0,True,,[],False,0.0,True,1,"[""chung2025""]",False,1.0,True,is_blank,"[""is_blank""]",False,0.0,True,is_blank,"[""is_blank""]",False,0.0,True,4,"[""chung2025""]",False,1.0,True,is_blank,"[""chung2025""]",False,1.0,True,is_blank,"[""chung2025""]",False,1.0,True
q316,"In the analysis of training a Llama-3.1 scale model, what was the estimated health cost, In USD, when training in Altoona, Iowa?",2510000,['han2024'],Table,USD,is_blank,"[""han2024""]",False,1.0,True,is_blank,"[""han2024""]",False,1.0,True,,[],False,0.0,True,20,"[""han2024""]",False,1.0,True,2.51,"[""han2024""]",False,1.0,True,2510000,"[""han2024""]",True,1.0,True,is_blank,"[""han2024""]",False,1.0,True,2510000,"[""han2024""]",True,1.0,True,2500000,"[""han2024""]",False,1.0,True
