id,question,GT_Value,GT_Ref,GT_Explanation,answer_unit,claude35-haiku-bench_Value,claude35-haiku-bench_Ref,claude35-haiku-bench_ValCorrect,claude35-haiku-bench_RefScore,claude35-haiku-bench_NACorrect,claude37-sonnet-bench_Value,claude37-sonnet-bench_Ref,claude37-sonnet-bench_ValCorrect,claude37-sonnet-bench_RefScore,claude37-sonnet-bench_NACorrect,deepseek-r1-bench_Value,deepseek-r1-bench_Ref,deepseek-r1-bench_ValCorrect,deepseek-r1-bench_RefScore,deepseek-r1-bench_NACorrect,haiku-bench_Value,haiku-bench_Ref,haiku-bench_ValCorrect,haiku-bench_RefScore,haiku-bench_NACorrect,llama3-70b-bench_Value,llama3-70b-bench_Ref,llama3-70b-bench_ValCorrect,llama3-70b-bench_RefScore,llama3-70b-bench_NACorrect,llama4-maverick-bench_Value,llama4-maverick-bench_Ref,llama4-maverick-bench_ValCorrect,llama4-maverick-bench_RefScore,llama4-maverick-bench_NACorrect,llama4-scout-bench_Value,llama4-scout-bench_Ref,llama4-scout-bench_ValCorrect,llama4-scout-bench_RefScore,llama4-scout-bench_NACorrect,nova-pro-bench_Value,nova-pro-bench_Ref,nova-pro-bench_ValCorrect,nova-pro-bench_RefScore,nova-pro-bench_NACorrect,sonnet-bench_Value,sonnet-bench_Ref,sonnet-bench_ValCorrect,sonnet-bench_RefScore,sonnet-bench_NACorrect
q003,What is the name of the benchmark suite presented in a recent paper for measuring inference energy consumption?,ML.ENERGY Benchmark,['chung2025'],Quote,is_blank,ML.ENERGY Benchmark,"[""chung2025""]",True,1.0,True,ML.ENERGY Benchmark,"[""chung2025""]",True,1.0,True,ML.ENERGY Benchmark,"[""chung2025""]",True,1.0,True,The ML.ENERGY Benchmark,"[""chung2025""]",False,1.0,True,ML.ENERGY Benchmark,"[""chung2025""]",True,1.0,True,ML.ENERGY Benchmark,"[""chung2025""]",True,1.0,True,ML.ENERGY Benchmark,"[""chung2025""]",True,1.0,True,,[],False,0.0,True,ML.ENERGY Benchmark,"[""chung2025""]",True,1.0,True
q009,What were the net CO2e emissions from training the GShard-600B model?,4.3,['patterson2021'],Quote,tCO2e,0.55,"[""wu2021a""]",False,0.0,True,450,"[""wu2021a""]",False,0.0,True,500,"[""wu2021a""]",False,0.0,True,0.5,"[""wu2021a""]",False,0.0,True,is_blank,"[""is_blank""]",False,0.0,True,0.55,"[""wu2021a""]",False,0.0,True,is_blank,"[""is_blank""]",False,0.0,True,is_blank,"[""is_blank""]",False,0.0,True,400000,"[""wu2021a""]",False,0.0,True
q054,What is the model size in gigabytes (GB) for the LLaMA-33B model?,64.7,['chen2024'],Table 3,GB,64.7,"[""chen2024""]",True,1.0,True,64.7,"[""chen2024""]",True,1.0,True,64.7,"[""chen2024""]",True,1.0,True,64.7,"[""chen2024""]",True,1.0,True,64.7,"[""[ref_id=chen2024]""]",True,0.0,True,64.7,"[""chen2024""]",True,1.0,True,64.7,"[""chen2024""]",True,1.0,True,64.7,"[""chen2024""]",True,1.0,True,64.7,"[""chen2024""]",True,1.0,True
q062,"What was the total electricity consumption of all Google Cloud TPU pods worldwide in 2023, in megawatt-hours?",is_blank,is_blank,is_blank,MWh,is_blank,"[""is_blank""]",True,1.0,True,is_blank,"[""is_blank""]",True,1.0,True,is_blank,"[""is_blank""]",True,1.0,True,is_blank,"[""is_blank""]",True,1.0,True,is_blank,"[""is_blank""]",True,1.0,True,is_blank,"[""is_blank""]",True,1.0,True,is_blank,"[""is_blank""]",True,1.0,True,is_blank,"[""is_blank""]",True,1.0,True,is_blank,"[""is_blank""]",True,1.0,True
q075,True or False: Hyperscale data centers in 2020 achieved more than 40% higher efficiency compared to traditional data centers.,1,"['wu2021b','patterson2021']","The >40% statement is explicit in Wu. Patterson's PUE numbers (1.59 vs 1.11) provide a numeric example consistent with ""more than 40% higher efficiency.""",is_blank,1,"[""wu2021b""]",True,0.5,True,1,"[""wu2021b""]",True,0.5,True,1,"[""wu2021b""]",True,0.5,True,1,"[""wu2021b""]",True,0.5,True,1,"[""wu2021b""]",True,0.5,True,1,"[""wu2021b""]",True,0.5,True,1,"[""wu2021b""]",True,0.5,True,1,"[""wu2021b""]",True,0.5,True,1,"[""wu2021b""]",True,0.5,True
q078,"For every medium-length GPT-3 completion (prompt= 800 words; response 150 - 300 words), roughly how many 500 mL bottles of water does the model 'drink'?","[0.02,0.1]",['li2025b'],"The paper states that one 500ml bottle is consumed for every 10 to 50 responses. Therefore, one response consumes 1/50 to 1/10 of a bottle, which is 0.02 to 0.1 bottles.",500 mL bottles,1,"[""li2025b"", ""luccioni2025a""]",False,0.5,True,1/10 to 1/50,"[""li2025b""]",False,1.0,True,10–50,"[""li2025b""]",False,1.0,True,10 - 50,"[""li2025b""]",False,1.0,True,is_blank,"[""is_blank""]",False,0.0,True,30,"[""li2025b""]",False,1.0,True,is_blank,"[""li2025b""]",False,1.0,True,10 to 50,"[""li2025b""]",False,1.0,True,0.02-0.1,"[""li2025b""]",False,1.0,True
q091,"From a sample of 60 papers from top AI conferences, what is the difference between the percentage of CVPR papers that target accuracy and the percentage of CVPR papers that target efficiency?",55,['schwartz2019'],Requires calculation (75-20),percent,55,"[""schwartz2019""]",True,1.0,True,55,"[""schwartz2019""]",True,1.0,True,55,"[""schwartz2019""]",True,1.0,True,55,"[""schwartz2019""]",True,1.0,True,55,"[""schwartz2019""]",True,1.0,True,55,"[""schwartz2019""]",True,1.0,True,55,"[""schwartz2019""]",True,1.0,True,55,"[""schwartz2019"", ""schwartz2019""]",True,1.0,True,55,"[""schwartz2019""]",True,1.0,True
q102,"True or False: The AI Act makes energy consumption data from providers publicly available to NGOs, analysts, and the general public.",0,['ebert2024'],Quote,is_blank,0,"[""ebert2024""]",True,1.0,True,0,"[""ebert2024""]",True,1.0,True,0,"[""ebert2024"", ""ebert2024"", ""ebert2024""]",True,1.0,True,is_blank,"[""ebert2024""]",False,1.0,True,0,"[""ebert2024""]",True,1.0,True,0,"[""ebert2024""]",True,1.0,True,0,"[""ebert2024""]",True,1.0,True,,[],False,0.0,True,0,"[""ebert2024""]",True,1.0,True
q105,What is the projected maximum batch size (in samples) for fine-tuning a Mixtral model with a projected GPU capacity of 100?,28,['xia2024'],Figure,samples,28,"[""xia2024""]",True,1.0,True,28,"[""xia2024""]",True,1.0,True,28,"[""xia2024""]",True,1.0,True,28 and 35,"[""xia2024""]",False,1.0,True,28,"[""xia2024""]",True,1.0,True,28,"[""xia2024""]",True,1.0,True,28,"[""xia2024""]",True,1.0,True,28,"[""xia2024"", ""xia2024"", ""xia2024"", ""xia2024""]",True,1.0,True,28,"[""xia2024""]",True,1.0,True
q106,What was the approximate speedup in inference throughput for LLaMA-7B when using NVIDIA A100 GPUs compared to V100 GPUs?,2,['samsi2024'],Quote,multiplier,2,"[""samsi2024""]",True,1.0,True,2,"[""samsi2024""]",True,1.0,True,2,"[""samsi2024""]",True,1.0,True,1,"[""samsi2024""]",False,1.0,True,2,"[""samsi2024""]",True,1.0,True,2,"[""samsi2024""]",True,1.0,True,2,"[""samsi2024""]",True,1.0,True,2,"[""samsi2024"", ""samsi2024""]",True,1.0,True,2,"[""samsi2024""]",True,1.0,True
q124,"What is the estimated total operational water consumption for training GPT-3 in Microsoft's U.S. data centers, in million liters?",5439000,['li2025b'],Table,liters,5.439,"[""li2025b""]",False,1.0,True,5.439,"[""li2025b""]",False,1.0,True,4.731,"[""li2025b""]",False,1.0,True,5.439,"[""li2025b""]",False,1.0,True,4.731,"[""li2025b""]",False,1.0,True,16.904,"[""li2025b""]",False,1.0,True,5.439,"[""li2025b""]",False,1.0,True,16.904,"[""li2025b""]",False,1.0,True,5.439,"[""li2025b""]",False,1.0,True
q135,True or False: The authors propose that sustainability impact assessments (SIAs) should apply not just to high-risk AI but across all AI systems.,1,['ebert2024'],Quote,is_blank,1,"[""ebert2024""]",True,1.0,True,1,"[""ebert2024""]",True,1.0,True,1,"[""ebert2024""]",True,1.0,True,1,"[""ebert2024""]",True,1.0,True,1,"[""ebert2024""]",True,1.0,True,1,"[""ebert2024""]",True,1.0,True,1,"[""ebert2024""]",True,1.0,True,1,"[""ebert2024""]",True,1.0,True,1,"[""ebert2024""]",True,1.0,True
q139,"As of 2023, what was the water use effectiveness (WUE) for AWS data centers, in L/kWh?",0.18,['amazon2023'],Quote,L/kWh,0.18,"[""amazon2023""]",True,1.0,True,0.18,"[""amazon2023""]",True,1.0,True,0.18,"[""amazon2023""]",True,1.0,True,0.18,"[""amazon2023""]",True,1.0,True,0.18,"[""[ref_id=amazon2023]""]",True,0.0,True,0.18,"[""amazon2023""]",True,1.0,True,0.18,"[""amazon2023""]",True,1.0,True,0.18,"[""amazon2023""]",True,1.0,True,0.18,"[""amazon2023""]",True,1.0,True
q146,True or False: Local inference was emphasized as a sustainability measure because it reduces both network overhead and carbon footprint when deploying large language models.,1,['khan2025'],Quote,is_blank,1,"[""khan2025""]",True,1.0,True,1,"[""khan2025""]",True,1.0,True,1,"[""khan2025""]",True,1.0,True,1,"[""khan2025""]",True,1.0,True,1,"[""khan2025""]",True,1.0,True,1,"[""khan2025""]",True,1.0,True,1,"[""khan2025""]",True,1.0,True,1,"[""khan2025""]",True,1.0,True,1,"[""khan2025""]",True,1.0,True
q153,True or False: Tracking the runtime of a training job is an important step for estimating compute cost in GPU-based or cloud environments.,1,['strubell2019'],Quote,is_blank,1,"[""strubell2019"", ""luccioni2023""]",True,0.5,True,1,"[""strubell2019"", ""kim2025""]",True,0.5,True,1,"[""luccioni2023"", ""strubell2019""]",True,0.5,True,1,"[""luccioni2023""]",True,0.0,True,1,"[""strubell2019"", ""luccioni2023""]",True,0.5,True,1,"[""luccioni2023"", ""strubell2019""]",True,0.5,True,1,"[""luccioni2023"", ""strubell2019""]",True,0.5,True,1,"[""strubell2019""]",True,1.0,True,1,"[""strubell2019"", ""luccioni2023""]",True,0.5,True
q158,"For the LLaMA-65B model, what was the maximum performance improvement (latency reduction) achieved by enabling the automated resource utilization overlapping feature in the 2025 Chen et al. study?",13.2,['chen2024'],Quote,percent,13.2,"[""chen2024""]",True,1.0,True,13.2,"[""chen2024""]",True,1.0,True,13.2,"[""chen2024""]",True,1.0,True,13.2,"[""chen2024""]",True,1.0,True,13.2,"[""chen2024""]",True,1.0,True,13.2,"[""chen2024""]",True,1.0,True,,[],False,0.0,True,,[],False,0.0,True,13.2,"[""chen2024""]",True,1.0,True
q164,How much does an elephant weigh?,is_blank,is_blank,is_blank,lbs,is_blank,"[""amazon2023""]",True,0.0,True,is_blank,"[""is_blank""]",True,1.0,True,is_blank,"[""is_blank""]",True,1.0,True,is_blank,"[""is_blank""]",True,1.0,True,is_blank,"[""is_blank""]",True,1.0,True,is_blank,"[""is_blank""]",True,1.0,True,is_blank,"[""is_blank""]",True,1.0,True,is_blank,"[""is_blank""]",True,1.0,True,is_blank,"[""amazon2023""]",True,0.0,True
q166,"Which of the following five large NLP DNNs has the highest energy consumption: Meena, T5, GPT-3, GShard-600B, or Switch Transformer?",GPT-3,['patterson2021'],Figure,is_blank,DeepSeek-R1,"[""jegham2025""]",False,0.0,True,is_blank,"[""is_blank""]",False,0.0,True,is_blank,"[""is_blank""]",False,0.0,True,DeepSeek-R1 (DS),"[""jegham2025""]",False,0.0,True,is_blank,"[""is_blank""]",False,0.0,True,DeepSeek-R1 (DS),"[""jegham2025""]",False,0.0,True,is_blank,"[""jegham2025""]",False,0.0,True,is_blank,"[""is_blank""]",False,0.0,True,is_blank,"[""is_blank""]",False,0.0,True
q170,How many days of CO₂ emissions from an average American life are equivalent to training BERT base?,14.4,['strubell2019'],1438 lbs / 99.8 lbs/day = 14.4 ,days,17.3,"[""strubell2019""]",False,1.0,True,6321,"[""strubell2019""]",False,1.0,True,is_blank,"[""is_blank""]",False,0.0,True,"626,155","[""strubell2019""]",False,1.0,True,6325,"[""strubell2019"", ""luccioni2025b""]",False,0.5,True,is_blank,"[""strubell2019"", ""luccioni2025b""]",False,0.5,True,17.3,"[""luccioni2025b"", ""strubell2019""]",False,0.5,True,1.72,"[""strubell2019""]",False,1.0,True,0.4,"[""strubell2019""]",False,1.0,True
q200,True or False: The Transformer architecture eventuallly outperforms the Evolved Transformers architecture on the WMT'24 EN-DE BLUE task as the model sizes grow.,0,['patterson2021'],Figure,is_blank,is_blank,"[""is_blank""]",False,0.0,True,is_blank,"[""is_blank""]",False,0.0,True,is_blank,"[""is_blank""]",False,0.0,True,is_blank,"[""is_blank""]",False,0.0,True,is_blank,"[""is_blank""]",False,0.0,True,is_blank,"[""is_blank""]",False,0.0,True,is_blank,"[""is_blank""]",False,0.0,True,is_blank,"[""is_blank""]",False,0.0,True,is_blank,"[""is_blank""]",False,0.0,True
q202,"What dataset of 5,842 labeled entries was used to test energy-efficient large language models in the financial domain?",Financial Sentiment Analysis,['khan2025'],Quote,is_blank,is_blank,"[""is_blank""]",False,0.0,True,is_blank,"[""is_blank""]",False,0.0,True,is_blank,"[""is_blank""]",False,0.0,True,is_blank,"[""is_blank""]",False,0.0,True,is_blank,"[""is_blank""]",False,0.0,True,is_blank,"[""is_blank""]",False,0.0,True,is_blank,"[""is_blank""]",False,0.0,True,is_blank,"[""is_blank""]",False,0.0,True,is_blank,"[""is_blank""]",False,0.0,True
q203,True or False: Eight T4 spot instances could be more cost-efficient than a DGX-2 node for distributed training.,1,['erben2023'],Quote,is_blank,1,"[""erben2023""]",True,1.0,True,1,"[""erben2023""]",True,1.0,True,1,"[""erben2023""]",True,1.0,True,1,"[""erben2023""]",True,1.0,True,1,"[""[ref_id=erben2023]""]",True,0.0,True,1,"[""erben2023""]",True,1.0,True,1,"[""erben2023""]",True,1.0,True,1,"[""erben2023"", ""erben2023""]",True,1.0,True,0,"[""erben2023""]",False,1.0,True
q207,True or False: The 2023 US Executive Order regarding AI mentioned the greenhouse gas emissions or energy usage of AI.,0,luccioni2025b,Quote,is_blank,0,"[""luccioni2025b""]",True,1.0,True,0,"[""luccioni2025b""]",True,1.0,True,0,"[""luccioni2025b""]",True,1.0,True,0,"[""luccioni2025b""]",True,1.0,True,0,"[""[ref_id=luccioni2025b]""]",True,0.0,True,0,"[""luccioni2025b""]",True,1.0,True,0,"[""luccioni2025b""]",True,1.0,True,0,"[""luccioni2025b""]",True,1.0,True,0,"[""luccioni2025b""]",True,1.0,True
q211,"True or False: Under Germany's 2023 Energy Efficiency Act, data centers must run on 100% renewable energy by January 1, 2027.",1,['ebert2024'],Quote,is_blank,1,"[""ebert2024""]",True,1.0,True,1,"[""ebert2024""]",True,1.0,True,1,"[""ebert2024""]",True,1.0,True,0,"[""ebert2024""]",False,1.0,True,1,"[""ebert2024""]",True,1.0,True,1,"[""ebert2024""]",True,1.0,True,1,"[""ebert2024""]",True,1.0,True,1,"[""ebert2024""]",True,1.0,True,1,"[""ebert2024""]",True,1.0,True
q215,"Out of a sample of 60 papers from top AI conferences, how many papers from ACL targeted both accuracy and efficiency?",2,['schwartz2019'],Figure,papers,6,"[""schwartz2019""]",False,1.0,True,0,"[""schwartz2019""]",False,1.0,True,6,"[""schwartz2019""]",False,1.0,True,6,"[""schwartz2019""]",False,1.0,True,is_blank,"[""is_blank""]",False,0.0,True,is_blank,"[""schwartz2019""]",False,1.0,True,is_blank,"[""is_blank""]",False,0.0,True,6,"[""schwartz2019""]",False,1.0,True,0,"[""schwartz2019""]",False,1.0,True
q221,"According to recent estimates, what percentage of a model's total lifecycle energy use can inference account for?",90,['jegham2025'],Quote,percent,90,"[""jegham2025"", ""luccioni2024"", ""chung2025""]",True,0.3333333333333333,True,90,"[""jegham2025"", ""luccioni2024""]",True,0.5,True,90,"[""jegham2025""]",True,1.0,True,90,"[""jegham2025""]",True,1.0,True,90,"[""jegham2025"", ""luccioni2024"", ""chung2025""]",True,0.3333333333333333,True,90,"[""jegham2025"", ""luccioni2024""]",True,0.5,True,90,"[""jegham2025"", ""luccioni2024""]",True,0.5,True,90,"[""jegham2025"", ""luccioni2024"", ""chung2025""]",True,0.3333333333333333,True,90,"[""jegham2025"", ""luccioni2024""]",True,0.5,True
q230,True or False: The AI Act requires providers to report both training and inference energy consumption for general-purpose AI models.,0,['ebert2024'],Quote,is_blank,0,"[""ebert2024""]",True,1.0,True,0,"[""ebert2024""]",True,1.0,True,,[],False,0.0,True,0,"[""ebert2024""]",True,1.0,True,is_blank,"[""is_blank""]",False,0.0,True,0,"[""ebert2024""]",True,1.0,True,0,"[""ebert2024""]",True,1.0,True,,[],False,0.0,True,0,"[""ebert2024""]",True,1.0,True
q231,True or False: The AI Act currently requires providers to report energy use during the inference phase of AI models.,0,['ebert2024'],Quote,is_blank,0,"[""ebert2024""]",True,1.0,True,0,"[""ebert2024""]",True,1.0,True,0,"[""ebert2024""]",True,1.0,True,0,"[""ebert2024""]",True,1.0,True,0,"[""ebert2024""]",True,1.0,True,0,"[""ebert2024""]",True,1.0,True,0,"[""ebert2024""]",True,1.0,True,,[],False,0.0,True,0,"[""ebert2024""]",True,1.0,True
q246,True or False: New AI data centers often rely on air cooling due to high server power densities.,0,['li2025b'],Quote,is_blank,0,"[""li2025b""]",True,1.0,True,0,"[""li2025b""]",True,1.0,True,0,"[""li2025b""]",True,1.0,True,0,"[""li2025b""]",True,1.0,True,0,"[""li2025b""]",True,1.0,True,0,"[""[\""li2025b\""]""]",True,0.0,True,0,"[""li2025b""]",True,1.0,True,is_blank,is_blank,False,0.0,True,0,"[""li2025b""]",True,1.0,True
q253,By what factor did platform-level caching improve the power efficiency of the inference workload for the cross-lingual Transformer language model described in Wu et al. (2021)?,6.7,['wu2021a'],Quote,multiplier,6.7,"[""wu2021a""]",True,1.0,True,6.7,"[""wu2021a""]",True,1.0,True,6.7,"[""wu2021a""]",True,1.0,True,6.7,"[""wu2021a""]",True,1.0,True,6.7,"[""wu2021a""]",True,1.0,True,6.7,"[""wu2021a""]",True,1.0,True,6.7,"[""wu2021a""]",True,1.0,True,6.7,"[""wu2021a""]",True,1.0,True,6.7,"[""wu2021a""]",True,1.0,True
q262,What is the estimated CO2 emissions in pounds from training a BERT base model for 79 hours using  64 V100 GPUs?,1438,['strubell2019'],Table,lbs,1438,"[""strubell2019""]",True,1.0,True,1438,"[""strubell2019""]",True,1.0,True,1438,"[""strubell2019""]",True,1.0,True,1438,"[""strubell2019""]",True,1.0,True,1438,"[""strubell2019""]",True,1.0,True,1438,"[""strubell2019""]",True,1.0,True,1438,"[""strubell2019""]",True,1.0,True,1438,"[""strubell2019""]",True,1.0,True,1438,"[""strubell2019""]",True,1.0,True
q263,"According to a recent paper, what percentage of total compute demand does ML inference reportedly account for?","[80,90]",['chung2025'],Quote,percent,80-90,"[""chung2025"", ""luccioni2024"", ""fernandez2025""]",False,0.3333333333333333,True,80-90,"[""chung2025"", ""luccioni2024""]",False,0.5,True,80–90,"[""chung2025"", ""luccioni2024"", ""fernandez2025""]",False,0.3333333333333333,True,80-90,"[""chung2025"", ""luccioni2024"", ""fernandez2025""]",False,0.3333333333333333,True,80-90,"[""chung2025"", ""luccioni2024"", ""fernandez2025""]",False,0.3333333333333333,True,85,"[""chung2025"", ""luccioni2024"", ""fernandez2025""]",True,0.3333333333333333,True,80-90,"[""chung2025"", ""luccioni2024"", ""fernandez2025""]",False,0.3333333333333333,True,80–90%,"[""chung2025"", ""luccioni2024"", ""fernandez2025""]",False,0.3333333333333333,True,85,"[""chung2025"", ""luccioni2024"", ""fernandez2025""]",True,0.3333333333333333,True
q272,How many U.S. household-years of electricity consumption is training a 6.1B-parameter language model equivalent to?,1.3,"['dodge2022','strubell2019']",13.8 MWh ÷ 10.7 MWh/yr ≈ 1.3 household-years.,household-years,9,"[""dodge2022""]",False,0.5,True,is_blank,"[""dodge2022""]",False,0.5,True,is_blank,"[""is_blank""]",False,0.0,True,103.5,"[""dodge2022""]",False,0.5,True,9.97,"[""dodge2022""]",False,0.5,True,is_blank,"[""is_blank""]",False,0.0,True,is_blank,"[""dodge2022""]",False,0.5,True,9.73,"[""dodge2022""]",False,0.5,True,is_blank,"[""dodge2022""]",False,0.5,True
q278,True or False: Egress costs in geo-distributed NLP experiments could account for more than 90% of the total cost per VM.,1,['erben2023'],"Figure, Quote",is_blank,1,"[""erben2023""]",True,1.0,True,1,"[""erben2023""]",True,1.0,True,1,"[""erben2023""]",True,1.0,True,1,"[""erben2023""]",True,1.0,True,1,"[""[ref_id=erben2023]""]",True,0.0,True,1,"[""[\""erben2023\""]""]",True,0.0,True,1,"[""erben2023""]",True,1.0,True,1,"[""erben2023""]",True,1.0,True,1,"[""erben2023""]",True,1.0,True
q280,"Given the total pre-training GPU hours and the number of GPUs used, estimate the total wall-clock time in days required to pre-train the JetMoE-8B model.",13,['shen2024'],"Math: wall_clock_hours ≈ 30,000 GPUh ÷ 96 GPUs = 312.5 h; days ≈ 312.5 ÷ 24 ≈ 13.0 days (pretraining; alignment 60 GPUh is separate).",days,3.125,"[""shen2024""]",False,1.0,True,13.02,"[""shen2024""]",False,1.0,True,13,"[""shen2024""]",True,1.0,True,is_blank,"[""shen2024""]",False,1.0,True,,[],False,0.0,True,13.02,"[""shen2024""]",False,1.0,True,is_blank,"[""shen2024""]",False,1.0,True,31.25,"[""shen2024"", ""shen2024""]",False,1.0,True,13,"[""shen2024""]",True,1.0,True
q282,"What is the term for the amount of water evaporated, transpired, or incorporated into products, and is defined as 'water withdrawal minus water discharge'?",Water consumption,['li2025b'],Quote,is_blank,Water consumption,"[""li2025b""]",True,1.0,True,Water consumption,"[""li2025b""]",True,1.0,True,Water consumption,"[""li2025b""]",True,1.0,True,Water consumption,"[""li2025b""]",True,1.0,True,Water consumption,"[""li2025b""]",True,1.0,True,Water consumption,"[""li2025b""]",True,1.0,True,,[],False,0.0,True,Water consumption,"[""li2025b""]",True,1.0,True,Water consumption,"[""li2025b""]",True,1.0,True
q296,What was the observed range of inference energy per second for LLaMA-65B across GPU shard configurations?,"[300,1000]",['samsi2024'],Quote,W,300-1000,"[""samsi2024""]",False,1.0,True,300W,"[""samsi2024""]",False,1.0,True,300-1000,"[""samsi2024""]",False,1.0,True,is_blank,"[""samsi2024""]",False,1.0,True,300-1000,"[""samsi2024""]",False,1.0,True,300-1000,"[""samsi2024""]",False,1.0,True,,[],False,0.0,True,,[],False,0.0,True,300-1000,"[""samsi2024""]",False,1.0,True
q297,"When comparing small and large versions of Qwen models in zero-shot classification, how many times more energy did the 72B version consume than the 7B version?",8.720430108,['zschache2025'], 48.66/5.58 ,multiplier,7,"[""zschache2025""]",False,1.0,True,7,"[""zschache2025""]",False,1.0,True,7,"[""zschache2025""]",False,1.0,True,7,"[""zschache2025""]",False,1.0,True,7,"[""[ref_id=zschache2025]""]",False,0.0,True,7,"[""zschache2025""]",False,1.0,True,7,"[""zschache2025""]",False,1.0,True,7,"[""zschache2025"", ""zschache2025""]",False,1.0,True,7,"[""zschache2025""]",False,1.0,True
q304,By what percentage did Qwen's carbon emissions fall when applying quantization and local inference for sentiment classification?,55.6,['khan2025'],0.009→0.004=55.6%,percent,,[],False,0.0,True,55.6,"[""khan2025""]",True,1.0,True,55.56,"[""khan2025""]",True,1.0,True,,[],False,0.0,True,55.56,"[""khan2025""]",True,1.0,True,55.56,"[""khan2025""]",True,1.0,True,55.56,"[""khan2025""]",True,1.0,True,55.6,"[""khan2025""]",True,1.0,True,56,"[""khan2025""]",False,1.0,True
q306,How many widely used model architectures across different tasks were included in the latest iteration of the ML.ENERGY Benchmark?,40,['chung2025'],Quote,models,40,"[""chung2025""]",True,1.0,True,40,"[""chung2025""]",True,1.0,True,40,"[""chung2025""]",True,1.0,True,40,"[""chung2025""]",True,1.0,True,40,"[""chung2025""]",True,1.0,True,40,"[""chung2025""]",True,1.0,True,40,"[""chung2025""]",True,1.0,True,40,"[""chung2025""]",True,1.0,True,40,"[""chung2025""]",True,1.0,True
q316,"In the analysis of training a Llama-3.1 scale model, what was the estimated health cost, In USD, when training in Altoona, Iowa?",2510000,['han2024'],Table,USD,2.5,"[""han2024""]",False,1.0,True,2500000,"[""han2024""]",False,1.0,True,2500000,"[""han2024""]",False,1.0,True,2500000,"[""han2024""]",False,1.0,True,2500000,"[""han2024""]",False,1.0,True,2.5,"[""han2024""]",False,1.0,True,2.5,"[""han2024""]",False,1.0,True,,[],False,0.0,True,2500000,"[""han2024""]",False,1.0,True
