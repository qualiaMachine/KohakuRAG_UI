"""
DataPacker Performance Benchmark

Comprehensive benchmark for all DataPacker types including new vector support.
Tests pack/unpack performance for primitives, structured data, and vectors.
"""

import argparse
import struct
import time
from typing import List

import numpy as np
from tqdm import tqdm

from kohakuvault import DataPacker


# =============================================================================
# Utilities
# =============================================================================


def format_time(seconds: float) -> str:
    """Format time in appropriate unit."""
    if seconds < 0.001:
        return f"{seconds*1000000:.0f}us"
    elif seconds < 1.0:
        return f"{seconds*1000:.1f}ms"
    else:
        return f"{seconds:.2f}s"


def format_size(bytes_val: int) -> str:
    """Format bytes as human-readable."""
    for unit in ["B", "KB", "MB", "GB"]:
        if bytes_val < 1024.0:
            return f"{bytes_val:.0f}{unit}"
        bytes_val /= 1024.0
    return f"{bytes_val:.1f}TB"


# =============================================================================
# 1. Primitive Types Benchmark
# =============================================================================


def benchmark_primitives(n_ops=10000):
    """Benchmark primitive types pack() loop vs pack_many()."""
    print("\n" + "=" * 100)
    print("1. Primitive Types: pack() loop vs pack_many()")
    print("=" * 100)

    results = []

    # Test i64
    print(f"\nBenchmarking i64 ({n_ops:,} operations)...")
    packer_i64 = DataPacker("i64")
    values_i64 = list(range(n_ops))

    # Loop with pack()
    start = time.perf_counter()
    for val in values_i64:
        _ = packer_i64.pack(val)
    i64_loop_time = time.perf_counter() - start

    # Bulk with pack_many()
    start = time.perf_counter()
    _ = packer_i64.pack_many(values_i64)
    i64_bulk_time = time.perf_counter() - start

    # Unpack comparison
    packed_all = packer_i64.pack_many(values_i64)

    start = time.perf_counter()
    for i in range(n_ops):
        _ = packer_i64.unpack(packed_all, i * 8)
    i64_unpack_loop_time = time.perf_counter() - start

    start = time.perf_counter()
    _ = packer_i64.unpack_many(packed_all, count=n_ops)
    i64_unpack_bulk_time = time.perf_counter() - start

    results.append(
        {
            "type": "i64",
            "pack_loop": i64_loop_time,
            "pack_bulk": i64_bulk_time,
            "pack_speedup": i64_loop_time / i64_bulk_time,
            "unpack_loop": i64_unpack_loop_time,
            "unpack_bulk": i64_unpack_bulk_time,
            "unpack_speedup": i64_unpack_loop_time / i64_unpack_bulk_time,
        }
    )

    # Test f64
    print(f"Benchmarking f64 ({n_ops:,} operations)...")
    packer_f64 = DataPacker("f64")
    values_f64 = [float(i) for i in range(n_ops)]

    # Loop with pack()
    start = time.perf_counter()
    for val in values_f64:
        _ = packer_f64.pack(val)
    f64_loop_time = time.perf_counter() - start

    # Bulk with pack_many()
    start = time.perf_counter()
    _ = packer_f64.pack_many(values_f64)
    f64_bulk_time = time.perf_counter() - start

    # Unpack comparison
    packed_all = packer_f64.pack_many(values_f64)

    start = time.perf_counter()
    for i in range(n_ops):
        _ = packer_f64.unpack(packed_all, i * 8)
    f64_unpack_loop_time = time.perf_counter() - start

    start = time.perf_counter()
    _ = packer_f64.unpack_many(packed_all, count=n_ops)
    f64_unpack_bulk_time = time.perf_counter() - start

    results.append(
        {
            "type": "f64",
            "pack_loop": f64_loop_time,
            "pack_bulk": f64_bulk_time,
            "pack_speedup": f64_loop_time / f64_bulk_time,
            "unpack_loop": f64_unpack_loop_time,
            "unpack_bulk": f64_unpack_bulk_time,
            "unpack_speedup": f64_unpack_loop_time / f64_unpack_bulk_time,
        }
    )

    # Print results
    print(
        f"\n{'Type':<10s} {'Pack Loop':<15s} {'Pack Bulk':<15s} {'Speedup':<12s} {'Unpack Loop':<15s} {'Unpack Bulk':<15s} {'Speedup':<12s}"
    )
    print("-" * 110)
    for r in results:
        print(
            f"{r['type']:<10s} "
            f"{format_time(r['pack_loop']):<15s} "
            f"{format_time(r['pack_bulk']):<15s} "
            f"{r['pack_speedup']:<12.2f}x "
            f"{format_time(r['unpack_loop']):<15s} "
            f"{format_time(r['unpack_bulk']):<15s} "
            f"{r['unpack_speedup']:<12.2f}x"
        )


# =============================================================================
# 2. Vector Types Benchmark
# =============================================================================


def benchmark_vectors(n_ops=10000):
    """Benchmark vector packing for various dimensions and types."""
    print("\n" + "=" * 100)
    print("2. Vector Types: Fixed vs Arbitrary Shape")
    print("=" * 100)

    results = []

    # Test configurations: (dtype, dimensions, label)
    test_configs = [
        ("vec:f32:128", 128, "Embedding-128 (fixed)"),
        ("vec:f32:768", 768, "Embedding-768 (fixed)"),
        ("vec:f32:1536", 1536, "Embedding-1536 (fixed)"),
        ("vec:f32", 128, "Embedding-128 (arbitrary)"),
        ("vec:f32", 768, "Embedding-768 (arbitrary)"),
        ("vec:i64:100", 100, "Int64-100 (fixed)"),
        ("vec:u8:28:28", 28 * 28, "Image-28x28 (fixed)"),
        ("vec:u8:224:224", 224 * 224, "Image-224x224 (fixed)"),
    ]

    for dtype, dim_or_total, label in tqdm(test_configs, desc="Vector Packing"):
        packer = DataPacker(dtype)

        # Generate test data
        if "u8" in dtype:
            if ":" in dtype.split("u8")[1]:  # Fixed shape like vec:u8:28:28
                dims_str = dtype.split("u8:")[1]
                shape = tuple(int(d) for d in dims_str.split(":"))
                data = [np.random.randint(0, 256, size=shape, dtype=np.uint8) for _ in range(n_ops)]
            else:
                data = [
                    np.random.randint(0, 256, size=dim_or_total, dtype=np.uint8)
                    for _ in range(n_ops)
                ]
        elif "i64" in dtype:
            data = [np.arange(dim_or_total, dtype=np.int64) for _ in range(n_ops)]
        elif "f32" in dtype:
            if ":" in dtype.split("f32")[1]:  # Fixed shape
                data = [np.random.randn(dim_or_total).astype(np.float32) for _ in range(n_ops)]
            else:  # Arbitrary shape
                data = [np.random.randn(dim_or_total).astype(np.float32) for _ in range(n_ops)]

        # Benchmark pack
        start = time.perf_counter()
        packed_items = [packer.pack(item) for item in data]
        pack_time = time.perf_counter() - start

        # Benchmark unpack
        start = time.perf_counter()
        for packed in packed_items:
            _ = packer.unpack(packed, 0)
        unpack_time = time.perf_counter() - start

        # Get size info
        sample_packed = packed_items[0]
        packed_size = len(sample_packed)

        results.append(
            {
                "label": label,
                "dtype": dtype,
                "pack_time": pack_time,
                "unpack_time": unpack_time,
                "pack_ops": n_ops / pack_time,
                "unpack_ops": n_ops / unpack_time,
                "packed_size": packed_size,
                "is_varsize": packer.is_varsize,
            }
        )

    # Print results
    print(
        f"\n{'Type':<30s} {'Size':<15s} {'Pack':<15s} {'Unpack':<15s} {'Pack/s':<15s} {'Unpack/s':<15s}"
    )
    print("-" * 105)
    for r in results:
        varsize_marker = " (varsize)" if r["is_varsize"] else ""
        print(
            f"{r['label']:<30s} "
            f"{format_size(r['packed_size']):<15s} "
            f"{format_time(r['pack_time']):<15s} "
            f"{format_time(r['unpack_time']):<15s} "
            f"{r['pack_ops']:<15,.0f} "
            f"{r['unpack_ops']:<15,.0f}"
        )


# =============================================================================
# 3. Vector Bulk Operations Benchmark
# =============================================================================


def benchmark_vector_bulk(n_ops=10000):
    """Benchmark pack_many/unpack_many for vectors."""
    print("\n" + "=" * 100)
    print("3. Vector Bulk Operations: pack_many vs loop")
    print("=" * 100)

    results = []

    # Test configurations: (dtype, dim, label)
    test_configs = [
        ("vec:f32:128", 128, "Embedding-128"),
        ("vec:f32:768", 768, "Embedding-768"),
        ("vec:i64:100", 100, "Int64-100"),
        ("vec:u8:28:28", (28, 28), "Image-28x28"),
    ]

    for dtype, shape, label in tqdm(test_configs, desc="Vector Bulk"):
        packer = DataPacker(dtype)

        # Generate test data
        if isinstance(shape, tuple):
            data = [np.random.randint(0, 256, size=shape, dtype=np.uint8) for _ in range(n_ops)]
        elif "f32" in dtype:
            data = [np.random.randn(shape).astype(np.float32) for _ in range(n_ops)]
        elif "i64" in dtype:
            data = [np.arange(shape, dtype=np.int64) for _ in range(n_ops)]

        # Benchmark pack (loop)
        start = time.perf_counter()
        packed_items = [packer.pack(item) for item in data]
        pack_loop_time = time.perf_counter() - start

        # Benchmark pack_many (bulk)
        start = time.perf_counter()
        packed_bulk = packer.pack_many(data)
        pack_bulk_time = time.perf_counter() - start

        # Benchmark unpack (loop)
        start = time.perf_counter()
        for packed in packed_items:
            _ = packer.unpack(packed, 0)
        unpack_loop_time = time.perf_counter() - start

        # Benchmark unpack_many (bulk)
        start = time.perf_counter()
        _ = packer.unpack_many(packed_bulk, count=n_ops)
        unpack_bulk_time = time.perf_counter() - start

        results.append(
            {
                "label": label,
                "pack_loop_time": pack_loop_time,
                "pack_bulk_time": pack_bulk_time,
                "unpack_loop_time": unpack_loop_time,
                "unpack_bulk_time": unpack_bulk_time,
                "pack_speedup": pack_loop_time / pack_bulk_time,
                "unpack_speedup": unpack_loop_time / unpack_bulk_time,
            }
        )

    # Print results
    print(
        f"\n{'Type':<20s} {'Pack Loop':<15s} {'Pack Bulk':<15s} {'Speedup':<12s} {'Unpack Loop':<15s} {'Unpack Bulk':<15s} {'Speedup':<12s}"
    )
    print("-" * 110)
    for r in results:
        print(
            f"{r['label']:<20s} "
            f"{format_time(r['pack_loop_time']):<15s} "
            f"{format_time(r['pack_bulk_time']):<15s} "
            f"{r['pack_speedup']:<12.2f}x "
            f"{format_time(r['unpack_loop_time']):<15s} "
            f"{format_time(r['unpack_bulk_time']):<15s} "
            f"{r['unpack_speedup']:<12.2f}x"
        )


# =============================================================================
# 4. Structured Types Benchmark
# =============================================================================


def benchmark_structured(n_ops=10000):
    """Benchmark MessagePack and CBOR."""
    print("\n" + "=" * 100)
    print("4. Structured Types: MessagePack vs CBOR vs JSON")
    print("=" * 100)

    import json

    # Test data
    data = {
        "name": "Test User",
        "age": 30,
        "scores": [95, 87, 92, 88, 91],
        "active": True,
        "metadata": {"created": "2025-01-01", "verified": True},
    }

    results = []

    # Python JSON
    print(f"\nBenchmarking JSON ({n_ops:,} operations)...")
    start = time.perf_counter()
    for _ in range(n_ops):
        json_str = json.dumps(data)
        _ = json_str.encode("utf-8")
    json_pack_time = time.perf_counter() - start

    start = time.perf_counter()
    json_bytes = json.dumps(data).encode("utf-8")
    for _ in range(n_ops):
        _ = json.loads(json_bytes.decode("utf-8"))
    json_unpack_time = time.perf_counter() - start

    json_size = len(json_bytes)

    results.append(
        {
            "type": "JSON (Python)",
            "pack_time": json_pack_time,
            "unpack_time": json_unpack_time,
            "pack_ops": n_ops / json_pack_time,
            "unpack_ops": n_ops / json_unpack_time,
            "size": json_size,
        }
    )

    # MessagePack
    print(f"Benchmarking MessagePack ({n_ops:,} operations)...")
    packer_msgpack = DataPacker("msgpack")

    start = time.perf_counter()
    for _ in range(n_ops):
        _ = packer_msgpack.pack(data)
    msgpack_pack_time = time.perf_counter() - start

    packed_msgpack = packer_msgpack.pack(data)
    start = time.perf_counter()
    for _ in range(n_ops):
        _ = packer_msgpack.unpack(packed_msgpack, 0)
    msgpack_unpack_time = time.perf_counter() - start

    msgpack_size = len(packed_msgpack)

    results.append(
        {
            "type": "MessagePack (Rust)",
            "pack_time": msgpack_pack_time,
            "unpack_time": msgpack_unpack_time,
            "pack_ops": n_ops / msgpack_pack_time,
            "unpack_ops": n_ops / msgpack_unpack_time,
            "size": msgpack_size,
        }
    )

    # CBOR
    print(f"Benchmarking CBOR ({n_ops:,} operations)...")
    packer_cbor = DataPacker("cbor")

    start = time.perf_counter()
    for _ in range(n_ops):
        _ = packer_cbor.pack(data)
    cbor_pack_time = time.perf_counter() - start

    packed_cbor = packer_cbor.pack(data)
    start = time.perf_counter()
    for _ in range(n_ops):
        _ = packer_cbor.unpack(packed_cbor, 0)
    cbor_unpack_time = time.perf_counter() - start

    cbor_size = len(packed_cbor)

    results.append(
        {
            "type": "CBOR (Rust)",
            "pack_time": cbor_pack_time,
            "unpack_time": cbor_unpack_time,
            "pack_ops": n_ops / cbor_pack_time,
            "unpack_ops": n_ops / cbor_unpack_time,
            "size": cbor_size,
        }
    )

    # Print results
    print(
        f"\n{'Type':<25s} {'Size':<10s} {'Pack':<15s} {'Unpack':<15s} {'Pack/s':<15s} {'Unpack/s':<15s}"
    )
    print("-" * 95)
    for r in results:
        print(
            f"{r['type']:<25s} "
            f"{r['size']:<10d} "
            f"{format_time(r['pack_time']):<15s} "
            f"{format_time(r['unpack_time']):<15s} "
            f"{r['pack_ops']:<15,.0f} "
            f"{r['unpack_ops']:<15,.0f}"
        )

    # Print summary
    json_pack_ops = results[0]["pack_ops"]
    msgpack_pack_ops = results[1]["pack_ops"]
    msgpack_speedup = msgpack_pack_ops / json_pack_ops

    print(f"\nMessagePack vs JSON:")
    print(f"  Size reduction: {100 * msgpack_size / json_size:.1f}% of JSON size")
    print(
        f"  Pack speedup: {msgpack_speedup:.2f}x faster"
        if msgpack_speedup > 1
        else f"  Pack: {1/msgpack_speedup:.2f}x slower"
    )


# =============================================================================
# 5. String Encoding Benchmark
# =============================================================================


def benchmark_strings(n_ops=10000):
    """Benchmark different string encodings."""
    print("\n" + "=" * 100)
    print("5. String Encodings")
    print("=" * 100)

    text = "Hello, World! This is a test string with some Unicode: ä½ å¥½ä¸–ç•Œ ðŸš€"
    ascii_text = "Hello, World! This is a test string."

    encodings = [
        ("str:utf8", text, "UTF-8 (variable)"),
        ("str:32:utf8", text[:20], "UTF-8 (fixed 32B)"),
        ("str:utf16le", text, "UTF-16LE (variable)"),
        ("str:ascii", ascii_text, "ASCII (variable)"),
    ]

    results = []

    for dtype, test_text, label in encodings:
        packer = DataPacker(dtype)

        # Benchmark pack
        start = time.perf_counter()
        for _ in range(n_ops):
            _ = packer.pack(test_text)
        pack_time = time.perf_counter() - start

        # Benchmark unpack
        packed = packer.pack(test_text)
        start = time.perf_counter()
        for _ in range(n_ops):
            _ = packer.unpack(packed, 0)
        unpack_time = time.perf_counter() - start

        results.append(
            {
                "label": label,
                "pack_time": pack_time,
                "unpack_time": unpack_time,
                "size": len(packed),
                "pack_ops": n_ops / pack_time,
                "unpack_ops": n_ops / unpack_time,
            }
        )

    # Print results
    print(
        f"\n{'Encoding':<25s} {'Size':<10s} {'Pack':<15s} {'Unpack':<15s} {'Pack/s':<15s} {'Unpack/s':<15s}"
    )
    print("-" * 95)
    for r in results:
        print(
            f"{r['label']:<25s} "
            f"{r['size']:<10d} "
            f"{format_time(r['pack_time']):<15s} "
            f"{format_time(r['unpack_time']):<15s} "
            f"{r['pack_ops']:<15,.0f} "
            f"{r['unpack_ops']:<15,.0f}"
        )


# =============================================================================
# 6. Vector Dimensions Scaling Benchmark
# =============================================================================


def benchmark_vector_scaling(dimensions_list: List[int] = None):
    """Benchmark how performance scales with vector dimensions."""
    if dimensions_list is None:
        dimensions_list = [64, 128, 256, 512, 768, 1024, 1536, 2048, 3072, 4096]

    print("\n" + "=" * 100)
    print("6. Vector Dimension Scaling (float32)")
    print("=" * 100)

    n_ops = 5000  # Reduced for larger vectors
    results = []

    for dims in tqdm(dimensions_list, desc="Dimension Scaling"):
        packer = DataPacker(f"vec:f32:{dims}")

        # Generate data
        data = [np.random.randn(dims).astype(np.float32) for _ in range(n_ops)]

        # Benchmark pack
        start = time.perf_counter()
        packed_items = [packer.pack(item) for item in data]
        pack_time = time.perf_counter() - start

        # Benchmark unpack
        start = time.perf_counter()
        for packed in packed_items:
            _ = packer.unpack(packed, 0)
        unpack_time = time.perf_counter() - start

        # Calculate throughput
        total_bytes = dims * 4 * n_ops  # f32 = 4 bytes
        pack_mb_per_sec = (total_bytes / (1024 * 1024)) / pack_time
        unpack_mb_per_sec = (total_bytes / (1024 * 1024)) / unpack_time

        results.append(
            {
                "dims": dims,
                "pack_time": pack_time,
                "unpack_time": unpack_time,
                "pack_ops": n_ops / pack_time,
                "unpack_ops": n_ops / unpack_time,
                "pack_mb_s": pack_mb_per_sec,
                "unpack_mb_s": unpack_mb_per_sec,
            }
        )

    # Print results
    print(
        f"\n{'Dims':<10s} {'Pack':<15s} {'Unpack':<15s} {'Pack/s':<15s} {'Unpack/s':<15s} {'Pack MB/s':<15s} {'Unpack MB/s':<15s}"
    )
    print("-" * 110)
    for r in results:
        print(
            f"{r['dims']:<10d} "
            f"{format_time(r['pack_time']):<15s} "
            f"{format_time(r['unpack_time']):<15s} "
            f"{r['pack_ops']:<15,.0f} "
            f"{r['unpack_ops']:<15,.0f} "
            f"{r['pack_mb_s']:<15.1f} "
            f"{r['unpack_mb_s']:<15.1f}"
        )


# =============================================================================
# 7. Overhead Analysis
# =============================================================================


def benchmark_overhead():
    """Analyze header overhead for different vector formats."""
    print("\n" + "=" * 100)
    print("7. Format Overhead Analysis")
    print("=" * 100)

    # Same vector, different formats
    vec_data = np.random.randn(128).astype(np.float32)

    configs = [
        ("vec:f32:128", "Fixed shape (128)"),
        ("vec:f32", "Arbitrary shape (128)"),
    ]

    results = []

    for dtype, label in configs:
        packer = DataPacker(dtype)
        packed = packer.pack(vec_data)

        data_size = 128 * 4  # 128 floats * 4 bytes
        overhead = len(packed) - data_size
        overhead_pct = 100 * overhead / data_size

        results.append(
            {
                "label": label,
                "total_size": len(packed),
                "data_size": data_size,
                "overhead": overhead,
                "overhead_pct": overhead_pct,
            }
        )

    # Print results
    print(f"\n{'Format':<30s} {'Total':<12s} {'Data':<12s} {'Overhead':<12s} {'Overhead %':<12s}")
    print("-" * 80)
    for r in results:
        print(
            f"{r['label']:<30s} "
            f"{r['total_size']:<12d} "
            f"{r['data_size']:<12d} "
            f"{r['overhead']:<12d} "
            f"{r['overhead_pct']:<12.2f}%"
        )

    print("\nFormat Details:")
    print("  Fixed shape:     |type(1)|data| = 1 byte overhead")
    print("  Arbitrary shape: |type(1)|ndim(1)|shape(ndim*4)|data| = (2 + ndim*4) bytes overhead")
    print("  For 1D vector: 6 bytes overhead (1 + 1 + 1*4)")


# =============================================================================
# Main Runner
# =============================================================================


def main():
    """Run all DataPacker benchmarks."""
    parser = argparse.ArgumentParser(
        description="DataPacker Performance Benchmark",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python benchmark_datapacker_new.py                    # Run all benchmarks
  python benchmark_datapacker_new.py --ops 50000        # More operations
  python benchmark_datapacker_new.py --dims 128 768     # Specific dimensions
        """,
    )

    parser.add_argument(
        "--ops",
        type=int,
        default=10000,
        help="Number of operations for each benchmark (default: 10000)",
    )

    parser.add_argument(
        "--dims",
        type=int,
        nargs="*",
        default=None,
        help="Custom vector dimensions for scaling test",
    )

    args = parser.parse_args()

    print("=" * 100)
    print("DataPacker Comprehensive Performance Benchmark")
    print("=" * 100)
    print(f"\nOperations per test: {args.ops:,}")
    print("Testing all supported types: primitives, vectors, structured data")

    try:
        # Run all benchmark suites
        benchmark_primitives(n_ops=args.ops)
        benchmark_vectors(n_ops=args.ops)
        benchmark_vector_bulk(n_ops=args.ops)
        benchmark_structured(n_ops=args.ops)
        benchmark_strings(n_ops=args.ops)

        if args.dims:
            benchmark_vector_scaling(dimensions_list=args.dims)
        else:
            benchmark_vector_scaling()

        benchmark_overhead()

        print("\n" + "=" * 100)
        print("Benchmark Complete!")
        print("=" * 100)
        print("\nKey Takeaways:")
        print("1. Rust DataPacker is faster than Python struct.pack for primitives")
        print("2. Vector bulk operations (pack_many/unpack_many) provide significant speedups")
        print("3. Fixed-shape vectors have minimal overhead (1 byte)")
        print("4. MessagePack is more compact and faster than JSON")
        print("5. Performance scales well with vector dimensions")

    except Exception as e:
        print(f"\nError during benchmark: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    main()
