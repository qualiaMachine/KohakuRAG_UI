"""Document indexing pipeline (structure → embeddings → stored nodes)."""

from typing import Iterable, Literal

import numpy as np

from .embeddings import EmbeddingModel, JinaEmbeddingModel, average_embeddings
from .text_utils import split_paragraphs, split_sentences
from .types import (
    DocumentPayload,
    NodeKind,
    ParagraphPayload,
    SectionPayload,
    SentencePayload,
    StoredNode,
    TreeNode,
)

# Embedding mode for paragraphs
ParagraphEmbeddingMode = Literal["averaged", "full", "both"]


def sentence_payloads_from_text(text: str) -> list[SentencePayload]:
    """Split text into sentence payloads using heuristic rules."""
    return [SentencePayload(text=s) for s in split_sentences(text)]


def paragraph_payload_from_text(text: str) -> ParagraphPayload:
    """Convert plain text into a paragraph with sentence segmentation."""
    return ParagraphPayload(
        text=text,
        sentences=sentence_payloads_from_text(text),
    )


def sections_from_text(document: DocumentPayload) -> list[SectionPayload]:
    """Auto-generate a single section from unstructured document text."""
    paragraphs = [
        paragraph_payload_from_text(paragraph)
        for paragraph in split_paragraphs(document.text)
    ]
    return [
        SectionPayload(
            title=document.title,
            paragraphs=paragraphs,
            metadata={"autogenerated": True},
        )
    ]


class DocumentIndexer:
    """Builds hierarchical nodes from DocumentPayloads and embeds them.

    Args:
        embedding_model: The embedding model to use. Defaults to JinaEmbeddingModel.
        paragraph_embedding_mode: How to embed paragraphs:
            - "averaged": Use weighted average of sentence embeddings (default)
            - "full": Embed paragraph text directly
            - "both": Store both averaged and full embeddings (full in metadata)
    """

    def __init__(
        self,
        embedding_model: EmbeddingModel | None = None,
        paragraph_embedding_mode: ParagraphEmbeddingMode = "averaged",
    ) -> None:
        self._embedding_model = embedding_model or JinaEmbeddingModel()
        self._paragraph_embedding_mode = paragraph_embedding_mode

    async def index(self, document: DocumentPayload) -> list[StoredNode]:
        """Build hierarchical tree, compute embeddings, and return storable nodes."""
        root = self._build_tree(document)
        await self._embed_tree(root)
        return [self._to_stored(node) for node in self._flatten(root)]

    def _build_tree(self, document: DocumentPayload) -> TreeNode:
        """Build document → section → paragraph → sentence hierarchy.

        Node IDs follow pattern: doc:sec1:p2:s3 for easy parent lookup.
        """
        # Track global counters for generating unique IDs
        counters = {"section": 0, "paragraph": 0, "sentence": 0}

        # Use provided structure or generate from plain text
        sections = document.sections or sections_from_text(document)

        # Reconstruct full document text if needed
        document_text = document.text or "\n\n".join(
            paragraph.text for section in sections for paragraph in section.paragraphs
        )

        # Build root document node
        root_metadata = dict(document.metadata)
        root_metadata.setdefault("document_id", document.document_id)
        root_metadata.setdefault("document_title", document.title)
        root = TreeNode(
            node_id=document.document_id,
            parent_id=None,
            kind=NodeKind.DOCUMENT,
            title=document.title,
            text=document_text,
            metadata=root_metadata,
        )

        # Build section nodes
        for section in sections:
            counters["section"] += 1
            section_id = f"{document.document_id}:sec{counters['section']}"
            section_meta = dict(section.metadata)
            section_meta.update(
                {
                    "document_id": document.document_id,
                    "document_title": document.title,
                    "section_index": counters["section"],
                }
            )
            section_node = TreeNode(
                node_id=section_id,
                parent_id=root.node_id,
                kind=NodeKind.SECTION,
                title=section.title,
                text=section.title,
                metadata=section_meta,
            )
            root.children.append(section_node)

            # Build paragraph nodes within this section
            for paragraph in section.paragraphs:
                counters["paragraph"] += 1
                paragraph_id = f"{section_id}:p{counters['paragraph']}"
                paragraph_meta = dict(paragraph.metadata)
                paragraph_meta.update(
                    {
                        "document_id": document.document_id,
                        "document_title": document.title,
                        "section_id": section_id,
                        "section_index": counters["section"],
                        "paragraph_index": counters["paragraph"],
                    }
                )
                paragraph_node = TreeNode(
                    node_id=paragraph_id,
                    parent_id=section_id,
                    kind=NodeKind.PARAGRAPH,
                    title=section.title,
                    text=paragraph.text,
                    metadata=paragraph_meta,
                )
                section_node.children.append(paragraph_node)

                # Build sentence nodes within this paragraph
                sentences = paragraph.sentences or sentence_payloads_from_text(
                    paragraph.text
                )
                for sentence in sentences:
                    counters["sentence"] += 1
                    sentence_id = f"{paragraph_id}:s{counters['sentence']}"
                    sentence_meta = dict(sentence.metadata)
                    sentence_meta.update(
                        {
                            "document_id": document.document_id,
                            "document_title": document.title,
                            "section_id": section_id,
                            "paragraph_id": paragraph_id,
                            "sentence_index": counters["sentence"],
                        }
                    )
                    sentence_node = TreeNode(
                        node_id=sentence_id,
                        parent_id=paragraph_id,
                        kind=NodeKind.SENTENCE,
                        title=section.title,
                        text=sentence.text,
                        metadata=sentence_meta,
                    )
                    paragraph_node.children.append(sentence_node)

        return root

    async def _embed_tree(self, root: TreeNode) -> None:
        """Embed leaf nodes and propagate upward to parents.

        Supports different paragraph embedding modes:
        - "averaged": Paragraph embedding = average of sentence embeddings
        - "full": Paragraph embedding = direct embedding of paragraph text
        - "both": Store averaged as main embedding, full in metadata
        """
        # Batch-embed all leaf nodes (sentences) for efficiency
        leaves = [node for node in self._flatten(root) if not node.children]
        if leaves:
            embeddings = await self._embedding_model.embed(
                [leaf.text for leaf in leaves]
            )
            for leaf, vector in zip(leaves, embeddings, strict=True):
                leaf.embedding = vector

        # Collect paragraphs if we need full embeddings
        paragraphs = [
            node for node in self._flatten(root) if node.kind == NodeKind.PARAGRAPH
        ]

        # Compute full paragraph embeddings if needed
        if self._paragraph_embedding_mode in ("full", "both") and paragraphs:
            para_embeddings = await self._embedding_model.embed(
                [p.text for p in paragraphs]
            )
            para_full_map = {
                p.node_id: vec
                for p, vec in zip(paragraphs, para_embeddings, strict=True)
            }
        else:
            para_full_map = {}

        # Recursively compute parent embeddings from children
        self._propagate_embeddings(root, para_full_map)

    def _propagate_embeddings(
        self, node: TreeNode, para_full_map: dict[str, np.ndarray] | None = None
    ) -> np.ndarray:
        """Recursively compute parent embeddings as average of children.

        Args:
            node: Current node to process
            para_full_map: Map of paragraph node_id -> full embedding (for "full"/"both" modes)
        """
        if para_full_map is None:
            para_full_map = {}

        if node.embedding is not None:
            return node.embedding  # Already embedded (leaf node)

        # Recurse to children first
        child_vectors = [
            self._propagate_embeddings(child, para_full_map) for child in node.children
        ]
        if not child_vectors:
            raise ValueError(f"Node {node.node_id} is missing an embedding.")

        # Compute averaged embedding from children
        averaged_embedding = average_embeddings(child_vectors)

        # Handle paragraph embedding modes
        if node.kind == NodeKind.PARAGRAPH and node.node_id in para_full_map:
            full_embedding = para_full_map[node.node_id]

            if self._paragraph_embedding_mode == "full":
                # Use full embedding as the main embedding
                node.embedding = full_embedding
            elif self._paragraph_embedding_mode == "both":
                # Use averaged as main, store full in metadata
                node.embedding = averaged_embedding
                # Store full embedding as base64-encoded numpy array in metadata
                node.metadata["full_embedding"] = full_embedding.tobytes().hex()
            else:
                # "averaged" mode - just use averaged
                node.embedding = averaged_embedding
        else:
            # Non-paragraph nodes or no full embedding available
            node.embedding = averaged_embedding

        return node.embedding

    def _flatten(self, node: TreeNode) -> Iterable[TreeNode]:
        """Depth-first traversal of tree."""
        yield node
        for child in node.children:
            yield from self._flatten(child)

    def _to_stored(self, node: TreeNode) -> StoredNode:
        """Convert tree node to storable format."""
        if node.embedding is None:
            raise ValueError(f"Node {node.node_id} is missing an embedding.")

        return StoredNode(
            node_id=node.node_id,
            parent_id=node.parent_id,
            kind=node.kind,
            title=node.title,
            text=node.text,
            metadata=node.metadata,
            embedding=node.embedding,
            child_ids=[child.node_id for child in node.children],
        )
