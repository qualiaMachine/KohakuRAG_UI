{"document_id": "dodge2022", "title": "Measuring the Carbon Intensity of AI in Cloud Instances", "text": "Measuring the Carbon Intensity of AI in Cloud Instances\nJESSE DODGE, Allen Institute for AI, USA\nTAYLOR PREWITT, University of Washington, USA\nREMI TACHET DES COMBES, Microsoft Research Montreal, USA\nERIKA ODMARK, Microsoft, USA\nROY SCHWARTZ,Hebrew University of Jerusalem, Israel\nEMMA STRUBELL, Carnegie Mellon University, USA\nALEXANDRA SASHA LUCCIONI, Hugging Face, USA\nNOAH A. SMITH, Allen Institute for AI and University of Washington, USA\nNICOLE DECARIO, Allen Institute for AI, USA\nWILL BUCHANAN, Microsoft, USA\nThe advent of cloud computing has provided people around the world with unprecedented access to computational power and\nenabled rapid growth in technologies such as machine learning, the computational demands of which incur a high energy cost and a\ncommensurate carbon footprint. As a result, recent scholarship has called for better estimates of the greenhouse gas impact of AI: data\nscientists today do not have easy or reliable access to measurements of this information, which precludes development of actionable\ntactics. We argue that cloud providers presenting information about software carbon intensity to users is a fundamental stepping\nstone towards minimizing emissions.\nIn this paper, we provide a framework for measuring software carbon intensity, and propose to measure operational carbon\nemissions by using location-based and time-specific marginal emissions data per energy unit. We provide measurements of operational\nsoftware carbon intensity for a set of modern models covering natural language processing and computer vision applications, and a\nwide range of model sizes, including pretraining of a 6.1 billion parameter language model. We then evaluate a suite of approaches for\nreducing emissions on the Microsoft Azure cloud compute platform: using cloud instances in different geographic regions, using cloud\ninstances at different times of day, and dynamically pausing cloud instances when the marginal carbon intensity is above a certain\nthreshold. We confirm previous results that the geographic region of the data center plays a significant role in the carbon intensity for\na given cloud instance, and find that choosing an appropriate region can have the largest operational emissions reduction impact. We\nalso present new results showing that the time of day has meaningful impact on operational software carbon intensity.Finally, we\nconclude with recommendations for how machine learning practitioners can use software carbon intensity information to reduce\nenvironmental impact.\nAdditional Key Words and Phrases: CO2, emissions, cloud, carbon intensity, carbon awareness, grid\nACM Reference Format:\nJesse Dodge, Taylor Prewitt, Remi Tachet Des Combes, Erika Odmark, Roy Schwartz, Emma Strubell, Alexandra Sasha Luccioni, Noah\nA. Smith, Nicole DeCario, and Will Buchanan. 2022. Measuring the Carbon Intensity of AI in Cloud Instances. In 2022 ACM Conference\non Fairness, Accountability, and Transparency (FAccT ‚Äô22), June 21‚Äì24, 2022, Seoul, Republic of Korea. ACM, New York, NY, USA, 25 pages.\nhttps://doi.org/10.1145/3531146.3533234\nPermission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not\nmade or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party\ncomponents of this work must be honored. For all other uses, contact the owner/author(s).\n¬© 2022 Copyright held by the owner/author(s).\nManuscript submitted to ACM\n1\narXiv:2206.05229v1  [cs.LG]  10 Jun 2022\n\nFAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea Dodge et al.\n1 INTRODUCTION\nClimate change is an increasing threat to life on our planet, which disproportionately impacts the most disadvantaged\ncommunities and fragile ecosystems [28]. One of the main drivers of climate change is carbon dioxide, or CO2, which\ncontributes to the greenhouse effect by trapping the heat from the sun within the atmosphere without letting it dissipate.\nCO2 (and other types of greenhouse gases, such as methane and ozone) are emitted by many sources, some natural\nbut most man-made, such as the burning of oil and gas for transportation and heating or for industrial processes\nsuch as smelting. In 2018, it was estimated that global data center energy use represented close to 1% of global energy\nusage [27]. While it is not yet known what proportion of data center use is for training artificial intelligence (AI)\nmodels, it is undeniable that AI and its sub-fields have grown dramatically in recent years, with no sign of slowing\ndown [39, 43]. While a number of papers have addressed the CO2 emissions produced by AI (e.g., [23, 26, 33, 34]), the\nextent and provenance of CO2 emissions in the field is still under-explored. Nonetheless, a common theme of previous\nwork is that it aims to estimate the emissions produced by training AI models, or carrying out the accompanying\nneural architecture search (NAS) process, based on coarse measures such as CO2 emissions of electricity used in the\nregion where the computations were carried out (e.g., [42]), or post-hoc analyses using information that is not publicly\navailable (e.g., [34]).\nWith an increasing amount of AI model training being done on cloud compute instances, reducing the emissions\ngenerated by these workloads will be key to reducing our carbon footprint as a field. However, to reduce greenhouse gas\nemissions from cloud computing, we need consider the role of two types of actors: the cloud provider (such as Microsoft\nAzure, Google‚Äôs GCP, or Amazon‚Äôs AWS) and the user who reserves and uses cloud resources (e.g., an AI researcher\ntraining a model on a cloud instance, or a company hosting a website). Typically, the provider‚Äôs motivation is to build a\nsystem where users can access the computing power and storage that best meets their needs. The user, on the other\nhand, is motivated by some end task which requires computing power, such as running a set of experiments or putting\na model into production. Often the user will first consider the minimal computational requirements to achieve their\ngoals, then later ease-of-use features relating to transfer speed or extra storage depending on available budget. Driven\nby these motivations, providers and users can each take actions to meet their goals: providers can build data centers\nand set up APIs to enable users‚Äô access and accounting, while users can choose their cloud provider, which region to\nuse, and the number and type of cloud instances required for their end task at a given point in time. Based on these\nstakeholders and motivations, in this work we address the following research questions: 1) how should we measure and\nreport operational carbon costs of AI workloads? And 2) can we shift computation spatially and temporally to mitigate\nemissions?\nIn this article, we introduce the first tool to estimate the real-time CO2 emissions impact of instances on a cloud\ncomputing platform. The tool calculates operational carbon emissions by using location-based and time-specific marginal\nemissions data per energy unit. Using the tool, we explore several case studies on the Microsoft Azure cloud compute\nplatform spanning the areas of natural language processing (NLP) and computer vision, estimating the carbon intensity\nof training a variety of commonly used machine learning models. We also explore two avenues for users of cloud\ninstances to reduce their CO 2 using this tool by: (1) Changing the region of compute and (2) changing the time of\nday during which the model is run. While the former has been recognized by prior work [13, 23], we are the first to\naddress the latter to the best of our knowledge. Further, our tool makes it possible to automatically schedule jobs in\norder to reduce their carbon footprint by leveraging these differences in carbon intensity due to time and geographic\nlocation. Finally, we provide guidance regarding what should be measured and how, following the Green Software\n2\n\nMeasuring the Carbon Intensity of AI in Cloud Instances FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea\nFoundation‚Äôs guidelines regarding Software Carbon Intensity (SCI), and suggest future areas of research to improve the\nstate of carbon estimation and reporting in AI.\n2 RELATED WORK\nAttention was first drawn to the environmental impact of AI research by the seminal work of Strubell et al. [42], which\nquantified the emissions produced by training a Transformer model with Neural Architecture search, finding it to\nbe comparable to the lifetime carbon emissions of five cars. Patterson et al . [34] presented some updated analyses\nof similar experiments, including popular architectures like T5 [ 35] and BERT [ 8], analyzing CO 2 emissions as a\nfactor of their energy consumption, carbon intensity of training servers, etc. Other work such as Green AI [39] delved\nfurther into inequality of access to computational resources within the research community, and advocated for the\ninclusion of efficiency evaluation alongside accuracy as a primary evaluation criterion. Much existing and ongoing\nwork on quantifying the environmental footprint of ML has been focused on estimating the CO2 emissions of model\ntraining. This is a more straightforward endeavor compared to other stages both upstream and downstream from the\ntraining process, given that it is well-defined in time and its emissions can be measured in real-time with tools like\nCode Carbon [38] and Carbon Tracker [1] or estimated post-hoc using tools such as ML CO 2 Impact Tracker [23].\nOur tool builds upon this work by making carbon tracking on cloud instances possible, enabling a larger portion of\nML model training work to profit from fine-grained carbon estimation. However, recent work has found that their\nresults vary significantly and are not fully representative of the true emissions incurred by training [3]. Perhaps most\nsimilar to our work, EnergyVis [41] is an interactive tool for visualizing and comparing energy consumption of ML\nmodels as a function of hardware and physical location (U.S. state), given metadata about a model‚Äôs energy use per\nepoch. Other studies have gone beyond simply tracking the emissions from training models, aiming to quantify the\nemissions resulting from manufacturing computing hardware [15], the broader impacts of sustainable AI [49], and the\nmethodologies used to assess those impacts [21, 26]. Building upon this research, efforts have also been made to certify\nsystems as being socially- and environmentally-conscious [14], working towards comparing both the environmental\ncosts and potential benefits of AI models in order to paint a more holistic picture of AI.\nMajor technology companies have also been increasingly committed to reducing their emissions, largely via the\npurchase of Renewable Energy Credits (RECs), which involves directly buying quantities of energy produced by\nrenewable sources, translating into carbon reductions under the assumption that the clean energy is displacing an\nequivalent amount of electricity produced by non-renewable methods [11]. Many cloud providers, from Google Cloud\nPlatform to Microsoft Azure, therefore claim that they are now ‚Äúcarbon-neutral, ‚Äù given that they offset the entirety of\nthe emissions of their cloud centers, though we must be wary of the precise provenance of RECs, and the details of\nhow each organization defines ‚Äúzero‚Äù net emissions [36]. This is complemented by efforts to mitigate the actual CO2\nemissions of the compute regions themselves, with several server locations partially powered by renewable energy\nsources such as solar and wind [12, 29, 40] and giving users the necessary tools to pick compute regions with a smaller\ncarbon footprint [13, 17], which are often tied to the amount of low-carbon energy that is being purchased, and not the\ngrid emissions intensity. It is important to note that the decision on when and where to deploy a workload should be\nbased on a grid emissions signal, not the amount of emissions offset through market-based measures (e.g., green power\npurchase agreements (PPAs), renewable energy certificates (RECs), or other carbon offset mechanisms): purchasing\nclean energy is not the same as consuming clean energy.\n3\n\nFAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea Dodge et al.\n3 REPORTING AI CARBON INTENSITY\nCarbon accounting and reporting is becoming increasingly common in ML, with conferences such as NeurIPS requesting\nthat submissions report their emissions [31] and recent work reporting the emissions incurred [37, 44]. However, it\nhas yet to become the norm in our field, and we are still lacking systematic information regarding the environmental\nfootprint of training ML models and how we can reduce it. In this paper, we argue that if members of the ML community\nhad access to information about the CO2 emissions of their actions, they could adapt their decisions to reduce these\nemissions while still meeting the computational needs for their end tasks. In addition, providers building tools that\nenable users to track their CO2 emissions directly aligns with providers‚Äô goals, as it will inform users‚Äô decisions without\nbeing overly burdensome. Any cloud provider that discloses this information to users will, in fact, be improving those\ncustomers‚Äô experiences, and likely increase usage of the platform. More specifically, we propose that, for a cloud user\nwho wants to estimate their carbon footprint, the most salient information providers can report is the CO2 emissions\ngenerated by their cloud instances. Arguably the single most important contribution of this paper is the simplest: a\npresentation of the software carbon intensity (SCI) as a proxy for carbon emissions for a given cloud instance as it is\nrunning.\n3.1 Methodology: Computing CO 2 Intensity\nIn this section we describe a method for estimating carbon intensity for cloud instances. At a high level, this involves\ntracking electricity consumption of hardware related to a single cloud instance, and mapping that electricity usage to\nCO2 emissions by using a grid-based carbon intensity.\nAs developed by the Green Software Foundation, the Software Carbon Intensity (ùëÜùê∂ùêº ) is a rate, carbon emissions per\none functional unit, or R. The equation used to calculate the ùëÜùê∂ùêº value of a software system is therefore:\nùëÜùê∂ùêº = (( ùê∏ ‚àó ùêº ) + ùëÄ) per ùëÖ (1)\nwhere:\n‚Ä¢ ùê∏ = Energy consumed by a software system. Specifically, we focus on energy consumption of Graphical Processing\nUnits, or GPUs. The units used are kilowatt-hours (kWh).\n‚Ä¢ ùêº = Location-based marginal carbon emissions for the grid that powers the datacenter. WattTime provides\nmeasurements of grams of carbon dioxide equivalent per kilowatt-hour of electricity (gCO2eq/kWh)\n‚Ä¢ ùëÄ = Embodied carbon (also referred to as ‚Äúembedded carbon‚Äù) is the amount of carbon emitted during the\ncreation, usage, and disposal of a hardware device. When software runs on a device, a fraction of the total\nembodied emissions of the device is allocated to the software.\n‚Ä¢ ùëÖ = Functional unit. In this instance, we are defining the functional unit as one machine learning training job,\nbut it is extensible to other scenarios.\nThe equation can be further refined to:\nùëÜùê∂ùêº = (ùëÇ + ùëÄ) per ùëÖ (2)\nwhere ùëÇ = ùê∏ ‚àó ùêº calculates the operational emissions based on energy consumption (ùê∏) multiplied by the location-based\nand time-specific carbon intensity measurement (ùêº). Once more this can be further refined to simply:\nùëÜùê∂ùêº = ùê∂ per ùëÖ (3)\n4\n\nMeasuring the Carbon Intensity of AI in Cloud Instances FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea\nwhere ùê∂ = ùëÇ + ùëÄ is the software carbon intensity for a given cloud instance. In this paper, we focus on measuring\noperational emissionsùëÇ, and leave measurement and accounting for embodied emissions due to specialized ML hardware\nsuch as GPUs to future work (see ¬ß8).\nThe objective of the Green Software Foundation‚Äôs Software Carbon Intensity (SCI) specification is to calculate and\nreduce a SCI score, based on carbon emissions reductions, rather than the currently-used market-based neutralization.\nSpecifically, the SCI uses a \"consequential\" carbon accounting approach, which aims to quantify the marginal change in\nemissions caused by decisions or interventions. This differs from the commonly used \"attributional\" carbon accounting\napproach, which uses average carbon intensity data, meaning it does not provide the most actionable information to\nhelp reduce carbon emissions. Due to the myriad potential pitfalls of relying on market-based measures in place of\nactual reduction in emissions [36], it is not possible to reduce the SCI through carbon neutralization or carbon offsets.\nWe assert that cloud providers should provide the SCI to developers and data scientists to help them make choices that\nreduce the carbon footprint of their ML workloads.\n3.2 The Scope of our Tool: GPU Computation of a Single Cloud Instance\nData centers typically comprise many computer systems and hardware components, including storage, GPUs, CPUs,\nand networking components. We can break down the electricity usage for data centers into: 1) electricity that is used\nfor a single cloud instance, and 2) electricity that is used for the benefit of the whole data center. In this work we focus\non the former, a single cloud instance; because of this, a reader should understand that our estimates of the electricity\nconsumption and emissions are underestimates.1\nElectricity Consumption from a Single Cloud Instance. The most accurate and popular AI models today are typically\n(deep) neural networks, which are most performant on specialized, highly parallelized, and often energy-intensive\nhardware [43]. The most common scenario is for AI workloads to run on graphics processing units (GPUs), which provide\nsignificant acceleration compared to CPUs (central processing units) but are more power-hungry (often consuming\n250W-350W, compared to CPU consumption of 10-150W). Due to specialization to the matrix multiply operations at\nthe core of neural network computations and a high rate of parallelization, GPUs can perform many more of these\ntypes of computations in the same amount of time as a CPU, but this increased computation throughput comes at an\nincreased energy cost. Thus in ML applications based on deep learning, the majority of the electricity consumption\nis due to the GPU [ 5, 45]. While this result is fairly uncontroversial, we ran an experiment to confirm it. To do so,\nwe trained a BERT-base model [8] on a single NVIDIA TITAN X GPU (12 GB) in a commodity server with two Intel\nXeon E5-2630 v3 CPUs (2.4GHz) and 256GB RAM (16x16GB DIMMs) to measure the relative electricity consumption\nof different components. We trained the model using the original code provided by Devlin et al. [8] on the language\nmodel pre-training task for 12 hours on one GPU, sampling the instantaneous energy use of the GPU, CPU and DRAM\nfor each socket throughout that period, then averaging to get average power draw per component in watts. GPU\nenergy draw was measured using nvidia-smi and CPU and DRAM power draw were obtained using Intel‚Äôs RAPL.\nOur measurements, in watts, are presented in Table 1. As expected the GPU accounts for almost 3/4 of electricity\nconsumption.\nFocus on GPUs. In cloud datacenters, the CPUs, RAM, storage, and motherboards are often shared across multiple\ninstances; while this provides the flexibility that makes the cloud so useful, it leads to technical limitations that make it\n1There is related work on estimating and reducing the electricity of data centers in general, e.g., [10, 24].\n5\n\nFAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea Dodge et al.\nHardwa. GPU CPU0 CPU1 DRAM0 DRAM1 Total\nWatts 187.1 22.9 9.3 23.0 9.3 251.6\nFraction 74% 9% 4% 9% 4% 100%\nTable 1. The electricity consumption, in watts and percentages, when training BERT base on a single NVIDIA TITAN X GPU (12GB),\nin a commodity server with two Intel Xeon E5-2630 v3 CPUs (2.4GHz) and 256GB RAM (16x16GB DIMMs). Power consumption is\naveraged across instantaneous measurements over 12 hours of training on using the masked language modeling objective. The GPU\nalone accounts for 74% of the total energy consumption due to these components.\ndifficult (and in some cases impossible) to properly estimate electricity consumption from these sources for a single\ninstance. However, GPUs are typically not shared across instances, and in fact for large AI workloads it‚Äôs often the\ncase that multiple GPUs are attached to a single instance, leading to an even greater proportion of the total energy\nconsumption being used by the GPUs. Thus, it is relatively easy to measure the GPU electricity consumption for a\nsingle instance, while it is not for other components. For this reason, and because they typically consume the majority\nof electricity in AI workloads, in this work we only measure GPU electricity consumption. We recognize this is a first\nstep towards a more complete measurement, and provide further discussion in the next section.2\nOther sources of CO 2. Data centers have a number of electricity uses that are important, but will not be covered by\nour tool. According to the U.S. Department of Energy: ‚ÄúThe electricity consumed in these data centers is mainly by the\nequipment (50%) and HVAC (25%‚Äì40%)‚Äù [47]. Such other sources of emissions can be accounted for using methods\nsuch as Power Usage Effectiveness (PUE), which can be used to describe the proportion of electricity consumption\nby the computing equipment vs. other sources. For a given datacenter, this can be turned into a factor which can be\nmultiplied against the electricity consumption of computing equipment to get an estimate of the total consumption.\nSome companies have highlighted particularly low PUEs, such as Google claiming a PUE of 1.10 across its fleet of data\ncenters for the 12 months ending in Q1 2021,3 compared to an average global PUE of 1.59 [2].\nOther factors, such as the emissions produced by maintenance workers driving to and from the data center, emissions\nfrom manufacturing the computer systems, and emissions from building the structure in which the data center is\nhoused4 are non-negligible but beyond the scope of this paper. Finally, for workloads that do not use GPUs (e.g., storage\nor web hosting) we recommend users choose low emissions regions and times of day, as they will not have access to\nsingle-instance emissions calculations. We leave it open for future research to address how to appropriately allocate\nCO2 emissions from such data center-wide processes to individual reserved cloud instances.\n4 ELECTRICITY CONSUMPTION FOR AI WORKLOADS\nAs outlined in ¬ß3.1, calculating software carbon intensity begins with recording the electricity consumption, which\ncan then be mapped to emissions based on the emissions of the grid being used. In this section, we present data on\nelectricity consumption for experiments training 11 different models, covering natural language processing (NLP) and\ncomputer vision applications, ranging from less than an hour on a single GPU up to more than 8 days on 256 GPUs. We\noutline both the experiments themselves and their electricity consumption, and in the following section we use the\nelectricity consumption and carbon intensity tool described in the previous section to calculate their software carbon\nintensity.\n2We note that our conclusions drawn from experiments and analyses on time-shifting and location-shifting are still applicable with tools that measure\nmore electricity than just the GPU.\n3https://www.google.com/about/datacenters/efficiency/\n4One of the largest single source of CO2 emissions, contributing to 7%-8% of global emissions, is the production of cement [20].\n6\n\nMeasuring the Carbon Intensity of AI in Cloud Instances FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea\nModel BERT BERT 6B Dense Dense Dense ViT ViT ViT ViT ViT\nfinetune pretrain Transf. 121 169 201 Tiny Small Base Large Huge\nGPU 4¬∑V100 8¬∑V100 256¬∑A100 1¬∑P40 1¬∑P40 1¬∑P40 1¬∑V100 1¬∑V100 1¬∑V100 4¬∑V100 4¬∑V100\nHours 6 36 192 0.3 0.3 0.4 19 19 21 90 216\nkWh 3.1 37.3 13,812.4 0.02 0.03 0.04 1.7 2.2 4.7 93.3 237.6\nTable 2. For the 11 models in our analysis: the type of GPU, the number of GPUs of that type, the number of hours, and the energy\nused in kWh. For example, our BERT language modeling (BERT LM) experiment used 8 V100 GPUs for 36 hours and used a total of\n37.3 kWh. We note our training run of the 6 billion parameter transformer only trained for approximately 13% of the time it would\ntake to train to completion, we estimate a full training run would consume approximately 103,593 kWh.\n4.1 NLP\nBERT Training. We monitored the energy consumption while training a BERT-small model [8] for approximately 36\nhours on 8 NVIDIA V100 GPUs. That training run consumed over 37 kWh of electricity.\nBERT Finetuning. We tracked the energy consumption while finetuning the BERT-small model on a standard natural\nlanguage inference task [48, MNLI] for approximately 6 hours on 4 NVIDIA V100 GPUs. Our finetuning run consumed\naround 3.2 kWh of electricity, i.e., less than one tenth that due to BERT-small pre-training.\n6 Billion Parameter Transformer. We tracked the energy consumption of training a large language model comprising\nover 6.1 billion parameters during 8 days on 256 NVIDIA A100s. The total energy amounted to a staggering 13.8 MWh.\nThis model was not trained to completion, but only until 13%; a full training run would take 60 days. Thus, we estimate\nthe total energy consumption to train this model to completion would be approximately (60/8) ‚àó 13.8 = 103.5 MWh, or\n103,500 kWh ‚Äî almost 2800 times more than training the BERT-small model!\n4.2 Computer Vision\nDenseNets. We trained three sizes of DenseNets [19] on MNIST [25]. The jobs lasted between 20 and 25 minutes and\nconsumed between 20 and 38Wh (or 0.02 to 0.04 kWh) of electricity, which is negligible compared to the other models.\nVision Transformers. We evaluated the energy consumption during the training of five sizes of Vision Transformers [9]\non ImageNet [7]. For the smallest ViT experiment (ViT tiny), training lasted around 19 hours on a single V100 and\nconsumed approximately 1.7 kWh. For the largest one (ViT huge), training lasted more than 9 days on a 4 V100s and\nconsumed approximately 237 kWh. The full list of models can be found in Table 2.\n5 EMISSIONS BY REGION AND TIME OF DAY\nUsing the methodology presented above, we provide some of the first measurements of the differences of actual\ndatacenters from a major cloud provider. Importantly, what we have is a time series of marginal emissions: for example,\nif a job were to run from 1 pm to 5 pm in the US West region with a cloud instance that has four fully-utilized GPUs, both\nthe energy consumed and the marginal carbon intensity during that time is what we want to record. This time-series\ndata can estimate the cumulative emissions for that experiment at the end.\n5.1 Region\nHow much does the choice of datacenter region impact the emissions? And for a single region, how much variation\noccurs throughout the year? We address these questions in Figure 1, which shows carbon emissions that would be\n7\n\nFAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea Dodge et al.\nFig. 1. Carbon emissions that would be emitted from training BERT (language modeling on 8 V100s for 36 hours) in 16 different\nregions (one region per line) at different times throughout the year. Each line is relatively flat, indicating the emissions in a single\nregion during different months are relatively similar. There is large variation between the least carbon-intensive regions (the lowest\nlines) compared to the most carbon-intensive regions (the top lines), indicating that choosing the region in which experiments run\ncan be very impactful ( 7k grams vs. 26k grams, for the most efficient vs. least efficient regions).\nemitted from training BERT (see ¬ß4 for more details) on 8 V100 GPUs for 36 hours in 16 different regions (one region\nper line) at different times throughout the year.\nWhat do emissions look like across the 11 experiments described in ¬ß4? In Figure 2 we show results for all 11\nexperiments, which cover two BERT experiments (finetuning and language modeling), partial training of a 6.1 billion\nparameter Transformer, 3 sizes of DenseNets, and five sizes of Vision Transformers. Each experiment is represented by\na vertical blue bar showing the range of emissions that would be emitted for that experiment across different regions.\nThe top of the blue bar is the emissions from running that experiment in the region with the most emissions, the bottom\nis the emissions from running that experiment in the region with the least emissions, the black line represents the\naverage, and the light blue regions are the top and bottom quartiles.\nIn Figure 2 we also include estimates of equivalent sources of emissions per the United States Environmental\nProtection Agency [46]. One phone charge is estimated to emit 8.22 √ó 10‚àí6 metric tons (using US national weighted\naverage CO2 marginal emission rate for delivered electricity), one mile driven is estimated to emit 3.98 √ó 10‚àí4 metric\ntons (using average US passenger vehicle, which gets 22.5 miles per gallon of gasoline), one gallon of gasoline consumed\nis estimated to emit 8.887 √ó 10‚àí3 metric tons, one barrel of crude oil consumed is estimated to emit 0.43 metric tons,\none average US home energy use is estimated to emit 8.30 metric tons (using the sum of emissions from generating\nelectricity, natural gas, liquid petroleum, and fuel oil), and one rail car of coal is estimated to emit 181.29 metric tons.\n8\n\n[Image page=8 idx=1 name=Im1.png] Size: 2942x1683, Data: 515704 bytes\n\nMeasuring the Carbon Intensity of AI in Cloud Instances FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea\nFig. 2. Emissions for our 11 experiments described in ¬ß4. For each model we show a vertical blue bar, where the top of the bar is\nthe max, the bottom is the min, and the black line represents the average emissions (across regions and time of year). First and\nfourth quartiles are represented by the light blue at the top and bottom of each vertical blue bar. The largest training runs (e.g., 6\nbillion parameter LM) releases a significant amount of emissions, no matter the region (and recall the 6 billion parameter LM is only\ntrained for 13% of a full run, so a full run would emit about an order of magnitude more emissions than reported here). The smallest\nexperiments emit very little. Presented on a log scale, with references on the right indicating equivalent sources of emissions per the\nUnited States Environmental Protection Agency [46].\nThe largest experiment in our set is the 6 billion parameter transformer, and that model is only partially trained (as\ndescribed in ¬ß4, it is only trained for about 13% of the time needed to converge). Even partially trained, experiments of\nthis size can emit more CO2 than all emissions from the average US home for a year (which includes emissions from\nelectricity generation, natural gas, liquid petroleum gas, and fuel oil, totaling 8.3 metric tons CO2 per year). Perhaps\nunsurprisingly, even the most efficient region of those we examined for that experiment still leads to more emissions\nthan a full barrel of oil. If this had been trained to completion, we estimate it would have emitted 21 to 78 metric tons of\nCO2 (depending on the region it was run in).\nComparing against previous work on measuring emissions can be challenging without full information about data\nand model parallelism, GPU utilization, the number of weight updates, and other relevant factors; while we don‚Äôt have\nexperiments covering the same models as previous work on estimating CO2, we can make approximate comparisons\nalong three dimensions: a) kWh per GPU hour, b) CO 2 grams per GPU hour, and c) CO 2 grams per kWh. Here we\ncompare against [34] and [33] which report information about training especially large models. Their estimates also\n9\n\n[Image page=9 idx=1 name=Im2.png] Size: 2814x1943, Data: 175292 bytes\n\nFAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea Dodge et al.\ninclude additional sources of CO2, like PUE (Power Usage Effectiveness) of their datacenters, so we expect their kWh per\nGPU hour and CO2 per GPU hour to be higher than our estimates (which only count the GPU electricity consumption).\nAcross our experiments, we find kWh per GPU hour to range from 0.07 to 0.28, compared to Patterson et al. [34]\nwith 0.22 to 0.47, and Patterson et al. [33] with 0.36. We find CO2 (grams) per GPU hour in the most efficient region to\naverage 34, and in the least efficient region to average 128, where Patterson et al. [34] found a range of 63 to 202, and\nPatterson et al. [33] found 32. We find CO2 (grams) per kWh in the most efficient region to average 200, and in the least\nefficient region to average 755. The estimates from Patterson et al. [34] range between 427 and 545 (except GShard 600B\nwith 200), and Patterson et al. [33] found 88. In short, we find most of their estimates to be within the range of ours,\nwith the exception of Patterson et al. [33], which specifically aimed to choose a region that was more CO2 efficient.\nHour 0:00 03:00 06:00 09:00 12:00 15:00 18:00 21:00\nBERT Central Day 1 2,381 2,341 2,210 2,252 2,354 2,391 2,410 2,403\nfinetune US Day 2 2,330 2,249 2,204 2,299 2,320 2,317 2,339 2,344\nDay 3 2,430 2,339 2,257 2,313 2,393 2,374 2,317 2,331\nTable 3. How do emissions vary throughout different times of day? We present the emissions produced by the BERT finetuning\nexperiment described in ¬ß4 had it run at different times in the Central US region, on three separate days.\n5.2 Time of Day\nWhile the choice of region is a major source of variation in CO 2 emissions, diurnal variations also play a signifi-\ncant role. During the day, a region may have a higher mix of renewable energy or fossil-fuel based source [ 6]. As\none can see in Table 3, depending on the day, starting the BERT finetuning at, e.g., midnight instead of 6:00 can\nresult in carbon emissions increasing by up to 8%. The amount of variation varies by region and time of year as\nwell.\n6 OPTIMIZING CLOUD WORKLOADS\nWe use the tools presented so far to evaluate two algorithms for reducing emissions of AI workloads on the Microsoft\nAzure cloud compute platform using temporal shifting. We consider sixteen regions where workloads can be scheduled\non Azure: nine in North America, six in Europe and one in Australia (see Figure 3). For each region, we obtained from\nWattTime the historical marginal carbon emissions for the year 2020 at a 5-minute granularity. We also measured the\nelectricity consumption per 5-minute intervals of the various models introduced in ¬ß4. The two optimization methods\nwe studied are:\n‚Ä¢ Flexible Start. Start the workload at the time, in the next ùëÅ hours, that minimizes its carbon emissions. Once the\nworkload is launched, it is run until completion. Implementation: Consider all possible start times (in 5 minute\nincrements) in the desired window. For each start time, compute the job‚Äôs corresponding emissions and pick the\nlowest.\n‚Ä¢ Pause and Resume . Assuming the workload can be stopped and restarted (a fairly weak constraint), run its\ncomputations over the next (ùëÅ + job duration) hours while minimizing its total carbon emissions. This involves\npausing and resuming the job, possibly multiple times, to avoid consuming energy when carbon intensity is high.\nImplementation: Find the 5 minute intervals with the lowest marginal emissions during the (ùëÅ + job duration)\nhour window, and select enough intervals to add up to the job duration. Then simulate running the job only\n10\n\nMeasuring the Carbon Intensity of AI in Cloud Instances FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n10\n20\n30\n40\n50\n60\n70\n80CO2 emissions decrease in %\n6h\n12h\n18h\n24h\n(a) Flexible Start optimization for Dense 201.\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\n1.2\n1.4CO2 emissions decrease in %\n6h\n12h\n18h\n24h (b) Flexible Start optimization for 6B parameters Transformer.\nFig. 3. What proportion of emissions can we expect to save if we change the start time by up to 24 hours? For very short experiments\nlike DenseNet 201 (a), which ran for less than half an hour, we can find significant reduction, greater than 30% in multiple regions,\nand up to 80% in West US; for very long runs like training a 6 billion parameter language model for 8 days (b), changing the start time\nby up to 24 hours leads to less than 1.5% reduction at best in any region. Note: we confirmed with WattTime that emissions estimates\nfor West US were correct, that region has large variance.\nduring those intervals and compute the corresponding emissions. We explored two sets of values for ùëÅ : one\nabsolute, corresponding to increasing the total duration of the job by at most {6, 12, 18, 24} hours; and a second\none relative, where we allow the job to increase in duration by at most {25%, 50%, 75%, 100%}. In other words,\nfor the second set, we allow the workload to last for at most twice its duration had it not been stopped. While\narbitrary, we motivate the choice of those two sets by the extreme range of possible job duration (from minutes to\nweeks). Note that we assume pausing and restarting the job is immediate and does not consume additional energy:\nthis is similar in spirit (for carbon emissions) to Spot Instances on existing cloud platforms which automatically\npause an instance if its price rises above a threshold set by the user.\nWe find the region that the algorithms are evaluated in has a significant impact. For example, the region we labeled\nWest US varies frequently throughout a single day between periods of high emissions and very low emissions, and\nthus Pause and Resume can lead to significant reductions. However, other regions do not present as much variance,\nand thus lead to less reduction in emissions. See Figures 3 and 4. The lack of geographic diversity in the region list is\nan unfortunate consequence of the unavailability of carbon intensity data from other continents; we hope such data\nbecomes broadly available in the near future.\n6.1 Evaluation of Emissions Reduction Algorithms\nWe evaluate how the two optimization algorithms would impact the emissions from the 11 experiments described in ¬ß4.\nIn order to account for daily variations (weather, electricity demand, etc.), we report the average emissions decrease\ncomputed over 5 different start times in each month, giving a total of 60 data points.\n6.1.1 Emissions Reduction by Region.\nFlexible Start. When evaluating the Flexible Start algorithm for a fixed duration between 6 hours and 24 hours, we\nfind significant emissions reductions for shorter jobs (e.g., the DenseNet experiments), with minimal savings for jobs\n11\n\nFAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea Dodge et al.\nthat are longer than a day; this aligns with our expectations, as short jobs can be run when emissions are lowest\nthroughout a day, but long jobs naturally average across multiple days. See Figure 3, with results for all experiments\nin the appendix. This analysis is designed to highlight a use case where an AI workload needs to run regularly, but\nthe practitioner has some flexibility on when it runs (so it could, e.g., run over night, if that is when carbon intensity\nis lowest). This is in fact a common use case in production ML systems deployed at companies, where models are\nre-trained on a regular schedule to incorporate new data over time [16].\nPause and Resume. When evaluating the Pause and Resume algorithm for durations up to 100% of the duration of the\noriginal experiment, we find the opposite of the Flexible Start result: short experiments like DenseNet 201 only see\nemissions reductions smaller than 10%, while the 6 billion transformer training run (our experiment with the largest\ncarbon intensity) actually sees the largest decrease in emissions. See Figure 4 for two examples, with results for all 11\nexperiments in the appendix. This analysis is designed to highlight a use case where an AI workload can be increased\nin duration by some proportion of the original run time.\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n1\n2\n3\n4\n5\n6\n7\n8CO2 emissions decrease in %\n25%\n50%\n75%\n100%\n(a) Pause and Resume optimization for Dense 201.\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n5\n10\n15\n20\n25\n30CO2 emissions decrease in %\n25%\n50%\n75%\n100% (b) Pause and Resume optimization for 6B parameters Transformer.\nFig. 4. What proportion of emissions can we expect to save if we pause an AI workload when emissions in a region are high and\nresume when emissions are low, increasing the total duration by up to double the original duration? For short experiments, the\ndoubled duration is still relatively short, and thus leads to minimal emissions reduction (see DenseNet 201 in (a)); for very long runs\nlike our 6 billion parameter language model training run in (b), which ran for 8 days, doubling the duration can lead to significant\nsavings up to about 25%. We confirmed with WattTime that emissions estimates for West US were correct, as that region has large\nvariance.\n6.1.2 Comparable Duration Increases. In the previous section we examined the amount of emissions reduction for\nour two algorithms by region, and compared Pause and Resume increasing duration by a proportion of the original\nexperiment and Flexible Start by a fixed duration. Here we evaluate the two algorithms when they increase the duration\nof an AI workload by the same amount (each result is averaged across all regions and times of year). One can think\nof the Flexible Start algorithm as a version of Pause and Resume where there is only one start time, and no pausing\nallowed; thus we should expect the Flexible Start results to always lower bound the Pause and Resume ones.\nWe show results for both algorithms and two situations: increasing the duration of the run by 24 hours in Table 4,\nand by 100% in Table 5. In these tables we also include information about the average number of pauses per hour for\nthe Pause and Resume algorithm. Perhaps surprisingly, we find the average number of pauses is quite low. This can be\n12\n\nMeasuring the Carbon Intensity of AI in Cloud Instances FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea\ninterpreted as the number of times the carbon intensity crosses above the threshold minimizing total emissions being\nsmall.\nModel BERT BERT 6B Dense Dense Dense ViT ViT ViT ViT ViT\nfinetune LM Transf. 121 169 201 Tiny Small Base Large Huge\nFS 14.5% 3.4% 0.5% 26.8% 26.4% 25.9% 5.6% 5.3% 4.2% 1.3% 0.5%\nP&R 19.0% 8.5% 2.5% 27.7% 27.3% 27.1% 12.5% 12.3% 11.7% 4.7% 2.4%\nPauses / hr 0.23 0.3 0.15 0.06 0.07 0.08 0.3 0.3 0.3 0.23 0.14\nTable 4. For the 11 models in our analysis: the gain in percent averaged over the year and across the 16 regions for the Flexible Start\n(FS) and Pause and Resume (P&R) optimizations allowing for a 24h increase in job duration. The last line represents the average\nnumber of pauses per hour performed by the P&R optimization.\nNote that the above optimizations were performed using historical data, meaning that their results are the best\nachievable, assuming access to an oracle predicting carbon intensity perfectly. WattTime currently provides marginal\nemission rate estimates and forecasts for up to 24 hours, so for short workloads, our findings will reflect gains observed\nin practice using the forecasts. For longer workloads, our numbers give an upper bound on the realizable gains. For\nexample, the Pause and Resume algorithm pauses the workload when emissions are above a threshold, and resumes\nwhen emissions are below that threshold. In our evaluation here we set this threshold such that the total run time is\nincreased by, e.g., 24 hours; a machine learning practitioner would have to estimate how much a particular threshold\nwould increase job duration, but would not know exactly. The dynamic nature of the Pause and Resume optimizations\nsuggests that well-designed scheduling algorithms should be able to get rather close to the upper-bound. We leave such\nalgorithms to future work and hope our tools can inspire further research into that type of scheduling. Moreover, it is\nlikely that carbon intensity forecasting will improve over the years and eventually extend beyond 24 hours, allowing\ntime-shifting decisions to become increasingly accurate.\nModel BERT BERT 6B Dense Dense Dense ViT ViT ViT ViT ViT\nfinetune LM Transf. 121 169 201 Tiny Small Base Large Huge\nFS 7.0% 4.1% 2.6% 1.8% 2.5% 2.7% 5.0% 4.8% 3.9% 3.3% 3.0%\nP&R 9.5% 11.0% 11.4% 2.0% 2.8% 3.1% 11.0% 11.0% 10.8% 11.4% 11.3%\nPauses / hr 0.42 0.29 0.27 1.5 1.88 2.0 0.31 0.32 0.31 0.27 0.26\nTable 5. For the 11 models in our analysis: the gain in percent averaged over the year and across the 16 regions for the Flexible Start\n(FS) and Pause and Resume (P&R) optimizations allowing for a 100% increase in job duration. The last line represents the average\nnumber of pauses per hour performed by the P&R optimization.\n7 CONSIDERATIONS FOR MODEL DEVELOPMENT AND DEPLOYMENT\nGenerally speaking, we advocate that researchers and practitioners record and report the amount of emissions incurred\nby ML projects, starting with the initial exploratory training phases all the way through hyperparameter tuning and\ndeployment for the final model. This can inform an Operational Lifecycle Analysis (OLCA) for a machine learning\nmodel, which would account for all phases of the ML lifecycle. In the subsections below, we outline some ways in which\nthe proposed tool can be used at different stages of the model development and deployment process, and describe some\nenvironmental impacts due to ML modeling that are outside the scope of measurement of this tool.\n13\n\nFAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea Dodge et al.\nWe see various ways in which our tool can help guide model training, for instance via carbon-informed optimization\n(similarly to what [22] proposed for energy efficiency in federated learning), or for cloud-based recommendations that\nenable users to opt-in for carbon-aware configurations (in terms of region, time, etc.) to reduce the carbon intensity of\ntheir training workloads. We believe that tracking and reducing greenhouse gas emissions can be a very important\nfeature for users deciding on how they will set up their cloud usage, but we recognize that there are natural trade-offs\nthat must be considered. We therefore recommend that the measurements provided by our tool be used to guide\ninformed decisions alongside other considerations as part of a holistic approach, and not as a single gold standard\nto optimize against. For example, even just within the scope of ML model development, it often takes engineering\ntime to optimize a workload to be more efficient (i.e., use less computational resources), and a user should consider\nwhether that time would be better spent elsewhere (e.g., transferring the workload to another region with lower average\nemissions). Furthermore, some projects have strict time constraints, and so scheduling jobs to only run at night would\nsignificantly delay progress, potentially leading to more emissions in other parts of the project. Thus, our suggestions\nare not meant as a one-size-fits-all solution which will eliminate carbon emissions, but instead as a set of options which\ncan be referenced by users and decided upon on a case-by-case basis. Finally, there are also many additional upstream\nand downstream emissions considerations due to the ML model lifecycle, due to, e.g., hardware manufacturing and\ndownstream uses or misuses of the model, that could eclipse the direct emissions due to model training alone. See ¬ß2\nfor further discussion of this crucial point.\nAnother important consideration is operating cost; it could be the case that Region A is lower emissions but higher\ncost than Region B for a particular workload, and thus a user could run their workload in Region B and have some\nbudget left over that could be used for other reductions in emissions. A final consideration is cost of data transfer; it\ncould be the case that Region A is lower emissions and monetary cost than Region B for a particular workload, but the\nenergetic, environmental, or monetary cost of moving the data could exceed the benefits gained.\nIf we see broad adoption of such reporting tools, we may see increases in cloud use in regions which have low\nemissions. In such a scenario, providers could be incentivized to build new data centers, and providers should consider\nthe local impact of such construction.\n8 FUTURE DIRECTIONS\nAs mentioned in ¬ß7, single-instance emissions are a well-defined starting place for quantifying, mitigating, and reducing\nthe environmental impact due to ML, but do not present a complete picture of the total emissions that should be\naccounted for when considering the overall carbon emissions of the ML life cycle. Here are some aspects that are yet to\nbe accounted for (and in some cases, yet to be defined) in terms of the overall OLCA of machine learning:\nScopes of emissions. The Greenhouse Gas Protocol (GHGP) is a standard created by the World Resources Institute\nand the Business Council for Sustainable Development, and has seen broad adoption internationally. It defines Scope 1,\nScope 2, and Scope 3 emissions as follows: Scope 1 emissions are those generated by direct actions of a company, such as\nrunning motor vehicles; Scope 2 emissions are those associated with purchase of electricity, steam, heating, or cooling;\nand Scope 3 emissions are those that the company indirectly participates in, such as those due to investments of the\ncompany and downstream use of products. In the present work, we have focused on the Scope 2 emissions incurred\ndue to electricity usage by cloud providers. The current GHGP Scope 2 is an attributional guidance that precludes the\nuse of marginal emissions rates, and primarily focuses on broad generation-based average rates. It is important to note\n14\n\nMeasuring the Carbon Intensity of AI in Cloud Instances FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea\nthat the GHGP Scope 2 guidance is incompatible with the proposed method; this paper illustrates the need to revisit the\nScope 2 guidance to better align with consequential accounting methods.\nWe do not cover the Scope 1 emissions (e.g. emissions that directly result from business activities, such as stationary\ncombustion of fuels for backup power generation in cloud datacenters), for a more detailed discussion see e.g. Gupta\net al. [15], nor the Scope 3 emissions (e.g. emissions that indirectly result from all other business activities, such as\nthose associated with the upstream raw materials extraction, manufacturing, and delivery of cloud-based IT asset\ninfrastructure such as servers from suppliers to be used in a cloud provider‚Äôs datacenters). Both of these types of\nemissions warrant discussion and debate by the AI community‚Äî and indeed some work has begun on the subject,\ne.g., [21, 26]‚Äîbut we are missing a more concrete structure for categorizing, quantifying and mitigating the different\nscopes of emissions in our field. This would involve the active participation of specific stakeholders to establish the\ntooling and reporting required to better estimate these aspects, which is a challenge in itself.\nDeveloping certification systems for ‚ÄúGreen AI‚Äù. While initiatives like the Green Software Foundation are making\nimportant progress towards measuring and mitigating the carbon footprint of software in general, the decentralized\nand data-driven nature of ML will call for specific approaches and guidelines to ensure its efficiency. We anticipate that\nAI-specific initiatives, spanning both research and academia, will help establish certification systems (or badge systems)\nthat will allow both model developers and users make more informed choices with regards to sustainability. The current\nframing of Scopes 1, 2, and 3 may not encompass all the emissions reasonably associated with an AI program.\nImproving the carbon transparency of research and practice. Despite the existence of tools such as Code Carbon [38]\nand EvergyVis [41], both carbon estimation and reporting in ML publications and technical reports remain a relatively\nrare phenomenon. Conferences such as NeurIPS and NAACL have recently added emissions reporting as an optional part\nof the submission process; however, more encouragement will be necessary for this to become commonplace. Gathering\nmore data about the environmental impact of our field is a crucial step towards identifying room for improvement and,\neventually, reducing our emissions.\nSupporting improved estimates of emissions rates. The estimates of emissions rates providers would benefit from more\nand better data being provided by electric system operators. This is particularly true in areas of the world where it is\ncurrently not possible to produce hourly marginal estimates.\nReducing AI‚Äôs scope-enabled emissions. Responsible development and application of AI must account not only for the\nhidden costs of development, as discussed in this paper, but for the positive or negative carbon impact the application\nenables. AI models continue to be used for oil exploration [ 32], deforestation [30], and mining [ 18], among other\nenvironmentally-detrimental practices. When considering the net impacts of an AI application, it is imperative to\ndetermine the extent to which AI is incentivizing practices that have a negative impact on the environment, or the\nextent to which applications are directly reducing emissions or otherwise incentivizing practices that are beneficial to\nthe climate, and take these downstream direct and indirect effects into account in the overall environmental impact\nassessment of our field [4, 21].\nACKNOWLEDGMENTS\nWe thank Avi Allison (Microsoft) for insights associated with carbon accounting and Location-based Marginal Emissions\n(LME) data, Henry Richardson (WattTime) for insights on LME data and the Software Carbon Intensity (SCI) specification,\nAbhishek Gupta for his work on the SCI specification, and Ananya Ganesh (CU Boulder) for help in obtaining the\n15\n\nFAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea Dodge et al.\nmeasurements included in Table 1. We also thank Alessandro Sordoni, Payal Bajaj, and Vibhav Vineet for sharing their\ntraining and inference jobs, and Jon Borchardt for help with plotting.\nREFERENCES\n[1] Lasse F. Wolff Anthony, Benjamin Kanding, and Raghavendra Selvan. 2020. Carbontracker: Tracking and Predicting the Carbon Footprint of\nTraining Deep Learning Models. arXiv:2007.03051 [cs.CY]\n[2] Rhonda Ascierto and A Lawrence. 2020. Uptime institute global data center survey 2020. Uptime Institute 2 (2020).\n[3] Nesrine Bannour, Sahar Ghannay, Aur√©lie N√©v√©ol, and Anne-Laure Ligozat. 2021. Evaluating the carbon footprint of NLP methods: a survey and\nanalysis of existing tools. In EMNLP, Workshop SustaiNLP.\n[4] Abeba Birhane, Pratyusha Kalluri, Dallas Card, William Agnew, Ravit Dotan, and Michelle Bao. 2021. The values encoded in machine learning\nresearch. arXiv preprint arXiv:2106.15590 (2021).\n[5] Buildcomputers.net. 2021. Power Consumption of PC Components in Watts. https://www.buildcomputers.net/power-consumption-of-pc-\ncomponents.html\n[6] Jacques A de Chalendar and Sally M Benson. 2019. Why 100% renewable energy is not enough. Joule 3, 6 (2019), 1389‚Äì1393.\n[7] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. 2009. Imagenet: A large-scale hierarchical image database. In2009 IEEE conference\non computer vision and pattern recognition . Ieee, 248‚Äì255.\n[8] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language\nUnderstanding. arXiv:1810.04805 [cs.CL]\n[9] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias\nMinderer, Georg Heigold, Sylvain Gelly, et al. 2020. An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint\narXiv:2010.11929 (2020).\n[10] Jim Gao. 2014. Machine learning applications for data center optimization. (2014).\n[11] Michael Gillenwater. 2008. Redefining RECs‚ÄîPart 1: untangling attributes and offsets. Energy Policy 36, 6 (2008), 2109‚Äì2119.\n[12] Google. 2021. Carbon free energy for Google Cloud regions. https://cloud.google.com/sustainability/region-carbon\n[13] Google. 2021. Helping you pick the greenest region for your Google Cloud resources. https://cloud.google.com/blog/topics/sustainability/pick-the-\ngoogle-cloud-region-with-the-lowest-co2\n[14] Abhishek Gupta, Camylle Lanteigne, and Sara Kingsley. 2020. SECure: A Social and Environmental Certificate for AI Systems. arXiv preprint\narXiv:2006.06217 (2020).\n[15] Udit Gupta, Young Geun Kim, Sylvia Lee, Jordan Tse, Hsien-Hsin S Lee, Gu-Yeon Wei, David Brooks, and Carole-Jean Wu. 2021. Chasing Carbon:\nThe Elusive Environmental Footprint of Computing. In 2021 IEEE International Symposium on High-Performance Computer Architecture (HPCA) .\nIEEE, 854‚Äì867.\n[16] K. Hazelwood, S. Bird, D. Brooks, S. Chintala, U. Diril, D. Dzhulgakov, M. Fawzy, B. Jia, Y. Jia, A. Kalro, J. Law, K. Lee, J. Lu, P. Noordhuis, M.\nSmelyanskiy, L. Xiong, and X. Wang. 2018. Applied Machine Learning at Facebook: A Datacenter Infrastructure Perspective. In2018 IEEE International\nSymposium on High Performance Computer Architecture (HPCA) . 620‚Äì629. https://doi.org/10.1109/HPCA.2018.00059\n[17] Kees Hertogh. 2021. Empowering cloud sustainability with the Microsoft Emissions Impact Dashboard. https://azure.microsoft.com/en-\nus/blog/empowering-cloud-sustainability-with-the-microsoft-emissions-impact-dashboard/\n[18] Zeshan Hyder, Keng Siau, and Fiona Nah. 2019. Artificial intelligence, machine learning, and autonomous technologies in mining industry. Journal\nof Database Management (JDM) 30, 2 (2019), 67‚Äì79.\n[19] Forrest Iandola, Matt Moskewicz, Sergey Karayev, Ross Girshick, Trevor Darrell, and Kurt Keutzer. 2014. Densenet: Implementing efficient convnet\ndescriptor pyramids. arXiv preprint arXiv:1404.1869 (2014).\n[20] International Energy Authority (IEA). 2020. Energy Technology Perspectives 2020. https://www.iea.org/reports/energy-technology-perspectives-\n2020\n[21] Lynn Kaack, Priya Donti, Emma Strubell, George Kamiya, Felix Creutzig, and David Rolnick. 2021. Aligning artificial intelligence with climate\nchange mitigation. (2021).\n[22] Young Geun Kim and Carole-Jean Wu. 2021. AutoFL: Enabling Heterogeneity-Aware Energy Efficient Federated Learning. InMICRO-54: 54th Annual\nIEEE/ACM International Symposium on Microarchitecture . 183‚Äì198.\n[23] Alexandre Lacoste, Alexandra Luccioni, Victor Schmidt, and Thomas Dandres. 2019. Quantifying the carbon emissions of machine learning. arXiv\npreprint arXiv:1910.09700 (2019).\n[24] Nevena Lazic, Tyler Lu, Craig Boutilier, MK Ryu, Eehern Jay Wong, Binz Roy, and Greg Imwalle. 2018. Data center cooling using model-predictive\ncontrol. (2018).\n[25] Yann LeCun, L√©on Bottou, Yoshua Bengio, and Patrick Haffner. 1998. Gradient-based learning applied to document recognition. Proc. IEEE 86, 11\n(1998), 2278‚Äì2324.\n[26] Anne-Laure Ligozat, Julien Lef√®vre, Aur√©lie Bugeau, and Jacques Combaz. 2021. Unraveling the hidden environmental impacts of AI solutions for\nenvironment. arXiv preprint arXiv:2110.11822 (2021).\n16\n\nMeasuring the Carbon Intensity of AI in Cloud Instances FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea\n[27] Eric Masanet, Arman Shehabi, Nuoa Lei, Sarah Smith, and Jonathan Koomey. 2020. Recalibrating global data center energy-use estimates. Science\n367, 6481 (2020), 984‚Äì986.\n[28] Val√©rie Masson-Delmotte, Panmao Zhai, Hans-Otto P√∂rtner, Debra Roberts, Jim Skea, Priyadarshi R Shukla, Anna Pirani, Wilfran Moufouma-Okia,\nClotilde P√©an, Roz Pidcock, et al. 2018. Global warming of 1.5 C. An IPCC Special Report on the impacts of global warming of 1, 5 (2018).\n[29] Microsoft Azure. 2021. Azure sustainability. https://azure.microsoft.com/en-us/global-infrastructure/sustainability/#overview\n[30] Vasilii Mosin, Roberto Aguilar, Alexander Platonov, Albert Vasiliev, Alexander Kedrov, and Anton Ivanov. 2019. Remote sensing and machine\nlearning for tree detection and classification in forestry applications. InImage and Signal Processing for Remote Sensing XXV , Vol. 11155. International\nSociety for Optics and Photonics, 111550F.\n[31] NeurIPS 2021 Conference. 2021. NeurIPS 2021 Paper Checklist Guidelines. https://neurips.cc/Conferences/2021/PaperInformation/PaperChecklist\n[32] Vito Alexander Nordloh, Anna Roub√≠ckov√°, and Nick Brown. 2020. Machine Learning for Gas and Oil Exploration. arXiv preprint arXiv:2010.04186\n(2020).\n[33] David Patterson, Joseph Gonzalez, Urs H√∂lzle, Quoc Le, Chen Liang, Lluis-Miquel Munguia, Daniel Rothchild, David So, Maud Texier, and Jeff Dean.\n2022. The Carbon Footprint of Machine Learning Training Will Plateau, Then Shrink. TexRxiv (2022).\n[34] David Patterson, Joseph Gonzalez, Quoc Le, Chen Liang, Lluis-Miquel Munguia, Daniel Rothchild, David So, Maud Texier, and Jeff Dean. 2021.\nCarbon emissions and large neural network training. arXiv preprint arXiv:2104.10350 (2021).\n[35] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 2019. Exploring the\nlimits of transfer learning with a unified text-to-text transformer. arXiv preprint arXiv:1910.10683 (2019).\n[36] Joeri Rogelj, Oliver Geden, Annette Cowie, and Andy Reisinger. 2021. Net-zero emissions targets are vague: three ways to fix. Nature 591 (2021),\n365‚Äì368.\n[37] Victor Sanh, Albert Webson, Colin Raffel, Stephen H Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven Le Scao, Arun\nRaja, et al. 2021. Multitask prompted training enables zero-shot task generalization. arXiv preprint arXiv:2110.08207 (2021).\n[38] Victor Schmidt, Kamal Goyal, Aditya Joshi, Boris Feld, Liam Conell, Nikolas Laskaris, Doug Blank, Jonathan Wilson, Sorelle Friedler, and Sasha\nLuccioni. 2021. CodeCarbon: Estimate and Track Carbon Emissions from Machine Learning Computing.\n[39] Roy Schwartz, Jesse Dodge, Noah A Smith, and Oren Etzioni. 2020. Green AI. Commun. ACM 63, 12 (2020), 54‚Äì63.\n[40] Amazon Web Services. 2021. Sustainability in the Cloud. https://sustainability.aboutamazon.com/environment/the-cloud\n[41] Omar Shaikh, Jon Saad-Falcon, Austin P Wright, Nilaksh Das, Scott Freitas, Omar Asensio, and Duen Horng Chau. 2021. EnergyVis: Interactively\nTracking and Exploring Energy Consumption for ML Models . Association for Computing Machinery, New York, NY, USA. https://doi.org/10.1145/\n3411763.3451780\n[42] Emma Strubell, Ananya Ganesh, and Andrew McCallum. 2019. Energy and policy considerations for deep learning in NLP. arXiv preprint\narXiv:1906.02243 (2019).\n[43] Neil C Thompson, Kristjan Greenewald, Keeheon Lee, and Gabriel F Manso. 2020. The computational limits of deep learning. arXiv preprint\narXiv:2007.05558 (2020).\n[44] Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du,\nYaGuang Li, Hongrae Lee, Huaixiu Steven Zheng, Amin Ghafouri, Marcelo Menegali, Yanping Huang, Maxim Krikun, Dmitry Lepikhin, James Qin,\nDehao Chen, Yuanzhong Xu, Zhifeng Chen, Adam Roberts, Maarten Bosma, Yanqi Zhou, Chung-Ching Chang, Igor Krivokon, Will Rusch, Marc\nPickett, Kathleen Meier-Hellstern, Meredith Ringel Morris, Tulsee Doshi, Renelito Delos Santos, Toju Duke, Johnny Soraker, Ben Zevenbergen,\nVinodkumar Prabhakaran, Mark Diaz, Ben Hutchinson, Kristen Olson, Alejandra Molina, Erin Hoffman-John, Josh Lee, Lora Aroyo, Ravi Rajakumar,\nAlena Butryna, Matthew Lamm, Viktoriya Kuzmina, Joe Fenton, Aaron Cohen, Rachel Bernstein, Ray Kurzweil, Blaise Aguera-Arcas, Claire Cui,\nMarian Croak, Ed Chi, and Quoc Le. 2022. LaMDA: Language Models for Dialog Applications. arXiv:2201.08239 [cs.CL]\n[45] Georgina Torbet. 2019. How Much Energy Does Your PC Use? (And 8 Ways to Cut It Down). https://www.makeuseof.com/tag/much-energy-pc-\nuse-8-ways-cut/\n[46] United States Environmental Protection Agency. 2021. Greenhouse Gas Equivalencies Calculator. https://www.epa.gov/energy/greenhouse-gas-\nequivalencies-calculator\n[47] US Department of Energy. 2021. Energy-Efficient Cooling Control Systems for Data Centers. https://www.energy.gov/eere/amo/energy-efficient-\ncooling-control-systems-data-centers\n[48] Adina Williams, Nikita Nangia, and Samuel R Bowman. 2017. A broad-coverage challenge corpus for sentence understanding through inference.\narXiv preprint arXiv:1704.05426 (2017).\n[49] Carole-Jean Wu, Ramya Raghavendra, Udit Gupta, Bilge Acun, Newsha Ardalani, Kiwan Maeng, Gloria Chang, Fiona Aga Behram, James Huang,\nCharles Bai, et al. 2021. Sustainable ai: Environmental implications, challenges and opportunities. arXiv preprint arXiv:2111.00364 (2021).\n17\n\nFAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea Dodge et al.\nA ADDITIONAL PLOTS\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n2\n4\n6\n8\n10\n12CO2 emissions decrease in %\n6h\n12h\n18h\n24h\n(a) Flexible Start optimization.\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n5\n10\n15\n20\n25\n30CO2 emissions decrease in %\n25%\n50%\n75%\n100% (b) Pause and Resume optimization.\nFig. 5. Optimization results for the training of BERT small on 8 V100s. Without optimization, the job ran for approximately 36 hours\nand consumed 37.3 kWh.\nIn Figures 5, 6, 7, 8, 9, 10, 11, 12, 13, 14 and 15, we report the decrease in CO2 emissions (in percent) obtained when\nperforming the two optimizations introduced in the main text for all 16 regions, all 11 models, averaged over the year\nand for various values of the ùëÅ denoting the increase in job duration stemming from the optimization.\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n10\n20\n30\n40\n50CO2 emissions decrease in %\n6h\n12h\n18h\n24h\n(a) Flexible Start optimization.\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0.0\n2.5\n5.0\n7.5\n10.0\n12.5\n15.0\n17.5\n20.0CO2 emissions decrease in %\n25%\n50%\n75%\n100% (b) Pause and Resume optimization.\nFig. 6. Optimization results for the finetuning of BERT small on the MNLI dataset, using 4 V100s. Without optimization, the job ran\nfor approximately 6 hours and consumed 3.1 kWh.\n18\n\nMeasuring the Carbon Intensity of AI in Cloud Instances FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\n1.2\n1.4CO2 emissions decrease in %\n6h\n12h\n18h\n24h\n(a) Flexible Start optimization.\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n5\n10\n15\n20\n25\n30CO2 emissions decrease in %\n25%\n50%\n75%\n100% (b) Pause and Resume optimization.\nFig. 7. Optimization results for the training of a 6B Parameter Transformer on 256 A100s. Without optimization, the job ran for\napproximately 8 days and consumed 13,812 kWh.\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n10\n20\n30\n40\n50\n60\n70\n80CO2 emissions decrease in %\n6h\n12h\n18h\n24h\n(a) Flexible Start optimization.\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n1\n2\n3\n4\n5CO2 emissions decrease in %\n25%\n50%\n75%\n100% (b) Pause and Resume optimization.\nFig. 8. Optimization results for a DenseNet 121 trained on MNIST on 1 P40. Without optimization, the job ran for approximately 20\nminutes and consumed 20 WH.\n19\n\nFAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea Dodge et al.\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n10\n20\n30\n40\n50\n60\n70\n80CO2 emissions decrease in %\n6h\n12h\n18h\n24h\n(a) Flexible Start optimization.\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n1\n2\n3\n4\n5\n6\n7CO2 emissions decrease in %\n25%\n50%\n75%\n100% (b) Pause and Resume optimization.\nFig. 9. Optimization results for a DenseNet 169 trained on MNIST on 1 P40. Without optimization, the job ran for approximately 20\nminutes and consumed 28 WH.\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n10\n20\n30\n40\n50\n60\n70\n80CO2 emissions decrease in %\n6h\n12h\n18h\n24h\n(a) Flexible Start optimization.\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n1\n2\n3\n4\n5\n6\n7\n8CO2 emissions decrease in %\n25%\n50%\n75%\n100% (b) Pause and Resume optimization.\nFig. 10. Optimization results for a DenseNet 201 trained on MNIST on 1 P40. Without optimization, the job ran for approximately 25\nminutes and consumed 37 WH.\n20\n\nMeasuring the Carbon Intensity of AI in Cloud Instances FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n2\n4\n6\n8\n10\n12\n14\n16CO2 emissions decrease in %\n6h\n12h\n18h\n24h\n(a) Flexible Start optimization.\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n5\n10\n15\n20\n25CO2 emissions decrease in %\n25%\n50%\n75%\n100% (b) Pause and Resume optimization.\nFig. 11. Optimization results for a Tiny ViT trained on 1 V100. Without optimization, the job ran for approximately 19 hours and\nconsumed 1.7 kWh.\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n2\n4\n6\n8\n10\n12\n14CO2 emissions decrease in %\n6h\n12h\n18h\n24h\n(a) Flexible Start optimization.\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n5\n10\n15\n20\n25CO2 emissions decrease in %\n25%\n50%\n75%\n100% (b) Pause and Resume optimization.\nFig. 12. Optimization results for a Small ViT trained on 1 V100. Without optimization, the job ran for approximately 19 hours and\nconsumed 2.2 kWh.\n21\n\nFAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea Dodge et al.\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n2\n4\n6\n8CO2 emissions decrease in %\n6h\n12h\n18h\n24h\n(a) Flexible Start optimization.\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n5\n10\n15\n20\n25CO2 emissions decrease in %\n25%\n50%\n75%\n100% (b) Pause and Resume optimization.\nFig. 13. Optimization results for a Base ViT trained on 1 V100. Without optimization, the job ran for approximately 21 hours and\nconsumed 4.7 kWh.\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0.0\n0.5\n1.0\n1.5\n2.0\n2.5\n3.0\n3.5CO2 emissions decrease in %\n6h\n12h\n18h\n24h\n(a) Flexible Start optimization.\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n5\n10\n15\n20\n25\n30CO2 emissions decrease in %\n25%\n50%\n75%\n100% (b) Pause and Resume optimization.\nFig. 14. Optimization results for a Large ViT trained on 4 V100. Without optimization, the job ran for approximately 90 hours and\nconsumed 93.3 kWh.\n22\n\nMeasuring the Carbon Intensity of AI in Cloud Instances FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\n1.2CO2 emissions decrease in %\n6h\n12h\n18h\n24h\n(a) Flexible Start optimization.\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n5\n10\n15\n20\n25CO2 emissions decrease in %\n25%\n50%\n75%\n100% (b) Pause and Resume optimization.\nFig. 15. Optimization results for a Huge ViT trained on 4 V100. Without optimization, the job ran for approximately 9 days and\nconsumed 237.6 kWh.\n23\n\nFAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea Dodge et al.\nB ADDITIONAL TABLES\nIn Tables 6, 7, 8, 9, 10, 11, 12 and 13, we report the decrease in CO2 emissions (in percent) obtained when performing\nthe two optimizations introduced in the main text for all 11 models, averaged across the 16 regions we consider and\nover the year, for various values of the ùëÅ denoting the increase in job duration stemming from the optimization.\nModel BERT BERT 6B Dense Dense Dense ViT ViT ViT ViT ViT\nfinetune LM Transf. 121 169 201 Tiny Small Base Large Huge\nFS 1.9% 1.7% 0.8% 0.6% 0.4% 0.4% 1.8% 1.8% 1.6% 1.3% 0.9%\nP&R 3.1% 4.1% 4.5% 0.7% 0.6% 0.5% 4.5% 4.6% 4.4% 4.4% 4.5%\nPauses / hr 0.45 0.25 0.22 2.2 2.4 2.4 0.28 0.29 0.28 0.22 0.21\nTable 6. For the 11 models in our analysis: the gain in percent averaged over the year and across the 16 regions for the Flexible Start\n(FS) and Pause and Resume (P&R) optimizations allowing for a 25% increase in job duration. The last line represents the average\nnumber of pauses per hour performed by the P&R optimization.\nModel BERT BERT 6B Dense Dense Dense ViT ViT ViT ViT ViT\nfinetune LM Transf. 121 169 201 Tiny Small Base Large Huge\nFS 3.6% 2.9% 1.5% 1.0% 1.3% 1.2% 3.3% 3.1% 2.5% 2.1% 1.6%\nP&R 5.5% 7.0% 7.4% 1.1% 1.5% 1.6% 7.2% 7.0% 7.0% 7.3% 7.4%\nPauses / hr 0.47 0.29 0.27 1.83 2.33 2.33 0.32 0.33 0.32 0.27 0.26\nTable 7. For the 11 models in our analysis: the gain in percent averaged over the year and across the 16 regions for the Flexible Start\n(FS) and Pause and Resume (P&R) optimizations allowing for a 50% increase in job duration. The last line represents the average\nnumber of pauses per hour performed by the P&R optimization.\nModel BERT BERT 6B Dense Dense Dense ViT ViT ViT ViT ViT\nfinetune LM Transf. 121 169 201 Tiny Small Base Large Huge\nFS 5.4% 3.6% 2.0% 1.5% 1.7% 1.9% 4.2% 4.0% 3.3% 2.8% 2.2%\nP&R 7.6% 9.2% 9.6% 1.6% 2.0% 2.4% 9.2% 9.3% 9.2% 9.6% 9.6%\nPauses / hr 0.45 0.3 0.27 1.71 2.0 2.14 0.33 0.33 0.32 0.28 0.26\nTable 8. For the 11 models in our analysis: the gain in percent averaged over the year and across the 16 regions for the Flexible Start\n(FS) and Pause and Resume (P&R) optimizations allowing for a 75% increase in job duration. The last line represents the average\nnumber of pauses per hour performed by the P&R optimization.\nModel BERT BERT 6B Dense Dense Dense ViT ViT ViT ViT ViT\nfinetune LM Transf. 121 169 201 Tiny Small Base Large Huge\nFS 7.0% 4.1% 2.6% 1.8% 2.5% 2.7% 5.0% 4.8% 3.9% 3.3% 3.0%\nP&R 9.5% 11.0% 11.4% 2.0% 2.8% 3.1% 11.0% 11.0% 10.8% 11.4% 11.3%\nPauses / hr 0.42 0.29 0.27 1.5 1.88 2.0 0.31 0.32 0.31 0.27 0.26\nTable 9. For the 11 models in our analysis: the gain in percent averaged over the year and across the 16 regions for the Flexible Start\n(FS) and Pause and Resume (P&R) optimizations allowing for a 100% increase in job duration. The last line represents the average\nnumber of pauses per hour performed by the P&R optimization.\n24\n\nMeasuring the Carbon Intensity of AI in Cloud Instances FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea\nModel BERT BERT 6B Dense Dense Dense ViT ViT ViT ViT ViT\nfinetune LM Transf. 121 169 201 Tiny Small Base Large Huge\nFS 6.9% 1.2% 0.2% 15.3% 14.9% 14.5% 2.3% 2.2% 1.7% 0.5% 0.2%\nP&R 9.4% 2.9% 0.8% 15.8% 15.5% 15.3% 5.5% 5.3% 4.8% 1.5% 0.7%\nPauses / hr 0.41 0.21 0.06 0.22 0.27 0.28 0.29 0.3 0.29 0.11 0.06\nTable 10. For the 11 models in our analysis: the gain in percent averaged over the year and across the 16 regions for the Flexible\nStart (FS) and Pause and Resume (P&R) optimizations allowing for a 6h increase in job duration. The last line represents the average\nnumber of pauses per hour performed by the P&R optimization.\nModel BERT BERT 6B Dense Dense Dense ViT ViT ViT ViT ViT\nfinetune LM Transf. 121 169 201 Tiny Small Base Large Huge\nFS 10.1% 2.3% 0.3% 21.6% 21.1% 20.6% 3.8% 3.6% 2.7% 0.8% 0.3%\nP&R 13.8% 5.3% 1.4% 22.2% 21.7% 21.5% 8.3% 8.1% 7.7% 2.7% 1.3%\nPauses / hr 0.33 0.27 0.1 0.12 0.15 0.15 0.32 0.33 0.32 0.17 0.09\nTable 11. For the 11 models in our analysis: the gain in percent averaged over the year and across the 16 regions for the Flexible\nStart (FS) and Pause and Resume (P&R) optimizations allowing for a 12h increase in job duration. The last line represents the average\nnumber of pauses per hour performed by the P&R optimization.\nModel BERT BERT 6B Dense Dense Dense ViT ViT ViT ViT ViT\nfinetune LM Transf. 121 169 201 Tiny Small Base Large Huge\nFS 13.3% 2.9% 0.4% 24.1% 23.7% 23.2% 4.9% 4.6% 3.6% 1.1% 0.4%\nP&R 17.4% 7.0% 2.0% 24.9% 24.5% 24.2% 10.8% 10.5% 9.9% 3.8% 1.9%\nPauses / hr 0.26 0.29 0.13 0.08 0.09 0.1 0.31 0.32 0.32 0.2 0.12\nTable 12. For the 11 models in our analysis: the gain in percent averaged over the year and across the 16 regions for the Flexible\nStart (FS) and Pause and Resume (P&R) optimizations allowing for a 18h increase in job duration. The last line represents the average\nnumber of pauses per hour performed by the P&R optimization.\nModel BERT BERT 6B Dense Dense Dense ViT ViT ViT ViT ViT\nfinetune LM Transf. 121 169 201 Tiny Small Base Large Huge\nFS 14.5% 3.4% 0.5% 26.8% 26.4% 25.9% 5.6% 5.3% 4.2% 1.3% 0.5%\nP&R 19.0% 8.5% 2.5% 27.7% 27.3% 27.1% 12.5% 12.3% 11.7% 4.7% 2.4%\nPauses / hr 0.23 0.3 0.15 0.06 0.07 0.08 0.3 0.3 0.3 0.23 0.14\nTable 13. For the 11 models in our analysis: the gain in percent averaged over the year and across the 16 regions for the Flexible\nStart (FS) and Pause and Resume (P&R) optimizations allowing for a 24h increase in job duration. The last line represents the average\nnumber of pauses per hour performed by the P&R optimization.\n25", "metadata": {"url": "https://arxiv.org/pdf/2206.05229", "type": "paper", "year": "2022"}, "sections": [{"title": "Page 1", "paragraphs": [{"text": "Measuring the Carbon Intensity of AI in Cloud Instances\nJESSE DODGE, Allen Institute for AI, USA\nTAYLOR PREWITT, University of Washington, USA\nREMI TACHET DES COMBES, Microsoft Research Montreal, USA\nERIKA ODMARK, Microsoft, USA\nROY SCHWARTZ,Hebrew University of Jerusalem, Israel\nEMMA STRUBELL, Carnegie Mellon University, USA\nALEXANDRA SASHA LUCCIONI, Hugging Face, USA\nNOAH A. SMITH, Allen Institute for AI and University of Washington, USA\nNICOLE DECARIO, Allen Institute for AI, USA\nWILL BUCHANAN, Microsoft, USA\nThe advent of cloud computing has provided people around the world with unprecedented access to computational power and\nenabled rapid growth in technologies such as machine learning, the computational demands of which incur a high energy cost and a\ncommensurate carbon footprint. As a result, recent scholarship has called for better estimates of the greenhouse gas impact of AI: data\nscientists today do not have easy or reliable access to measurements of this information, which precludes development of actionable\ntactics. We argue that cloud providers presenting information about software carbon intensity to users is a fundamental stepping\nstone towards minimizing emissions.\nIn this paper, we provide a framework for measuring software carbon intensity, and propose to measure operational carbon\nemissions by using location-based and time-specific marginal emissions data per energy unit. We provide measurements of operational\nsoftware carbon intensity for a set of modern models covering natural language processing and computer vision applications, and a\nwide range of model sizes, including pretraining of a 6.1 billion parameter language model. We then evaluate a suite of approaches for\nreducing emissions on the Microsoft Azure cloud compute platform: using cloud instances in different geographic regions, using cloud\ninstances at different times of day, and dynamically pausing cloud instances when the marginal carbon intensity is above a certain\nthreshold. We confirm previous results that the geographic region of the data center plays a significant role in the carbon intensity for\na given cloud instance, and find that choosing an appropriate region can have the largest operational emissions reduction impact. We\nalso present new results showing that the time of day has meaningful impact on operational software carbon intensity.Finally, we\nconclude with recommendations for how machine learning practitioners can use software carbon intensity information to reduce\nenvironmental impact.\nAdditional Key Words and Phrases: CO2, emissions, cloud, carbon intensity, carbon awareness, grid\nACM Reference Format:\nJesse Dodge, Taylor Prewitt, Remi Tachet Des Combes, Erika Odmark, Roy Schwartz, Emma Strubell, Alexandra Sasha Luccioni, Noah\nA. Smith, Nicole DeCario, and Will Buchanan. 2022. Measuring the Carbon Intensity of AI in Cloud Instances. In 2022 ACM Conference\non Fairness, Accountability, and Transparency (FAccT ‚Äô22), June 21‚Äì24, 2022, Seoul, Republic of Korea. ACM, New York, NY, USA, 25 pages.\nhttps://doi.org/10.1145/3531146.3533234\nPermission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not\nmade or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party\ncomponents of this work must be honored. For all other uses, contact the owner/author(s).\n¬© 2022 Copyright held by the owner/author(s).\nManuscript submitted to ACM\n1\narXiv:2206.05229v1  [cs.LG]  10 Jun 2022", "sentences": [{"text": "Measuring the Carbon Intensity of AI in Cloud Instances\nJESSE DODGE, Allen Institute for AI, USA\nTAYLOR PREWITT, University of Washington, USA\nREMI TACHET DES COMBES, Microsoft Research Montreal, USA\nERIKA ODMARK, Microsoft, USA\nROY SCHWARTZ,Hebrew University of Jerusalem, Israel\nEMMA STRUBELL, Carnegie Mellon University, USA\nALEXANDRA SASHA LUCCIONI, Hugging Face, USA\nNOAH A.", "metadata": {}}, {"text": "SMITH, Allen Institute for AI and University of Washington, USA\nNICOLE DECARIO, Allen Institute for AI, USA\nWILL BUCHANAN, Microsoft, USA\nThe advent of cloud computing has provided people around the world with unprecedented access to computational power and\nenabled rapid growth in technologies such as machine learning, the computational demands of which incur a high energy cost and a\ncommensurate carbon footprint.", "metadata": {}}, {"text": "As a result, recent scholarship has called for better estimates of the greenhouse gas impact of AI: data\nscientists today do not have easy or reliable access to measurements of this information, which precludes development of actionable\ntactics.", "metadata": {}}, {"text": "We argue that cloud providers presenting information about software carbon intensity to users is a fundamental stepping\nstone towards minimizing emissions.", "metadata": {}}, {"text": "In this paper, we provide a framework for measuring software carbon intensity, and propose to measure operational carbon\nemissions by using location-based and time-specific marginal emissions data per energy unit.", "metadata": {}}, {"text": "We provide measurements of operational\nsoftware carbon intensity for a set of modern models covering natural language processing and computer vision applications, and a\nwide range of model sizes, including pretraining of a 6.1 billion parameter language model.", "metadata": {}}, {"text": "We then evaluate a suite of approaches for\nreducing emissions on the Microsoft Azure cloud compute platform: using cloud instances in different geographic regions, using cloud\ninstances at different times of day, and dynamically pausing cloud instances when the marginal carbon intensity is above a certain\nthreshold.", "metadata": {}}, {"text": "We confirm previous results that the geographic region of the data center plays a significant role in the carbon intensity for\na given cloud instance, and find that choosing an appropriate region can have the largest operational emissions reduction impact.", "metadata": {}}, {"text": "We\nalso present new results showing that the time of day has meaningful impact on operational software carbon intensity.Finally, we\nconclude with recommendations for how machine learning practitioners can use software carbon intensity information to reduce\nenvironmental impact.", "metadata": {}}, {"text": "Additional Key Words and Phrases: CO2, emissions, cloud, carbon intensity, carbon awareness, grid\nACM Reference Format:\nJesse Dodge, Taylor Prewitt, Remi Tachet Des Combes, Erika Odmark, Roy Schwartz, Emma Strubell, Alexandra Sasha Luccioni, Noah\nA.", "metadata": {}}, {"text": "Smith, Nicole DeCario, and Will Buchanan.", "metadata": {}}, {"text": "2022.", "metadata": {}}, {"text": "Measuring the Carbon Intensity of AI in Cloud Instances.", "metadata": {}}, {"text": "In 2022 ACM Conference\non Fairness, Accountability, and Transparency (FAccT ‚Äô22), June 21‚Äì24, 2022, Seoul, Republic of Korea.", "metadata": {}}, {"text": "ACM, New York, NY, USA, 25 pages.", "metadata": {}}, {"text": "https://doi.org/10.1145/3531146.3533234\nPermission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not\nmade or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.", "metadata": {}}, {"text": "Copyrights for third-party\ncomponents of this work must be honored.", "metadata": {}}, {"text": "For all other uses, contact the owner/author(s).", "metadata": {}}, {"text": "¬© 2022 Copyright held by the owner/author(s).", "metadata": {}}, {"text": "Manuscript submitted to ACM\n1\narXiv:2206.05229v1  [cs.LG]  10 Jun 2022", "metadata": {}}], "metadata": {"page": 1}}], "metadata": {"page": 1}}, {"title": "Page 2", "paragraphs": [{"text": "FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea Dodge et al.\n1 INTRODUCTION\nClimate change is an increasing threat to life on our planet, which disproportionately impacts the most disadvantaged\ncommunities and fragile ecosystems [28]. One of the main drivers of climate change is carbon dioxide, or CO2, which\ncontributes to the greenhouse effect by trapping the heat from the sun within the atmosphere without letting it dissipate.\nCO2 (and other types of greenhouse gases, such as methane and ozone) are emitted by many sources, some natural\nbut most man-made, such as the burning of oil and gas for transportation and heating or for industrial processes\nsuch as smelting. In 2018, it was estimated that global data center energy use represented close to 1% of global energy\nusage [27]. While it is not yet known what proportion of data center use is for training artificial intelligence (AI)\nmodels, it is undeniable that AI and its sub-fields have grown dramatically in recent years, with no sign of slowing\ndown [39, 43]. While a number of papers have addressed the CO2 emissions produced by AI (e.g., [23, 26, 33, 34]), the\nextent and provenance of CO2 emissions in the field is still under-explored. Nonetheless, a common theme of previous\nwork is that it aims to estimate the emissions produced by training AI models, or carrying out the accompanying\nneural architecture search (NAS) process, based on coarse measures such as CO2 emissions of electricity used in the\nregion where the computations were carried out (e.g., [42]), or post-hoc analyses using information that is not publicly\navailable (e.g., [34]).\nWith an increasing amount of AI model training being done on cloud compute instances, reducing the emissions\ngenerated by these workloads will be key to reducing our carbon footprint as a field. However, to reduce greenhouse gas\nemissions from cloud computing, we need consider the role of two types of actors: the cloud provider (such as Microsoft\nAzure, Google‚Äôs GCP, or Amazon‚Äôs AWS) and the user who reserves and uses cloud resources (e.g., an AI researcher\ntraining a model on a cloud instance, or a company hosting a website). Typically, the provider‚Äôs motivation is to build a\nsystem where users can access the computing power and storage that best meets their needs. The user, on the other\nhand, is motivated by some end task which requires computing power, such as running a set of experiments or putting\na model into production. Often the user will first consider the minimal computational requirements to achieve their\ngoals, then later ease-of-use features relating to transfer speed or extra storage depending on available budget. Driven\nby these motivations, providers and users can each take actions to meet their goals: providers can build data centers\nand set up APIs to enable users‚Äô access and accounting, while users can choose their cloud provider, which region to\nuse, and the number and type of cloud instances required for their end task at a given point in time. Based on these\nstakeholders and motivations, in this work we address the following research questions: 1) how should we measure and\nreport operational carbon costs of AI workloads? And 2) can we shift computation spatially and temporally to mitigate\nemissions?\nIn this article, we introduce the first tool to estimate the real-time CO2 emissions impact of instances on a cloud\ncomputing platform. The tool calculates operational carbon emissions by using location-based and time-specific marginal\nemissions data per energy unit. Using the tool, we explore several case studies on the Microsoft Azure cloud compute\nplatform spanning the areas of natural language processing (NLP) and computer vision, estimating the carbon intensity\nof training a variety of commonly used machine learning models. We also explore two avenues for users of cloud\ninstances to reduce their CO 2 using this tool by: (1) Changing the region of compute and (2) changing the time of\nday during which the model is run. While the former has been recognized by prior work [13, 23], we are the first to\naddress the latter to the best of our knowledge. Further, our tool makes it possible to automatically schedule jobs in\norder to reduce their carbon footprint by leveraging these differences in carbon intensity due to time and geographic\nlocation. Finally, we provide guidance regarding what should be measured and how, following the Green Software\n2", "sentences": [{"text": "FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea Dodge et al.", "metadata": {}}, {"text": "1 INTRODUCTION\nClimate change is an increasing threat to life on our planet, which disproportionately impacts the most disadvantaged\ncommunities and fragile ecosystems [28].", "metadata": {}}, {"text": "One of the main drivers of climate change is carbon dioxide, or CO2, which\ncontributes to the greenhouse effect by trapping the heat from the sun within the atmosphere without letting it dissipate.", "metadata": {}}, {"text": "CO2 (and other types of greenhouse gases, such as methane and ozone) are emitted by many sources, some natural\nbut most man-made, such as the burning of oil and gas for transportation and heating or for industrial processes\nsuch as smelting.", "metadata": {}}, {"text": "In 2018, it was estimated that global data center energy use represented close to 1% of global energy\nusage [27].", "metadata": {}}, {"text": "While it is not yet known what proportion of data center use is for training artificial intelligence (AI)\nmodels, it is undeniable that AI and its sub-fields have grown dramatically in recent years, with no sign of slowing\ndown [39, 43].", "metadata": {}}, {"text": "While a number of papers have addressed the CO2 emissions produced by AI (e.g., [23, 26, 33, 34]), the\nextent and provenance of CO2 emissions in the field is still under-explored.", "metadata": {}}, {"text": "Nonetheless, a common theme of previous\nwork is that it aims to estimate the emissions produced by training AI models, or carrying out the accompanying\nneural architecture search (NAS) process, based on coarse measures such as CO2 emissions of electricity used in the\nregion where the computations were carried out (e.g., [42]), or post-hoc analyses using information that is not publicly\navailable (e.g., [34]).", "metadata": {}}, {"text": "With an increasing amount of AI model training being done on cloud compute instances, reducing the emissions\ngenerated by these workloads will be key to reducing our carbon footprint as a field.", "metadata": {}}, {"text": "However, to reduce greenhouse gas\nemissions from cloud computing, we need consider the role of two types of actors: the cloud provider (such as Microsoft\nAzure, Google‚Äôs GCP, or Amazon‚Äôs AWS) and the user who reserves and uses cloud resources (e.g., an AI researcher\ntraining a model on a cloud instance, or a company hosting a website).", "metadata": {}}, {"text": "Typically, the provider‚Äôs motivation is to build a\nsystem where users can access the computing power and storage that best meets their needs.", "metadata": {}}, {"text": "The user, on the other\nhand, is motivated by some end task which requires computing power, such as running a set of experiments or putting\na model into production.", "metadata": {}}, {"text": "Often the user will first consider the minimal computational requirements to achieve their\ngoals, then later ease-of-use features relating to transfer speed or extra storage depending on available budget.", "metadata": {}}, {"text": "Driven\nby these motivations, providers and users can each take actions to meet their goals: providers can build data centers\nand set up APIs to enable users‚Äô access and accounting, while users can choose their cloud provider, which region to\nuse, and the number and type of cloud instances required for their end task at a given point in time.", "metadata": {}}, {"text": "Based on these\nstakeholders and motivations, in this work we address the following research questions: 1) how should we measure and\nreport operational carbon costs of AI workloads?", "metadata": {}}, {"text": "And 2) can we shift computation spatially and temporally to mitigate\nemissions?", "metadata": {}}, {"text": "In this article, we introduce the first tool to estimate the real-time CO2 emissions impact of instances on a cloud\ncomputing platform.", "metadata": {}}, {"text": "The tool calculates operational carbon emissions by using location-based and time-specific marginal\nemissions data per energy unit.", "metadata": {}}, {"text": "Using the tool, we explore several case studies on the Microsoft Azure cloud compute\nplatform spanning the areas of natural language processing (NLP) and computer vision, estimating the carbon intensity\nof training a variety of commonly used machine learning models.", "metadata": {}}, {"text": "We also explore two avenues for users of cloud\ninstances to reduce their CO 2 using this tool by: (1) Changing the region of compute and (2) changing the time of\nday during which the model is run.", "metadata": {}}, {"text": "While the former has been recognized by prior work [13, 23], we are the first to\naddress the latter to the best of our knowledge.", "metadata": {}}, {"text": "Further, our tool makes it possible to automatically schedule jobs in\norder to reduce their carbon footprint by leveraging these differences in carbon intensity due to time and geographic\nlocation.", "metadata": {}}, {"text": "Finally, we provide guidance regarding what should be measured and how, following the Green Software\n2", "metadata": {}}], "metadata": {"page": 2}}], "metadata": {"page": 2}}, {"title": "Page 3", "paragraphs": [{"text": "Measuring the Carbon Intensity of AI in Cloud Instances FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea\nFoundation‚Äôs guidelines regarding Software Carbon Intensity (SCI), and suggest future areas of research to improve the\nstate of carbon estimation and reporting in AI.\n2 RELATED WORK\nAttention was first drawn to the environmental impact of AI research by the seminal work of Strubell et al. [42], which\nquantified the emissions produced by training a Transformer model with Neural Architecture search, finding it to\nbe comparable to the lifetime carbon emissions of five cars. Patterson et al . [34] presented some updated analyses\nof similar experiments, including popular architectures like T5 [ 35] and BERT [ 8], analyzing CO 2 emissions as a\nfactor of their energy consumption, carbon intensity of training servers, etc. Other work such as Green AI [39] delved\nfurther into inequality of access to computational resources within the research community, and advocated for the\ninclusion of efficiency evaluation alongside accuracy as a primary evaluation criterion. Much existing and ongoing\nwork on quantifying the environmental footprint of ML has been focused on estimating the CO2 emissions of model\ntraining. This is a more straightforward endeavor compared to other stages both upstream and downstream from the\ntraining process, given that it is well-defined in time and its emissions can be measured in real-time with tools like\nCode Carbon [38] and Carbon Tracker [1] or estimated post-hoc using tools such as ML CO 2 Impact Tracker [23].\nOur tool builds upon this work by making carbon tracking on cloud instances possible, enabling a larger portion of\nML model training work to profit from fine-grained carbon estimation. However, recent work has found that their\nresults vary significantly and are not fully representative of the true emissions incurred by training [3]. Perhaps most\nsimilar to our work, EnergyVis [41] is an interactive tool for visualizing and comparing energy consumption of ML\nmodels as a function of hardware and physical location (U.S. state), given metadata about a model‚Äôs energy use per\nepoch. Other studies have gone beyond simply tracking the emissions from training models, aiming to quantify the\nemissions resulting from manufacturing computing hardware [15], the broader impacts of sustainable AI [49], and the\nmethodologies used to assess those impacts [21, 26]. Building upon this research, efforts have also been made to certify\nsystems as being socially- and environmentally-conscious [14], working towards comparing both the environmental\ncosts and potential benefits of AI models in order to paint a more holistic picture of AI.\nMajor technology companies have also been increasingly committed to reducing their emissions, largely via the\npurchase of Renewable Energy Credits (RECs), which involves directly buying quantities of energy produced by\nrenewable sources, translating into carbon reductions under the assumption that the clean energy is displacing an\nequivalent amount of electricity produced by non-renewable methods [11]. Many cloud providers, from Google Cloud\nPlatform to Microsoft Azure, therefore claim that they are now ‚Äúcarbon-neutral, ‚Äù given that they offset the entirety of\nthe emissions of their cloud centers, though we must be wary of the precise provenance of RECs, and the details of\nhow each organization defines ‚Äúzero‚Äù net emissions [36]. This is complemented by efforts to mitigate the actual CO2\nemissions of the compute regions themselves, with several server locations partially powered by renewable energy\nsources such as solar and wind [12, 29, 40] and giving users the necessary tools to pick compute regions with a smaller\ncarbon footprint [13, 17], which are often tied to the amount of low-carbon energy that is being purchased, and not the\ngrid emissions intensity. It is important to note that the decision on when and where to deploy a workload should be\nbased on a grid emissions signal, not the amount of emissions offset through market-based measures (e.g., green power\npurchase agreements (PPAs), renewable energy certificates (RECs), or other carbon offset mechanisms): purchasing\nclean energy is not the same as consuming clean energy.\n3", "sentences": [{"text": "Measuring the Carbon Intensity of AI in Cloud Instances FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea\nFoundation‚Äôs guidelines regarding Software Carbon Intensity (SCI), and suggest future areas of research to improve the\nstate of carbon estimation and reporting in AI.", "metadata": {}}, {"text": "2 RELATED WORK\nAttention was first drawn to the environmental impact of AI research by the seminal work of Strubell et al.", "metadata": {}}, {"text": "[42], which\nquantified the emissions produced by training a Transformer model with Neural Architecture search, finding it to\nbe comparable to the lifetime carbon emissions of five cars.", "metadata": {}}, {"text": "Patterson et al .", "metadata": {}}, {"text": "[34] presented some updated analyses\nof similar experiments, including popular architectures like T5 [ 35] and BERT [ 8], analyzing CO 2 emissions as a\nfactor of their energy consumption, carbon intensity of training servers, etc.", "metadata": {}}, {"text": "Other work such as Green AI [39] delved\nfurther into inequality of access to computational resources within the research community, and advocated for the\ninclusion of efficiency evaluation alongside accuracy as a primary evaluation criterion.", "metadata": {}}, {"text": "Much existing and ongoing\nwork on quantifying the environmental footprint of ML has been focused on estimating the CO2 emissions of model\ntraining.", "metadata": {}}, {"text": "This is a more straightforward endeavor compared to other stages both upstream and downstream from the\ntraining process, given that it is well-defined in time and its emissions can be measured in real-time with tools like\nCode Carbon [38] and Carbon Tracker [1] or estimated post-hoc using tools such as ML CO 2 Impact Tracker [23].", "metadata": {}}, {"text": "Our tool builds upon this work by making carbon tracking on cloud instances possible, enabling a larger portion of\nML model training work to profit from fine-grained carbon estimation.", "metadata": {}}, {"text": "However, recent work has found that their\nresults vary significantly and are not fully representative of the true emissions incurred by training [3].", "metadata": {}}, {"text": "Perhaps most\nsimilar to our work, EnergyVis [41] is an interactive tool for visualizing and comparing energy consumption of ML\nmodels as a function of hardware and physical location (U.S.", "metadata": {}}, {"text": "state), given metadata about a model‚Äôs energy use per\nepoch.", "metadata": {}}, {"text": "Other studies have gone beyond simply tracking the emissions from training models, aiming to quantify the\nemissions resulting from manufacturing computing hardware [15], the broader impacts of sustainable AI [49], and the\nmethodologies used to assess those impacts [21, 26].", "metadata": {}}, {"text": "Building upon this research, efforts have also been made to certify\nsystems as being socially- and environmentally-conscious [14], working towards comparing both the environmental\ncosts and potential benefits of AI models in order to paint a more holistic picture of AI.", "metadata": {}}, {"text": "Major technology companies have also been increasingly committed to reducing their emissions, largely via the\npurchase of Renewable Energy Credits (RECs), which involves directly buying quantities of energy produced by\nrenewable sources, translating into carbon reductions under the assumption that the clean energy is displacing an\nequivalent amount of electricity produced by non-renewable methods [11].", "metadata": {}}, {"text": "Many cloud providers, from Google Cloud\nPlatform to Microsoft Azure, therefore claim that they are now ‚Äúcarbon-neutral, ‚Äù given that they offset the entirety of\nthe emissions of their cloud centers, though we must be wary of the precise provenance of RECs, and the details of\nhow each organization defines ‚Äúzero‚Äù net emissions [36].", "metadata": {}}, {"text": "This is complemented by efforts to mitigate the actual CO2\nemissions of the compute regions themselves, with several server locations partially powered by renewable energy\nsources such as solar and wind [12, 29, 40] and giving users the necessary tools to pick compute regions with a smaller\ncarbon footprint [13, 17], which are often tied to the amount of low-carbon energy that is being purchased, and not the\ngrid emissions intensity.", "metadata": {}}, {"text": "It is important to note that the decision on when and where to deploy a workload should be\nbased on a grid emissions signal, not the amount of emissions offset through market-based measures (e.g., green power\npurchase agreements (PPAs), renewable energy certificates (RECs), or other carbon offset mechanisms): purchasing\nclean energy is not the same as consuming clean energy.", "metadata": {}}, {"text": "3", "metadata": {}}], "metadata": {"page": 3}}], "metadata": {"page": 3}}, {"title": "Page 4", "paragraphs": [{"text": "FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea Dodge et al.\n3 REPORTING AI CARBON INTENSITY\nCarbon accounting and reporting is becoming increasingly common in ML, with conferences such as NeurIPS requesting\nthat submissions report their emissions [31] and recent work reporting the emissions incurred [37, 44]. However, it\nhas yet to become the norm in our field, and we are still lacking systematic information regarding the environmental\nfootprint of training ML models and how we can reduce it. In this paper, we argue that if members of the ML community\nhad access to information about the CO2 emissions of their actions, they could adapt their decisions to reduce these\nemissions while still meeting the computational needs for their end tasks. In addition, providers building tools that\nenable users to track their CO2 emissions directly aligns with providers‚Äô goals, as it will inform users‚Äô decisions without\nbeing overly burdensome. Any cloud provider that discloses this information to users will, in fact, be improving those\ncustomers‚Äô experiences, and likely increase usage of the platform. More specifically, we propose that, for a cloud user\nwho wants to estimate their carbon footprint, the most salient information providers can report is the CO2 emissions\ngenerated by their cloud instances. Arguably the single most important contribution of this paper is the simplest: a\npresentation of the software carbon intensity (SCI) as a proxy for carbon emissions for a given cloud instance as it is\nrunning.\n3.1 Methodology: Computing CO 2 Intensity\nIn this section we describe a method for estimating carbon intensity for cloud instances. At a high level, this involves\ntracking electricity consumption of hardware related to a single cloud instance, and mapping that electricity usage to\nCO2 emissions by using a grid-based carbon intensity.\nAs developed by the Green Software Foundation, the Software Carbon Intensity (ùëÜùê∂ùêº ) is a rate, carbon emissions per\none functional unit, or R. The equation used to calculate the ùëÜùê∂ùêº value of a software system is therefore:\nùëÜùê∂ùêº = (( ùê∏ ‚àó ùêº ) + ùëÄ) per ùëÖ (1)\nwhere:\n‚Ä¢ ùê∏ = Energy consumed by a software system. Specifically, we focus on energy consumption of Graphical Processing\nUnits, or GPUs. The units used are kilowatt-hours (kWh).\n‚Ä¢ ùêº = Location-based marginal carbon emissions for the grid that powers the datacenter. WattTime provides\nmeasurements of grams of carbon dioxide equivalent per kilowatt-hour of electricity (gCO2eq/kWh)\n‚Ä¢ ùëÄ = Embodied carbon (also referred to as ‚Äúembedded carbon‚Äù) is the amount of carbon emitted during the\ncreation, usage, and disposal of a hardware device. When software runs on a device, a fraction of the total\nembodied emissions of the device is allocated to the software.\n‚Ä¢ ùëÖ = Functional unit. In this instance, we are defining the functional unit as one machine learning training job,\nbut it is extensible to other scenarios.\nThe equation can be further refined to:\nùëÜùê∂ùêº = (ùëÇ + ùëÄ) per ùëÖ (2)\nwhere ùëÇ = ùê∏ ‚àó ùêº calculates the operational emissions based on energy consumption (ùê∏) multiplied by the location-based\nand time-specific carbon intensity measurement (ùêº). Once more this can be further refined to simply:\nùëÜùê∂ùêº = ùê∂ per ùëÖ (3)\n4", "sentences": [{"text": "FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea Dodge et al.", "metadata": {}}, {"text": "3 REPORTING AI CARBON INTENSITY\nCarbon accounting and reporting is becoming increasingly common in ML, with conferences such as NeurIPS requesting\nthat submissions report their emissions [31] and recent work reporting the emissions incurred [37, 44].", "metadata": {}}, {"text": "However, it\nhas yet to become the norm in our field, and we are still lacking systematic information regarding the environmental\nfootprint of training ML models and how we can reduce it.", "metadata": {}}, {"text": "In this paper, we argue that if members of the ML community\nhad access to information about the CO2 emissions of their actions, they could adapt their decisions to reduce these\nemissions while still meeting the computational needs for their end tasks.", "metadata": {}}, {"text": "In addition, providers building tools that\nenable users to track their CO2 emissions directly aligns with providers‚Äô goals, as it will inform users‚Äô decisions without\nbeing overly burdensome.", "metadata": {}}, {"text": "Any cloud provider that discloses this information to users will, in fact, be improving those\ncustomers‚Äô experiences, and likely increase usage of the platform.", "metadata": {}}, {"text": "More specifically, we propose that, for a cloud user\nwho wants to estimate their carbon footprint, the most salient information providers can report is the CO2 emissions\ngenerated by their cloud instances.", "metadata": {}}, {"text": "Arguably the single most important contribution of this paper is the simplest: a\npresentation of the software carbon intensity (SCI) as a proxy for carbon emissions for a given cloud instance as it is\nrunning.", "metadata": {}}, {"text": "3.1 Methodology: Computing CO 2 Intensity\nIn this section we describe a method for estimating carbon intensity for cloud instances.", "metadata": {}}, {"text": "At a high level, this involves\ntracking electricity consumption of hardware related to a single cloud instance, and mapping that electricity usage to\nCO2 emissions by using a grid-based carbon intensity.", "metadata": {}}, {"text": "As developed by the Green Software Foundation, the Software Carbon Intensity (ùëÜùê∂ùêº ) is a rate, carbon emissions per\none functional unit, or R.", "metadata": {}}, {"text": "The equation used to calculate the ùëÜùê∂ùêº value of a software system is therefore:\nùëÜùê∂ùêº = (( ùê∏ ‚àó ùêº ) + ùëÄ) per ùëÖ (1)\nwhere:\n‚Ä¢ ùê∏ = Energy consumed by a software system.", "metadata": {}}, {"text": "Specifically, we focus on energy consumption of Graphical Processing\nUnits, or GPUs.", "metadata": {}}, {"text": "The units used are kilowatt-hours (kWh).", "metadata": {}}, {"text": "‚Ä¢ ùêº = Location-based marginal carbon emissions for the grid that powers the datacenter.", "metadata": {}}, {"text": "WattTime provides\nmeasurements of grams of carbon dioxide equivalent per kilowatt-hour of electricity (gCO2eq/kWh)\n‚Ä¢ ùëÄ = Embodied carbon (also referred to as ‚Äúembedded carbon‚Äù) is the amount of carbon emitted during the\ncreation, usage, and disposal of a hardware device.", "metadata": {}}, {"text": "When software runs on a device, a fraction of the total\nembodied emissions of the device is allocated to the software.", "metadata": {}}, {"text": "‚Ä¢ ùëÖ = Functional unit.", "metadata": {}}, {"text": "In this instance, we are defining the functional unit as one machine learning training job,\nbut it is extensible to other scenarios.", "metadata": {}}, {"text": "The equation can be further refined to:\nùëÜùê∂ùêº = (ùëÇ + ùëÄ) per ùëÖ (2)\nwhere ùëÇ = ùê∏ ‚àó ùêº calculates the operational emissions based on energy consumption (ùê∏) multiplied by the location-based\nand time-specific carbon intensity measurement (ùêº).", "metadata": {}}, {"text": "Once more this can be further refined to simply:\nùëÜùê∂ùêº = ùê∂ per ùëÖ (3)\n4", "metadata": {}}], "metadata": {"page": 4}}], "metadata": {"page": 4}}, {"title": "Page 5", "paragraphs": [{"text": "Measuring the Carbon Intensity of AI in Cloud Instances FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea\nwhere ùê∂ = ùëÇ + ùëÄ is the software carbon intensity for a given cloud instance. In this paper, we focus on measuring\noperational emissionsùëÇ, and leave measurement and accounting for embodied emissions due to specialized ML hardware\nsuch as GPUs to future work (see ¬ß8).\nThe objective of the Green Software Foundation‚Äôs Software Carbon Intensity (SCI) specification is to calculate and\nreduce a SCI score, based on carbon emissions reductions, rather than the currently-used market-based neutralization.\nSpecifically, the SCI uses a \"consequential\" carbon accounting approach, which aims to quantify the marginal change in\nemissions caused by decisions or interventions. This differs from the commonly used \"attributional\" carbon accounting\napproach, which uses average carbon intensity data, meaning it does not provide the most actionable information to\nhelp reduce carbon emissions. Due to the myriad potential pitfalls of relying on market-based measures in place of\nactual reduction in emissions [36], it is not possible to reduce the SCI through carbon neutralization or carbon offsets.\nWe assert that cloud providers should provide the SCI to developers and data scientists to help them make choices that\nreduce the carbon footprint of their ML workloads.\n3.2 The Scope of our Tool: GPU Computation of a Single Cloud Instance\nData centers typically comprise many computer systems and hardware components, including storage, GPUs, CPUs,\nand networking components. We can break down the electricity usage for data centers into: 1) electricity that is used\nfor a single cloud instance, and 2) electricity that is used for the benefit of the whole data center. In this work we focus\non the former, a single cloud instance; because of this, a reader should understand that our estimates of the electricity\nconsumption and emissions are underestimates.1\nElectricity Consumption from a Single Cloud Instance. The most accurate and popular AI models today are typically\n(deep) neural networks, which are most performant on specialized, highly parallelized, and often energy-intensive\nhardware [43]. The most common scenario is for AI workloads to run on graphics processing units (GPUs), which provide\nsignificant acceleration compared to CPUs (central processing units) but are more power-hungry (often consuming\n250W-350W, compared to CPU consumption of 10-150W). Due to specialization to the matrix multiply operations at\nthe core of neural network computations and a high rate of parallelization, GPUs can perform many more of these\ntypes of computations in the same amount of time as a CPU, but this increased computation throughput comes at an\nincreased energy cost. Thus in ML applications based on deep learning, the majority of the electricity consumption\nis due to the GPU [ 5, 45]. While this result is fairly uncontroversial, we ran an experiment to confirm it. To do so,\nwe trained a BERT-base model [8] on a single NVIDIA TITAN X GPU (12 GB) in a commodity server with two Intel\nXeon E5-2630 v3 CPUs (2.4GHz) and 256GB RAM (16x16GB DIMMs) to measure the relative electricity consumption\nof different components. We trained the model using the original code provided by Devlin et al. [8] on the language\nmodel pre-training task for 12 hours on one GPU, sampling the instantaneous energy use of the GPU, CPU and DRAM\nfor each socket throughout that period, then averaging to get average power draw per component in watts. GPU\nenergy draw was measured using nvidia-smi and CPU and DRAM power draw were obtained using Intel‚Äôs RAPL.\nOur measurements, in watts, are presented in Table 1. As expected the GPU accounts for almost 3/4 of electricity\nconsumption.\nFocus on GPUs. In cloud datacenters, the CPUs, RAM, storage, and motherboards are often shared across multiple\ninstances; while this provides the flexibility that makes the cloud so useful, it leads to technical limitations that make it\n1There is related work on estimating and reducing the electricity of data centers in general, e.g., [10, 24].\n5", "sentences": [{"text": "Measuring the Carbon Intensity of AI in Cloud Instances FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea\nwhere ùê∂ = ùëÇ + ùëÄ is the software carbon intensity for a given cloud instance.", "metadata": {}}, {"text": "In this paper, we focus on measuring\noperational emissionsùëÇ, and leave measurement and accounting for embodied emissions due to specialized ML hardware\nsuch as GPUs to future work (see ¬ß8).", "metadata": {}}, {"text": "The objective of the Green Software Foundation‚Äôs Software Carbon Intensity (SCI) specification is to calculate and\nreduce a SCI score, based on carbon emissions reductions, rather than the currently-used market-based neutralization.", "metadata": {}}, {"text": "Specifically, the SCI uses a \"consequential\" carbon accounting approach, which aims to quantify the marginal change in\nemissions caused by decisions or interventions.", "metadata": {}}, {"text": "This differs from the commonly used \"attributional\" carbon accounting\napproach, which uses average carbon intensity data, meaning it does not provide the most actionable information to\nhelp reduce carbon emissions.", "metadata": {}}, {"text": "Due to the myriad potential pitfalls of relying on market-based measures in place of\nactual reduction in emissions [36], it is not possible to reduce the SCI through carbon neutralization or carbon offsets.", "metadata": {}}, {"text": "We assert that cloud providers should provide the SCI to developers and data scientists to help them make choices that\nreduce the carbon footprint of their ML workloads.", "metadata": {}}, {"text": "3.2 The Scope of our Tool: GPU Computation of a Single Cloud Instance\nData centers typically comprise many computer systems and hardware components, including storage, GPUs, CPUs,\nand networking components.", "metadata": {}}, {"text": "We can break down the electricity usage for data centers into: 1) electricity that is used\nfor a single cloud instance, and 2) electricity that is used for the benefit of the whole data center.", "metadata": {}}, {"text": "In this work we focus\non the former, a single cloud instance;", "metadata": {}}, {"text": "because of this, a reader should understand that our estimates of the electricity\nconsumption and emissions are underestimates.1\nElectricity Consumption from a Single Cloud Instance.", "metadata": {}}, {"text": "The most accurate and popular AI models today are typically\n(deep) neural networks, which are most performant on specialized, highly parallelized, and often energy-intensive\nhardware [43].", "metadata": {}}, {"text": "The most common scenario is for AI workloads to run on graphics processing units (GPUs), which provide\nsignificant acceleration compared to CPUs (central processing units) but are more power-hungry (often consuming\n250W-350W, compared to CPU consumption of 10-150W).", "metadata": {}}, {"text": "Due to specialization to the matrix multiply operations at\nthe core of neural network computations and a high rate of parallelization, GPUs can perform many more of these\ntypes of computations in the same amount of time as a CPU, but this increased computation throughput comes at an\nincreased energy cost.", "metadata": {}}, {"text": "Thus in ML applications based on deep learning, the majority of the electricity consumption\nis due to the GPU [ 5, 45].", "metadata": {}}, {"text": "While this result is fairly uncontroversial, we ran an experiment to confirm it.", "metadata": {}}, {"text": "To do so,\nwe trained a BERT-base model [8] on a single NVIDIA TITAN X GPU (12 GB) in a commodity server with two Intel\nXeon E5-2630 v3 CPUs (2.4GHz) and 256GB RAM (16x16GB DIMMs) to measure the relative electricity consumption\nof different components.", "metadata": {}}, {"text": "We trained the model using the original code provided by Devlin et al.", "metadata": {}}, {"text": "[8] on the language\nmodel pre-training task for 12 hours on one GPU, sampling the instantaneous energy use of the GPU, CPU and DRAM\nfor each socket throughout that period, then averaging to get average power draw per component in watts.", "metadata": {}}, {"text": "GPU\nenergy draw was measured using nvidia-smi and CPU and DRAM power draw were obtained using Intel‚Äôs RAPL.", "metadata": {}}, {"text": "Our measurements, in watts, are presented in Table 1.", "metadata": {}}, {"text": "As expected the GPU accounts for almost 3/4 of electricity\nconsumption.", "metadata": {}}, {"text": "Focus on GPUs.", "metadata": {}}, {"text": "In cloud datacenters, the CPUs, RAM, storage, and motherboards are often shared across multiple\ninstances;", "metadata": {}}, {"text": "while this provides the flexibility that makes the cloud so useful, it leads to technical limitations that make it\n1There is related work on estimating and reducing the electricity of data centers in general, e.g., [10, 24].", "metadata": {}}, {"text": "5", "metadata": {}}], "metadata": {"page": 5}}], "metadata": {"page": 5}}, {"title": "Page 6", "paragraphs": [{"text": "FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea Dodge et al.\nHardwa. GPU CPU0 CPU1 DRAM0 DRAM1 Total\nWatts 187.1 22.9 9.3 23.0 9.3 251.6\nFraction 74% 9% 4% 9% 4% 100%\nTable 1. The electricity consumption, in watts and percentages, when training BERT base on a single NVIDIA TITAN X GPU (12GB),\nin a commodity server with two Intel Xeon E5-2630 v3 CPUs (2.4GHz) and 256GB RAM (16x16GB DIMMs). Power consumption is\naveraged across instantaneous measurements over 12 hours of training on using the masked language modeling objective. The GPU\nalone accounts for 74% of the total energy consumption due to these components.\ndifficult (and in some cases impossible) to properly estimate electricity consumption from these sources for a single\ninstance. However, GPUs are typically not shared across instances, and in fact for large AI workloads it‚Äôs often the\ncase that multiple GPUs are attached to a single instance, leading to an even greater proportion of the total energy\nconsumption being used by the GPUs. Thus, it is relatively easy to measure the GPU electricity consumption for a\nsingle instance, while it is not for other components. For this reason, and because they typically consume the majority\nof electricity in AI workloads, in this work we only measure GPU electricity consumption. We recognize this is a first\nstep towards a more complete measurement, and provide further discussion in the next section.2\nOther sources of CO 2. Data centers have a number of electricity uses that are important, but will not be covered by\nour tool. According to the U.S. Department of Energy: ‚ÄúThe electricity consumed in these data centers is mainly by the\nequipment (50%) and HVAC (25%‚Äì40%)‚Äù [47]. Such other sources of emissions can be accounted for using methods\nsuch as Power Usage Effectiveness (PUE), which can be used to describe the proportion of electricity consumption\nby the computing equipment vs. other sources. For a given datacenter, this can be turned into a factor which can be\nmultiplied against the electricity consumption of computing equipment to get an estimate of the total consumption.\nSome companies have highlighted particularly low PUEs, such as Google claiming a PUE of 1.10 across its fleet of data\ncenters for the 12 months ending in Q1 2021,3 compared to an average global PUE of 1.59 [2].\nOther factors, such as the emissions produced by maintenance workers driving to and from the data center, emissions\nfrom manufacturing the computer systems, and emissions from building the structure in which the data center is\nhoused4 are non-negligible but beyond the scope of this paper. Finally, for workloads that do not use GPUs (e.g., storage\nor web hosting) we recommend users choose low emissions regions and times of day, as they will not have access to\nsingle-instance emissions calculations. We leave it open for future research to address how to appropriately allocate\nCO2 emissions from such data center-wide processes to individual reserved cloud instances.\n4 ELECTRICITY CONSUMPTION FOR AI WORKLOADS\nAs outlined in ¬ß3.1, calculating software carbon intensity begins with recording the electricity consumption, which\ncan then be mapped to emissions based on the emissions of the grid being used. In this section, we present data on\nelectricity consumption for experiments training 11 different models, covering natural language processing (NLP) and\ncomputer vision applications, ranging from less than an hour on a single GPU up to more than 8 days on 256 GPUs. We\noutline both the experiments themselves and their electricity consumption, and in the following section we use the\nelectricity consumption and carbon intensity tool described in the previous section to calculate their software carbon\nintensity.\n2We note that our conclusions drawn from experiments and analyses on time-shifting and location-shifting are still applicable with tools that measure\nmore electricity than just the GPU.\n3https://www.google.com/about/datacenters/efficiency/\n4One of the largest single source of CO2 emissions, contributing to 7%-8% of global emissions, is the production of cement [20].\n6", "sentences": [{"text": "FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea Dodge et al.", "metadata": {}}, {"text": "Hardwa.", "metadata": {}}, {"text": "GPU CPU0 CPU1 DRAM0 DRAM1 Total\nWatts 187.1 22.9 9.3 23.0 9.3 251.6\nFraction 74% 9% 4% 9% 4% 100%\nTable 1.", "metadata": {}}, {"text": "The electricity consumption, in watts and percentages, when training BERT base on a single NVIDIA TITAN X GPU (12GB),\nin a commodity server with two Intel Xeon E5-2630 v3 CPUs (2.4GHz) and 256GB RAM (16x16GB DIMMs).", "metadata": {}}, {"text": "Power consumption is\naveraged across instantaneous measurements over 12 hours of training on using the masked language modeling objective.", "metadata": {}}, {"text": "The GPU\nalone accounts for 74% of the total energy consumption due to these components.", "metadata": {}}, {"text": "difficult (and in some cases impossible) to properly estimate electricity consumption from these sources for a single\ninstance.", "metadata": {}}, {"text": "However, GPUs are typically not shared across instances, and in fact for large AI workloads it‚Äôs often the\ncase that multiple GPUs are attached to a single instance, leading to an even greater proportion of the total energy\nconsumption being used by the GPUs.", "metadata": {}}, {"text": "Thus, it is relatively easy to measure the GPU electricity consumption for a\nsingle instance, while it is not for other components.", "metadata": {}}, {"text": "For this reason, and because they typically consume the majority\nof electricity in AI workloads, in this work we only measure GPU electricity consumption.", "metadata": {}}, {"text": "We recognize this is a first\nstep towards a more complete measurement, and provide further discussion in the next section.2\nOther sources of CO 2.", "metadata": {}}, {"text": "Data centers have a number of electricity uses that are important, but will not be covered by\nour tool.", "metadata": {}}, {"text": "According to the U.S.", "metadata": {}}, {"text": "Department of Energy: ‚ÄúThe electricity consumed in these data centers is mainly by the\nequipment (50%) and HVAC (25%‚Äì40%)‚Äù [47].", "metadata": {}}, {"text": "Such other sources of emissions can be accounted for using methods\nsuch as Power Usage Effectiveness (PUE), which can be used to describe the proportion of electricity consumption\nby the computing equipment vs.", "metadata": {}}, {"text": "other sources.", "metadata": {}}, {"text": "For a given datacenter, this can be turned into a factor which can be\nmultiplied against the electricity consumption of computing equipment to get an estimate of the total consumption.", "metadata": {}}, {"text": "Some companies have highlighted particularly low PUEs, such as Google claiming a PUE of 1.10 across its fleet of data\ncenters for the 12 months ending in Q1 2021,3 compared to an average global PUE of 1.59 [2].", "metadata": {}}, {"text": "Other factors, such as the emissions produced by maintenance workers driving to and from the data center, emissions\nfrom manufacturing the computer systems, and emissions from building the structure in which the data center is\nhoused4 are non-negligible but beyond the scope of this paper.", "metadata": {}}, {"text": "Finally, for workloads that do not use GPUs (e.g., storage\nor web hosting) we recommend users choose low emissions regions and times of day, as they will not have access to\nsingle-instance emissions calculations.", "metadata": {}}, {"text": "We leave it open for future research to address how to appropriately allocate\nCO2 emissions from such data center-wide processes to individual reserved cloud instances.", "metadata": {}}, {"text": "4 ELECTRICITY CONSUMPTION FOR AI WORKLOADS\nAs outlined in ¬ß3.1, calculating software carbon intensity begins with recording the electricity consumption, which\ncan then be mapped to emissions based on the emissions of the grid being used.", "metadata": {}}, {"text": "In this section, we present data on\nelectricity consumption for experiments training 11 different models, covering natural language processing (NLP) and\ncomputer vision applications, ranging from less than an hour on a single GPU up to more than 8 days on 256 GPUs.", "metadata": {}}, {"text": "We\noutline both the experiments themselves and their electricity consumption, and in the following section we use the\nelectricity consumption and carbon intensity tool described in the previous section to calculate their software carbon\nintensity.", "metadata": {}}, {"text": "2We note that our conclusions drawn from experiments and analyses on time-shifting and location-shifting are still applicable with tools that measure\nmore electricity than just the GPU.", "metadata": {}}, {"text": "3https://www.google.com/about/datacenters/efficiency/\n4One of the largest single source of CO2 emissions, contributing to 7%-8% of global emissions, is the production of cement [20].", "metadata": {}}, {"text": "6", "metadata": {}}], "metadata": {"page": 6}}], "metadata": {"page": 6}}, {"title": "Page 7", "paragraphs": [{"text": "Measuring the Carbon Intensity of AI in Cloud Instances FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea\nModel BERT BERT 6B Dense Dense Dense ViT ViT ViT ViT ViT\nfinetune pretrain Transf. 121 169 201 Tiny Small Base Large Huge\nGPU 4¬∑V100 8¬∑V100 256¬∑A100 1¬∑P40 1¬∑P40 1¬∑P40 1¬∑V100 1¬∑V100 1¬∑V100 4¬∑V100 4¬∑V100\nHours 6 36 192 0.3 0.3 0.4 19 19 21 90 216\nkWh 3.1 37.3 13,812.4 0.02 0.03 0.04 1.7 2.2 4.7 93.3 237.6\nTable 2. For the 11 models in our analysis: the type of GPU, the number of GPUs of that type, the number of hours, and the energy\nused in kWh. For example, our BERT language modeling (BERT LM) experiment used 8 V100 GPUs for 36 hours and used a total of\n37.3 kWh. We note our training run of the 6 billion parameter transformer only trained for approximately 13% of the time it would\ntake to train to completion, we estimate a full training run would consume approximately 103,593 kWh.\n4.1 NLP\nBERT Training. We monitored the energy consumption while training a BERT-small model [8] for approximately 36\nhours on 8 NVIDIA V100 GPUs. That training run consumed over 37 kWh of electricity.\nBERT Finetuning. We tracked the energy consumption while finetuning the BERT-small model on a standard natural\nlanguage inference task [48, MNLI] for approximately 6 hours on 4 NVIDIA V100 GPUs. Our finetuning run consumed\naround 3.2 kWh of electricity, i.e., less than one tenth that due to BERT-small pre-training.\n6 Billion Parameter Transformer. We tracked the energy consumption of training a large language model comprising\nover 6.1 billion parameters during 8 days on 256 NVIDIA A100s. The total energy amounted to a staggering 13.8 MWh.\nThis model was not trained to completion, but only until 13%; a full training run would take 60 days. Thus, we estimate\nthe total energy consumption to train this model to completion would be approximately (60/8) ‚àó 13.8 = 103.5 MWh, or\n103,500 kWh ‚Äî almost 2800 times more than training the BERT-small model!\n4.2 Computer Vision\nDenseNets. We trained three sizes of DenseNets [19] on MNIST [25]. The jobs lasted between 20 and 25 minutes and\nconsumed between 20 and 38Wh (or 0.02 to 0.04 kWh) of electricity, which is negligible compared to the other models.\nVision Transformers. We evaluated the energy consumption during the training of five sizes of Vision Transformers [9]\non ImageNet [7]. For the smallest ViT experiment (ViT tiny), training lasted around 19 hours on a single V100 and\nconsumed approximately 1.7 kWh. For the largest one (ViT huge), training lasted more than 9 days on a 4 V100s and\nconsumed approximately 237 kWh. The full list of models can be found in Table 2.\n5 EMISSIONS BY REGION AND TIME OF DAY\nUsing the methodology presented above, we provide some of the first measurements of the differences of actual\ndatacenters from a major cloud provider. Importantly, what we have is a time series of marginal emissions: for example,\nif a job were to run from 1 pm to 5 pm in the US West region with a cloud instance that has four fully-utilized GPUs, both\nthe energy consumed and the marginal carbon intensity during that time is what we want to record. This time-series\ndata can estimate the cumulative emissions for that experiment at the end.\n5.1 Region\nHow much does the choice of datacenter region impact the emissions? And for a single region, how much variation\noccurs throughout the year? We address these questions in Figure 1, which shows carbon emissions that would be\n7", "sentences": [{"text": "Measuring the Carbon Intensity of AI in Cloud Instances FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea\nModel BERT BERT 6B Dense Dense Dense ViT ViT ViT ViT ViT\nfinetune pretrain Transf.", "metadata": {}}, {"text": "121 169 201 Tiny Small Base Large Huge\nGPU 4¬∑V100 8¬∑V100 256¬∑A100 1¬∑P40 1¬∑P40 1¬∑P40 1¬∑V100 1¬∑V100 1¬∑V100 4¬∑V100 4¬∑V100\nHours 6 36 192 0.3 0.3 0.4 19 19 21 90 216\nkWh 3.1 37.3 13,812.4 0.02 0.03 0.04 1.7 2.2 4.7 93.3 237.6\nTable 2.", "metadata": {}}, {"text": "For the 11 models in our analysis: the type of GPU, the number of GPUs of that type, the number of hours, and the energy\nused in kWh.", "metadata": {}}, {"text": "For example, our BERT language modeling (BERT LM) experiment used 8 V100 GPUs for 36 hours and used a total of\n37.3 kWh.", "metadata": {}}, {"text": "We note our training run of the 6 billion parameter transformer only trained for approximately 13% of the time it would\ntake to train to completion, we estimate a full training run would consume approximately 103,593 kWh.", "metadata": {}}, {"text": "4.1 NLP\nBERT Training.", "metadata": {}}, {"text": "We monitored the energy consumption while training a BERT-small model [8] for approximately 36\nhours on 8 NVIDIA V100 GPUs.", "metadata": {}}, {"text": "That training run consumed over 37 kWh of electricity.", "metadata": {}}, {"text": "BERT Finetuning.", "metadata": {}}, {"text": "We tracked the energy consumption while finetuning the BERT-small model on a standard natural\nlanguage inference task [48, MNLI] for approximately 6 hours on 4 NVIDIA V100 GPUs.", "metadata": {}}, {"text": "Our finetuning run consumed\naround 3.2 kWh of electricity, i.e., less than one tenth that due to BERT-small pre-training.", "metadata": {}}, {"text": "6 Billion Parameter Transformer.", "metadata": {}}, {"text": "We tracked the energy consumption of training a large language model comprising\nover 6.1 billion parameters during 8 days on 256 NVIDIA A100s.", "metadata": {}}, {"text": "The total energy amounted to a staggering 13.8 MWh.", "metadata": {}}, {"text": "This model was not trained to completion, but only until 13%;", "metadata": {}}, {"text": "a full training run would take 60 days.", "metadata": {}}, {"text": "Thus, we estimate\nthe total energy consumption to train this model to completion would be approximately (60/8) ‚àó 13.8 = 103.5 MWh, or\n103,500 kWh ‚Äî almost 2800 times more than training the BERT-small model!", "metadata": {}}, {"text": "4.2 Computer Vision\nDenseNets.", "metadata": {}}, {"text": "We trained three sizes of DenseNets [19] on MNIST [25].", "metadata": {}}, {"text": "The jobs lasted between 20 and 25 minutes and\nconsumed between 20 and 38Wh (or 0.02 to 0.04 kWh) of electricity, which is negligible compared to the other models.", "metadata": {}}, {"text": "Vision Transformers.", "metadata": {}}, {"text": "We evaluated the energy consumption during the training of five sizes of Vision Transformers [9]\non ImageNet [7].", "metadata": {}}, {"text": "For the smallest ViT experiment (ViT tiny), training lasted around 19 hours on a single V100 and\nconsumed approximately 1.7 kWh.", "metadata": {}}, {"text": "For the largest one (ViT huge), training lasted more than 9 days on a 4 V100s and\nconsumed approximately 237 kWh.", "metadata": {}}, {"text": "The full list of models can be found in Table 2.", "metadata": {}}, {"text": "5 EMISSIONS BY REGION AND TIME OF DAY\nUsing the methodology presented above, we provide some of the first measurements of the differences of actual\ndatacenters from a major cloud provider.", "metadata": {}}, {"text": "Importantly, what we have is a time series of marginal emissions: for example,\nif a job were to run from 1 pm to 5 pm in the US West region with a cloud instance that has four fully-utilized GPUs, both\nthe energy consumed and the marginal carbon intensity during that time is what we want to record.", "metadata": {}}, {"text": "This time-series\ndata can estimate the cumulative emissions for that experiment at the end.", "metadata": {}}, {"text": "5.1 Region\nHow much does the choice of datacenter region impact the emissions?", "metadata": {}}, {"text": "And for a single region, how much variation\noccurs throughout the year?", "metadata": {}}, {"text": "We address these questions in Figure 1, which shows carbon emissions that would be\n7", "metadata": {}}], "metadata": {"page": 7}}], "metadata": {"page": 7}}, {"title": "Page 8", "paragraphs": [{"text": "FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea Dodge et al.\nFig. 1. Carbon emissions that would be emitted from training BERT (language modeling on 8 V100s for 36 hours) in 16 different\nregions (one region per line) at different times throughout the year. Each line is relatively flat, indicating the emissions in a single\nregion during different months are relatively similar. There is large variation between the least carbon-intensive regions (the lowest\nlines) compared to the most carbon-intensive regions (the top lines), indicating that choosing the region in which experiments run\ncan be very impactful ( 7k grams vs. 26k grams, for the most efficient vs. least efficient regions).\nemitted from training BERT (see ¬ß4 for more details) on 8 V100 GPUs for 36 hours in 16 different regions (one region\nper line) at different times throughout the year.\nWhat do emissions look like across the 11 experiments described in ¬ß4? In Figure 2 we show results for all 11\nexperiments, which cover two BERT experiments (finetuning and language modeling), partial training of a 6.1 billion\nparameter Transformer, 3 sizes of DenseNets, and five sizes of Vision Transformers. Each experiment is represented by\na vertical blue bar showing the range of emissions that would be emitted for that experiment across different regions.\nThe top of the blue bar is the emissions from running that experiment in the region with the most emissions, the bottom\nis the emissions from running that experiment in the region with the least emissions, the black line represents the\naverage, and the light blue regions are the top and bottom quartiles.\nIn Figure 2 we also include estimates of equivalent sources of emissions per the United States Environmental\nProtection Agency [46]. One phone charge is estimated to emit 8.22 √ó 10‚àí6 metric tons (using US national weighted\naverage CO2 marginal emission rate for delivered electricity), one mile driven is estimated to emit 3.98 √ó 10‚àí4 metric\ntons (using average US passenger vehicle, which gets 22.5 miles per gallon of gasoline), one gallon of gasoline consumed\nis estimated to emit 8.887 √ó 10‚àí3 metric tons, one barrel of crude oil consumed is estimated to emit 0.43 metric tons,\none average US home energy use is estimated to emit 8.30 metric tons (using the sum of emissions from generating\nelectricity, natural gas, liquid petroleum, and fuel oil), and one rail car of coal is estimated to emit 181.29 metric tons.\n8", "sentences": [{"text": "FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea Dodge et al.", "metadata": {}}, {"text": "Fig.", "metadata": {}}, {"text": "1.", "metadata": {}}, {"text": "Carbon emissions that would be emitted from training BERT (language modeling on 8 V100s for 36 hours) in 16 different\nregions (one region per line) at different times throughout the year.", "metadata": {}}, {"text": "Each line is relatively flat, indicating the emissions in a single\nregion during different months are relatively similar.", "metadata": {}}, {"text": "There is large variation between the least carbon-intensive regions (the lowest\nlines) compared to the most carbon-intensive regions (the top lines), indicating that choosing the region in which experiments run\ncan be very impactful ( 7k grams vs.", "metadata": {}}, {"text": "26k grams, for the most efficient vs.", "metadata": {}}, {"text": "least efficient regions).", "metadata": {}}, {"text": "emitted from training BERT (see ¬ß4 for more details) on 8 V100 GPUs for 36 hours in 16 different regions (one region\nper line) at different times throughout the year.", "metadata": {}}, {"text": "What do emissions look like across the 11 experiments described in ¬ß4?", "metadata": {}}, {"text": "In Figure 2 we show results for all 11\nexperiments, which cover two BERT experiments (finetuning and language modeling), partial training of a 6.1 billion\nparameter Transformer, 3 sizes of DenseNets, and five sizes of Vision Transformers.", "metadata": {}}, {"text": "Each experiment is represented by\na vertical blue bar showing the range of emissions that would be emitted for that experiment across different regions.", "metadata": {}}, {"text": "The top of the blue bar is the emissions from running that experiment in the region with the most emissions, the bottom\nis the emissions from running that experiment in the region with the least emissions, the black line represents the\naverage, and the light blue regions are the top and bottom quartiles.", "metadata": {}}, {"text": "In Figure 2 we also include estimates of equivalent sources of emissions per the United States Environmental\nProtection Agency [46].", "metadata": {}}, {"text": "One phone charge is estimated to emit 8.22 √ó 10‚àí6 metric tons (using US national weighted\naverage CO2 marginal emission rate for delivered electricity), one mile driven is estimated to emit 3.98 √ó 10‚àí4 metric\ntons (using average US passenger vehicle, which gets 22.5 miles per gallon of gasoline), one gallon of gasoline consumed\nis estimated to emit 8.887 √ó 10‚àí3 metric tons, one barrel of crude oil consumed is estimated to emit 0.43 metric tons,\none average US home energy use is estimated to emit 8.30 metric tons (using the sum of emissions from generating\nelectricity, natural gas, liquid petroleum, and fuel oil), and one rail car of coal is estimated to emit 181.29 metric tons.", "metadata": {}}, {"text": "8", "metadata": {}}], "metadata": {"page": 8}}, {"text": "[Image page=8 idx=1 name=Im1.png] Size: 2942x1683, Data: 515704 bytes", "sentences": [{"text": "[Image page=8 idx=1 name=Im1.png] Size: 2942x1683, Data: 515704 bytes", "metadata": {}}], "metadata": {"page": 8, "image_index": 1, "image_name": "Im1.png", "image_width": 2942, "image_height": 1683, "attachment_type": "image", "has_image_data": true, "image_data_size": 515704}}], "metadata": {"page": 8}}, {"title": "Page 9", "paragraphs": [{"text": "Measuring the Carbon Intensity of AI in Cloud Instances FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea\nFig. 2. Emissions for our 11 experiments described in ¬ß4. For each model we show a vertical blue bar, where the top of the bar is\nthe max, the bottom is the min, and the black line represents the average emissions (across regions and time of year). First and\nfourth quartiles are represented by the light blue at the top and bottom of each vertical blue bar. The largest training runs (e.g., 6\nbillion parameter LM) releases a significant amount of emissions, no matter the region (and recall the 6 billion parameter LM is only\ntrained for 13% of a full run, so a full run would emit about an order of magnitude more emissions than reported here). The smallest\nexperiments emit very little. Presented on a log scale, with references on the right indicating equivalent sources of emissions per the\nUnited States Environmental Protection Agency [46].\nThe largest experiment in our set is the 6 billion parameter transformer, and that model is only partially trained (as\ndescribed in ¬ß4, it is only trained for about 13% of the time needed to converge). Even partially trained, experiments of\nthis size can emit more CO2 than all emissions from the average US home for a year (which includes emissions from\nelectricity generation, natural gas, liquid petroleum gas, and fuel oil, totaling 8.3 metric tons CO2 per year). Perhaps\nunsurprisingly, even the most efficient region of those we examined for that experiment still leads to more emissions\nthan a full barrel of oil. If this had been trained to completion, we estimate it would have emitted 21 to 78 metric tons of\nCO2 (depending on the region it was run in).\nComparing against previous work on measuring emissions can be challenging without full information about data\nand model parallelism, GPU utilization, the number of weight updates, and other relevant factors; while we don‚Äôt have\nexperiments covering the same models as previous work on estimating CO2, we can make approximate comparisons\nalong three dimensions: a) kWh per GPU hour, b) CO 2 grams per GPU hour, and c) CO 2 grams per kWh. Here we\ncompare against [34] and [33] which report information about training especially large models. Their estimates also\n9", "sentences": [{"text": "Measuring the Carbon Intensity of AI in Cloud Instances FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea\nFig.", "metadata": {}}, {"text": "2.", "metadata": {}}, {"text": "Emissions for our 11 experiments described in ¬ß4.", "metadata": {}}, {"text": "For each model we show a vertical blue bar, where the top of the bar is\nthe max, the bottom is the min, and the black line represents the average emissions (across regions and time of year).", "metadata": {}}, {"text": "First and\nfourth quartiles are represented by the light blue at the top and bottom of each vertical blue bar.", "metadata": {}}, {"text": "The largest training runs (e.g., 6\nbillion parameter LM) releases a significant amount of emissions, no matter the region (and recall the 6 billion parameter LM is only\ntrained for 13% of a full run, so a full run would emit about an order of magnitude more emissions than reported here).", "metadata": {}}, {"text": "The smallest\nexperiments emit very little.", "metadata": {}}, {"text": "Presented on a log scale, with references on the right indicating equivalent sources of emissions per the\nUnited States Environmental Protection Agency [46].", "metadata": {}}, {"text": "The largest experiment in our set is the 6 billion parameter transformer, and that model is only partially trained (as\ndescribed in ¬ß4, it is only trained for about 13% of the time needed to converge).", "metadata": {}}, {"text": "Even partially trained, experiments of\nthis size can emit more CO2 than all emissions from the average US home for a year (which includes emissions from\nelectricity generation, natural gas, liquid petroleum gas, and fuel oil, totaling 8.3 metric tons CO2 per year).", "metadata": {}}, {"text": "Perhaps\nunsurprisingly, even the most efficient region of those we examined for that experiment still leads to more emissions\nthan a full barrel of oil.", "metadata": {}}, {"text": "If this had been trained to completion, we estimate it would have emitted 21 to 78 metric tons of\nCO2 (depending on the region it was run in).", "metadata": {}}, {"text": "Comparing against previous work on measuring emissions can be challenging without full information about data\nand model parallelism, GPU utilization, the number of weight updates, and other relevant factors;", "metadata": {}}, {"text": "while we don‚Äôt have\nexperiments covering the same models as previous work on estimating CO2, we can make approximate comparisons\nalong three dimensions: a) kWh per GPU hour, b) CO 2 grams per GPU hour, and c) CO 2 grams per kWh.", "metadata": {}}, {"text": "Here we\ncompare against [34] and [33] which report information about training especially large models.", "metadata": {}}, {"text": "Their estimates also\n9", "metadata": {}}], "metadata": {"page": 9}}, {"text": "[Image page=9 idx=1 name=Im2.png] Size: 2814x1943, Data: 175292 bytes", "sentences": [{"text": "[Image page=9 idx=1 name=Im2.png] Size: 2814x1943, Data: 175292 bytes", "metadata": {}}], "metadata": {"page": 9, "image_index": 1, "image_name": "Im2.png", "image_width": 2814, "image_height": 1943, "attachment_type": "image", "has_image_data": true, "image_data_size": 175292}}], "metadata": {"page": 9}}, {"title": "Page 10", "paragraphs": [{"text": "FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea Dodge et al.\ninclude additional sources of CO2, like PUE (Power Usage Effectiveness) of their datacenters, so we expect their kWh per\nGPU hour and CO2 per GPU hour to be higher than our estimates (which only count the GPU electricity consumption).\nAcross our experiments, we find kWh per GPU hour to range from 0.07 to 0.28, compared to Patterson et al. [34]\nwith 0.22 to 0.47, and Patterson et al. [33] with 0.36. We find CO2 (grams) per GPU hour in the most efficient region to\naverage 34, and in the least efficient region to average 128, where Patterson et al. [34] found a range of 63 to 202, and\nPatterson et al. [33] found 32. We find CO2 (grams) per kWh in the most efficient region to average 200, and in the least\nefficient region to average 755. The estimates from Patterson et al. [34] range between 427 and 545 (except GShard 600B\nwith 200), and Patterson et al. [33] found 88. In short, we find most of their estimates to be within the range of ours,\nwith the exception of Patterson et al. [33], which specifically aimed to choose a region that was more CO2 efficient.\nHour 0:00 03:00 06:00 09:00 12:00 15:00 18:00 21:00\nBERT Central Day 1 2,381 2,341 2,210 2,252 2,354 2,391 2,410 2,403\nfinetune US Day 2 2,330 2,249 2,204 2,299 2,320 2,317 2,339 2,344\nDay 3 2,430 2,339 2,257 2,313 2,393 2,374 2,317 2,331\nTable 3. How do emissions vary throughout different times of day? We present the emissions produced by the BERT finetuning\nexperiment described in ¬ß4 had it run at different times in the Central US region, on three separate days.\n5.2 Time of Day\nWhile the choice of region is a major source of variation in CO 2 emissions, diurnal variations also play a signifi-\ncant role. During the day, a region may have a higher mix of renewable energy or fossil-fuel based source [ 6]. As\none can see in Table 3, depending on the day, starting the BERT finetuning at, e.g., midnight instead of 6:00 can\nresult in carbon emissions increasing by up to 8%. The amount of variation varies by region and time of year as\nwell.\n6 OPTIMIZING CLOUD WORKLOADS\nWe use the tools presented so far to evaluate two algorithms for reducing emissions of AI workloads on the Microsoft\nAzure cloud compute platform using temporal shifting. We consider sixteen regions where workloads can be scheduled\non Azure: nine in North America, six in Europe and one in Australia (see Figure 3). For each region, we obtained from\nWattTime the historical marginal carbon emissions for the year 2020 at a 5-minute granularity. We also measured the\nelectricity consumption per 5-minute intervals of the various models introduced in ¬ß4. The two optimization methods\nwe studied are:\n‚Ä¢ Flexible Start. Start the workload at the time, in the next ùëÅ hours, that minimizes its carbon emissions. Once the\nworkload is launched, it is run until completion. Implementation: Consider all possible start times (in 5 minute\nincrements) in the desired window. For each start time, compute the job‚Äôs corresponding emissions and pick the\nlowest.\n‚Ä¢ Pause and Resume . Assuming the workload can be stopped and restarted (a fairly weak constraint), run its\ncomputations over the next (ùëÅ + job duration) hours while minimizing its total carbon emissions. This involves\npausing and resuming the job, possibly multiple times, to avoid consuming energy when carbon intensity is high.\nImplementation: Find the 5 minute intervals with the lowest marginal emissions during the (ùëÅ + job duration)\nhour window, and select enough intervals to add up to the job duration. Then simulate running the job only\n10", "sentences": [{"text": "FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea Dodge et al.", "metadata": {}}, {"text": "include additional sources of CO2, like PUE (Power Usage Effectiveness) of their datacenters, so we expect their kWh per\nGPU hour and CO2 per GPU hour to be higher than our estimates (which only count the GPU electricity consumption).", "metadata": {}}, {"text": "Across our experiments, we find kWh per GPU hour to range from 0.07 to 0.28, compared to Patterson et al.", "metadata": {}}, {"text": "[34]\nwith 0.22 to 0.47, and Patterson et al.", "metadata": {}}, {"text": "[33] with 0.36.", "metadata": {}}, {"text": "We find CO2 (grams) per GPU hour in the most efficient region to\naverage 34, and in the least efficient region to average 128, where Patterson et al.", "metadata": {}}, {"text": "[34] found a range of 63 to 202, and\nPatterson et al.", "metadata": {}}, {"text": "[33] found 32.", "metadata": {}}, {"text": "We find CO2 (grams) per kWh in the most efficient region to average 200, and in the least\nefficient region to average 755.", "metadata": {}}, {"text": "The estimates from Patterson et al.", "metadata": {}}, {"text": "[34] range between 427 and 545 (except GShard 600B\nwith 200), and Patterson et al.", "metadata": {}}, {"text": "[33] found 88.", "metadata": {}}, {"text": "In short, we find most of their estimates to be within the range of ours,\nwith the exception of Patterson et al.", "metadata": {}}, {"text": "[33], which specifically aimed to choose a region that was more CO2 efficient.", "metadata": {}}, {"text": "Hour 0:00 03:00 06:00 09:00 12:00 15:00 18:00 21:00\nBERT Central Day 1 2,381 2,341 2,210 2,252 2,354 2,391 2,410 2,403\nfinetune US Day 2 2,330 2,249 2,204 2,299 2,320 2,317 2,339 2,344\nDay 3 2,430 2,339 2,257 2,313 2,393 2,374 2,317 2,331\nTable 3.", "metadata": {}}, {"text": "How do emissions vary throughout different times of day?", "metadata": {}}, {"text": "We present the emissions produced by the BERT finetuning\nexperiment described in ¬ß4 had it run at different times in the Central US region, on three separate days.", "metadata": {}}, {"text": "5.2 Time of Day\nWhile the choice of region is a major source of variation in CO 2 emissions, diurnal variations also play a signifi-\ncant role.", "metadata": {}}, {"text": "During the day, a region may have a higher mix of renewable energy or fossil-fuel based source [ 6].", "metadata": {}}, {"text": "As\none can see in Table 3, depending on the day, starting the BERT finetuning at, e.g., midnight instead of 6:00 can\nresult in carbon emissions increasing by up to 8%.", "metadata": {}}, {"text": "The amount of variation varies by region and time of year as\nwell.", "metadata": {}}, {"text": "6 OPTIMIZING CLOUD WORKLOADS\nWe use the tools presented so far to evaluate two algorithms for reducing emissions of AI workloads on the Microsoft\nAzure cloud compute platform using temporal shifting.", "metadata": {}}, {"text": "We consider sixteen regions where workloads can be scheduled\non Azure: nine in North America, six in Europe and one in Australia (see Figure 3).", "metadata": {}}, {"text": "For each region, we obtained from\nWattTime the historical marginal carbon emissions for the year 2020 at a 5-minute granularity.", "metadata": {}}, {"text": "We also measured the\nelectricity consumption per 5-minute intervals of the various models introduced in ¬ß4.", "metadata": {}}, {"text": "The two optimization methods\nwe studied are:\n‚Ä¢ Flexible Start.", "metadata": {}}, {"text": "Start the workload at the time, in the next ùëÅ hours, that minimizes its carbon emissions.", "metadata": {}}, {"text": "Once the\nworkload is launched, it is run until completion.", "metadata": {}}, {"text": "Implementation: Consider all possible start times (in 5 minute\nincrements) in the desired window.", "metadata": {}}, {"text": "For each start time, compute the job‚Äôs corresponding emissions and pick the\nlowest.", "metadata": {}}, {"text": "‚Ä¢ Pause and Resume .", "metadata": {}}, {"text": "Assuming the workload can be stopped and restarted (a fairly weak constraint), run its\ncomputations over the next (ùëÅ + job duration) hours while minimizing its total carbon emissions.", "metadata": {}}, {"text": "This involves\npausing and resuming the job, possibly multiple times, to avoid consuming energy when carbon intensity is high.", "metadata": {}}, {"text": "Implementation: Find the 5 minute intervals with the lowest marginal emissions during the (ùëÅ + job duration)\nhour window, and select enough intervals to add up to the job duration.", "metadata": {}}, {"text": "Then simulate running the job only\n10", "metadata": {}}], "metadata": {"page": 10}}], "metadata": {"page": 10}}, {"title": "Page 11", "paragraphs": [{"text": "Measuring the Carbon Intensity of AI in Cloud Instances FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n10\n20\n30\n40\n50\n60\n70\n80CO2 emissions decrease in %\n6h\n12h\n18h\n24h\n(a) Flexible Start optimization for Dense 201.\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\n1.2\n1.4CO2 emissions decrease in %\n6h\n12h\n18h\n24h (b) Flexible Start optimization for 6B parameters Transformer.\nFig. 3. What proportion of emissions can we expect to save if we change the start time by up to 24 hours? For very short experiments\nlike DenseNet 201 (a), which ran for less than half an hour, we can find significant reduction, greater than 30% in multiple regions,\nand up to 80% in West US; for very long runs like training a 6 billion parameter language model for 8 days (b), changing the start time\nby up to 24 hours leads to less than 1.5% reduction at best in any region. Note: we confirmed with WattTime that emissions estimates\nfor West US were correct, that region has large variance.\nduring those intervals and compute the corresponding emissions. We explored two sets of values for ùëÅ : one\nabsolute, corresponding to increasing the total duration of the job by at most {6, 12, 18, 24} hours; and a second\none relative, where we allow the job to increase in duration by at most {25%, 50%, 75%, 100%}. In other words,\nfor the second set, we allow the workload to last for at most twice its duration had it not been stopped. While\narbitrary, we motivate the choice of those two sets by the extreme range of possible job duration (from minutes to\nweeks). Note that we assume pausing and restarting the job is immediate and does not consume additional energy:\nthis is similar in spirit (for carbon emissions) to Spot Instances on existing cloud platforms which automatically\npause an instance if its price rises above a threshold set by the user.\nWe find the region that the algorithms are evaluated in has a significant impact. For example, the region we labeled\nWest US varies frequently throughout a single day between periods of high emissions and very low emissions, and\nthus Pause and Resume can lead to significant reductions. However, other regions do not present as much variance,\nand thus lead to less reduction in emissions. See Figures 3 and 4. The lack of geographic diversity in the region list is\nan unfortunate consequence of the unavailability of carbon intensity data from other continents; we hope such data\nbecomes broadly available in the near future.\n6.1 Evaluation of Emissions Reduction Algorithms\nWe evaluate how the two optimization algorithms would impact the emissions from the 11 experiments described in ¬ß4.\nIn order to account for daily variations (weather, electricity demand, etc.), we report the average emissions decrease\ncomputed over 5 different start times in each month, giving a total of 60 data points.\n6.1.1 Emissions Reduction by Region.\nFlexible Start. When evaluating the Flexible Start algorithm for a fixed duration between 6 hours and 24 hours, we\nfind significant emissions reductions for shorter jobs (e.g., the DenseNet experiments), with minimal savings for jobs\n11", "sentences": [{"text": "Measuring the Carbon Intensity of AI in Cloud Instances FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea\nEast USWest USWest US2West US3Central US\nN.", "metadata": {}}, {"text": "Central USS.", "metadata": {}}, {"text": "Central USW.", "metadata": {}}, {"text": "Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n10\n20\n30\n40\n50\n60\n70\n80CO2 emissions decrease in %\n6h\n12h\n18h\n24h\n(a) Flexible Start optimization for Dense 201.", "metadata": {}}, {"text": "East USWest USWest US2West US3Central US\nN.", "metadata": {}}, {"text": "Central USS.", "metadata": {}}, {"text": "Central USW.", "metadata": {}}, {"text": "Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\n1.2\n1.4CO2 emissions decrease in %\n6h\n12h\n18h\n24h (b) Flexible Start optimization for 6B parameters Transformer.", "metadata": {}}, {"text": "Fig.", "metadata": {}}, {"text": "3.", "metadata": {}}, {"text": "What proportion of emissions can we expect to save if we change the start time by up to 24 hours?", "metadata": {}}, {"text": "For very short experiments\nlike DenseNet 201 (a), which ran for less than half an hour, we can find significant reduction, greater than 30% in multiple regions,\nand up to 80% in West US;", "metadata": {}}, {"text": "for very long runs like training a 6 billion parameter language model for 8 days (b), changing the start time\nby up to 24 hours leads to less than 1.5% reduction at best in any region.", "metadata": {}}, {"text": "Note: we confirmed with WattTime that emissions estimates\nfor West US were correct, that region has large variance.", "metadata": {}}, {"text": "during those intervals and compute the corresponding emissions.", "metadata": {}}, {"text": "We explored two sets of values for ùëÅ : one\nabsolute, corresponding to increasing the total duration of the job by at most {6, 12, 18, 24} hours;", "metadata": {}}, {"text": "and a second\none relative, where we allow the job to increase in duration by at most {25%, 50%, 75%, 100%}.", "metadata": {}}, {"text": "In other words,\nfor the second set, we allow the workload to last for at most twice its duration had it not been stopped.", "metadata": {}}, {"text": "While\narbitrary, we motivate the choice of those two sets by the extreme range of possible job duration (from minutes to\nweeks).", "metadata": {}}, {"text": "Note that we assume pausing and restarting the job is immediate and does not consume additional energy:\nthis is similar in spirit (for carbon emissions) to Spot Instances on existing cloud platforms which automatically\npause an instance if its price rises above a threshold set by the user.", "metadata": {}}, {"text": "We find the region that the algorithms are evaluated in has a significant impact.", "metadata": {}}, {"text": "For example, the region we labeled\nWest US varies frequently throughout a single day between periods of high emissions and very low emissions, and\nthus Pause and Resume can lead to significant reductions.", "metadata": {}}, {"text": "However, other regions do not present as much variance,\nand thus lead to less reduction in emissions.", "metadata": {}}, {"text": "See Figures 3 and 4.", "metadata": {}}, {"text": "The lack of geographic diversity in the region list is\nan unfortunate consequence of the unavailability of carbon intensity data from other continents;", "metadata": {}}, {"text": "we hope such data\nbecomes broadly available in the near future.", "metadata": {}}, {"text": "6.1 Evaluation of Emissions Reduction Algorithms\nWe evaluate how the two optimization algorithms would impact the emissions from the 11 experiments described in ¬ß4.", "metadata": {}}, {"text": "In order to account for daily variations (weather, electricity demand, etc.), we report the average emissions decrease\ncomputed over 5 different start times in each month, giving a total of 60 data points.", "metadata": {}}, {"text": "6.1.1 Emissions Reduction by Region.", "metadata": {}}, {"text": "Flexible Start.", "metadata": {}}, {"text": "When evaluating the Flexible Start algorithm for a fixed duration between 6 hours and 24 hours, we\nfind significant emissions reductions for shorter jobs (e.g., the DenseNet experiments), with minimal savings for jobs\n11", "metadata": {}}], "metadata": {"page": 11}}], "metadata": {"page": 11}}, {"title": "Page 12", "paragraphs": [{"text": "FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea Dodge et al.\nthat are longer than a day; this aligns with our expectations, as short jobs can be run when emissions are lowest\nthroughout a day, but long jobs naturally average across multiple days. See Figure 3, with results for all experiments\nin the appendix. This analysis is designed to highlight a use case where an AI workload needs to run regularly, but\nthe practitioner has some flexibility on when it runs (so it could, e.g., run over night, if that is when carbon intensity\nis lowest). This is in fact a common use case in production ML systems deployed at companies, where models are\nre-trained on a regular schedule to incorporate new data over time [16].\nPause and Resume. When evaluating the Pause and Resume algorithm for durations up to 100% of the duration of the\noriginal experiment, we find the opposite of the Flexible Start result: short experiments like DenseNet 201 only see\nemissions reductions smaller than 10%, while the 6 billion transformer training run (our experiment with the largest\ncarbon intensity) actually sees the largest decrease in emissions. See Figure 4 for two examples, with results for all 11\nexperiments in the appendix. This analysis is designed to highlight a use case where an AI workload can be increased\nin duration by some proportion of the original run time.\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n1\n2\n3\n4\n5\n6\n7\n8CO2 emissions decrease in %\n25%\n50%\n75%\n100%\n(a) Pause and Resume optimization for Dense 201.\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n5\n10\n15\n20\n25\n30CO2 emissions decrease in %\n25%\n50%\n75%\n100% (b) Pause and Resume optimization for 6B parameters Transformer.\nFig. 4. What proportion of emissions can we expect to save if we pause an AI workload when emissions in a region are high and\nresume when emissions are low, increasing the total duration by up to double the original duration? For short experiments, the\ndoubled duration is still relatively short, and thus leads to minimal emissions reduction (see DenseNet 201 in (a)); for very long runs\nlike our 6 billion parameter language model training run in (b), which ran for 8 days, doubling the duration can lead to significant\nsavings up to about 25%. We confirmed with WattTime that emissions estimates for West US were correct, as that region has large\nvariance.\n6.1.2 Comparable Duration Increases. In the previous section we examined the amount of emissions reduction for\nour two algorithms by region, and compared Pause and Resume increasing duration by a proportion of the original\nexperiment and Flexible Start by a fixed duration. Here we evaluate the two algorithms when they increase the duration\nof an AI workload by the same amount (each result is averaged across all regions and times of year). One can think\nof the Flexible Start algorithm as a version of Pause and Resume where there is only one start time, and no pausing\nallowed; thus we should expect the Flexible Start results to always lower bound the Pause and Resume ones.\nWe show results for both algorithms and two situations: increasing the duration of the run by 24 hours in Table 4,\nand by 100% in Table 5. In these tables we also include information about the average number of pauses per hour for\nthe Pause and Resume algorithm. Perhaps surprisingly, we find the average number of pauses is quite low. This can be\n12", "sentences": [{"text": "FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea Dodge et al.", "metadata": {}}, {"text": "that are longer than a day;", "metadata": {}}, {"text": "this aligns with our expectations, as short jobs can be run when emissions are lowest\nthroughout a day, but long jobs naturally average across multiple days.", "metadata": {}}, {"text": "See Figure 3, with results for all experiments\nin the appendix.", "metadata": {}}, {"text": "This analysis is designed to highlight a use case where an AI workload needs to run regularly, but\nthe practitioner has some flexibility on when it runs (so it could, e.g., run over night, if that is when carbon intensity\nis lowest).", "metadata": {}}, {"text": "This is in fact a common use case in production ML systems deployed at companies, where models are\nre-trained on a regular schedule to incorporate new data over time [16].", "metadata": {}}, {"text": "Pause and Resume.", "metadata": {}}, {"text": "When evaluating the Pause and Resume algorithm for durations up to 100% of the duration of the\noriginal experiment, we find the opposite of the Flexible Start result: short experiments like DenseNet 201 only see\nemissions reductions smaller than 10%, while the 6 billion transformer training run (our experiment with the largest\ncarbon intensity) actually sees the largest decrease in emissions.", "metadata": {}}, {"text": "See Figure 4 for two examples, with results for all 11\nexperiments in the appendix.", "metadata": {}}, {"text": "This analysis is designed to highlight a use case where an AI workload can be increased\nin duration by some proportion of the original run time.", "metadata": {}}, {"text": "East USWest USWest US2West US3Central US\nN.", "metadata": {}}, {"text": "Central USS.", "metadata": {}}, {"text": "Central USW.", "metadata": {}}, {"text": "Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n1\n2\n3\n4\n5\n6\n7\n8CO2 emissions decrease in %\n25%\n50%\n75%\n100%\n(a) Pause and Resume optimization for Dense 201.", "metadata": {}}, {"text": "East USWest USWest US2West US3Central US\nN.", "metadata": {}}, {"text": "Central USS.", "metadata": {}}, {"text": "Central USW.", "metadata": {}}, {"text": "Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n5\n10\n15\n20\n25\n30CO2 emissions decrease in %\n25%\n50%\n75%\n100% (b) Pause and Resume optimization for 6B parameters Transformer.", "metadata": {}}, {"text": "Fig.", "metadata": {}}, {"text": "4.", "metadata": {}}, {"text": "What proportion of emissions can we expect to save if we pause an AI workload when emissions in a region are high and\nresume when emissions are low, increasing the total duration by up to double the original duration?", "metadata": {}}, {"text": "For short experiments, the\ndoubled duration is still relatively short, and thus leads to minimal emissions reduction (see DenseNet 201 in (a));", "metadata": {}}, {"text": "for very long runs\nlike our 6 billion parameter language model training run in (b), which ran for 8 days, doubling the duration can lead to significant\nsavings up to about 25%.", "metadata": {}}, {"text": "We confirmed with WattTime that emissions estimates for West US were correct, as that region has large\nvariance.", "metadata": {}}, {"text": "6.1.2 Comparable Duration Increases.", "metadata": {}}, {"text": "In the previous section we examined the amount of emissions reduction for\nour two algorithms by region, and compared Pause and Resume increasing duration by a proportion of the original\nexperiment and Flexible Start by a fixed duration.", "metadata": {}}, {"text": "Here we evaluate the two algorithms when they increase the duration\nof an AI workload by the same amount (each result is averaged across all regions and times of year).", "metadata": {}}, {"text": "One can think\nof the Flexible Start algorithm as a version of Pause and Resume where there is only one start time, and no pausing\nallowed;", "metadata": {}}, {"text": "thus we should expect the Flexible Start results to always lower bound the Pause and Resume ones.", "metadata": {}}, {"text": "We show results for both algorithms and two situations: increasing the duration of the run by 24 hours in Table 4,\nand by 100% in Table 5.", "metadata": {}}, {"text": "In these tables we also include information about the average number of pauses per hour for\nthe Pause and Resume algorithm.", "metadata": {}}, {"text": "Perhaps surprisingly, we find the average number of pauses is quite low.", "metadata": {}}, {"text": "This can be\n12", "metadata": {}}], "metadata": {"page": 12}}], "metadata": {"page": 12}}, {"title": "Page 13", "paragraphs": [{"text": "Measuring the Carbon Intensity of AI in Cloud Instances FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea\ninterpreted as the number of times the carbon intensity crosses above the threshold minimizing total emissions being\nsmall.\nModel BERT BERT 6B Dense Dense Dense ViT ViT ViT ViT ViT\nfinetune LM Transf. 121 169 201 Tiny Small Base Large Huge\nFS 14.5% 3.4% 0.5% 26.8% 26.4% 25.9% 5.6% 5.3% 4.2% 1.3% 0.5%\nP&R 19.0% 8.5% 2.5% 27.7% 27.3% 27.1% 12.5% 12.3% 11.7% 4.7% 2.4%\nPauses / hr 0.23 0.3 0.15 0.06 0.07 0.08 0.3 0.3 0.3 0.23 0.14\nTable 4. For the 11 models in our analysis: the gain in percent averaged over the year and across the 16 regions for the Flexible Start\n(FS) and Pause and Resume (P&R) optimizations allowing for a 24h increase in job duration. The last line represents the average\nnumber of pauses per hour performed by the P&R optimization.\nNote that the above optimizations were performed using historical data, meaning that their results are the best\nachievable, assuming access to an oracle predicting carbon intensity perfectly. WattTime currently provides marginal\nemission rate estimates and forecasts for up to 24 hours, so for short workloads, our findings will reflect gains observed\nin practice using the forecasts. For longer workloads, our numbers give an upper bound on the realizable gains. For\nexample, the Pause and Resume algorithm pauses the workload when emissions are above a threshold, and resumes\nwhen emissions are below that threshold. In our evaluation here we set this threshold such that the total run time is\nincreased by, e.g., 24 hours; a machine learning practitioner would have to estimate how much a particular threshold\nwould increase job duration, but would not know exactly. The dynamic nature of the Pause and Resume optimizations\nsuggests that well-designed scheduling algorithms should be able to get rather close to the upper-bound. We leave such\nalgorithms to future work and hope our tools can inspire further research into that type of scheduling. Moreover, it is\nlikely that carbon intensity forecasting will improve over the years and eventually extend beyond 24 hours, allowing\ntime-shifting decisions to become increasingly accurate.\nModel BERT BERT 6B Dense Dense Dense ViT ViT ViT ViT ViT\nfinetune LM Transf. 121 169 201 Tiny Small Base Large Huge\nFS 7.0% 4.1% 2.6% 1.8% 2.5% 2.7% 5.0% 4.8% 3.9% 3.3% 3.0%\nP&R 9.5% 11.0% 11.4% 2.0% 2.8% 3.1% 11.0% 11.0% 10.8% 11.4% 11.3%\nPauses / hr 0.42 0.29 0.27 1.5 1.88 2.0 0.31 0.32 0.31 0.27 0.26\nTable 5. For the 11 models in our analysis: the gain in percent averaged over the year and across the 16 regions for the Flexible Start\n(FS) and Pause and Resume (P&R) optimizations allowing for a 100% increase in job duration. The last line represents the average\nnumber of pauses per hour performed by the P&R optimization.\n7 CONSIDERATIONS FOR MODEL DEVELOPMENT AND DEPLOYMENT\nGenerally speaking, we advocate that researchers and practitioners record and report the amount of emissions incurred\nby ML projects, starting with the initial exploratory training phases all the way through hyperparameter tuning and\ndeployment for the final model. This can inform an Operational Lifecycle Analysis (OLCA) for a machine learning\nmodel, which would account for all phases of the ML lifecycle. In the subsections below, we outline some ways in which\nthe proposed tool can be used at different stages of the model development and deployment process, and describe some\nenvironmental impacts due to ML modeling that are outside the scope of measurement of this tool.\n13", "sentences": [{"text": "Measuring the Carbon Intensity of AI in Cloud Instances FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea\ninterpreted as the number of times the carbon intensity crosses above the threshold minimizing total emissions being\nsmall.", "metadata": {}}, {"text": "Model BERT BERT 6B Dense Dense Dense ViT ViT ViT ViT ViT\nfinetune LM Transf.", "metadata": {}}, {"text": "121 169 201 Tiny Small Base Large Huge\nFS 14.5% 3.4% 0.5% 26.8% 26.4% 25.9% 5.6% 5.3% 4.2% 1.3% 0.5%\nP&R 19.0% 8.5% 2.5% 27.7% 27.3% 27.1% 12.5% 12.3% 11.7% 4.7% 2.4%\nPauses / hr 0.23 0.3 0.15 0.06 0.07 0.08 0.3 0.3 0.3 0.23 0.14\nTable 4.", "metadata": {}}, {"text": "For the 11 models in our analysis: the gain in percent averaged over the year and across the 16 regions for the Flexible Start\n(FS) and Pause and Resume (P&R) optimizations allowing for a 24h increase in job duration.", "metadata": {}}, {"text": "The last line represents the average\nnumber of pauses per hour performed by the P&R optimization.", "metadata": {}}, {"text": "Note that the above optimizations were performed using historical data, meaning that their results are the best\nachievable, assuming access to an oracle predicting carbon intensity perfectly.", "metadata": {}}, {"text": "WattTime currently provides marginal\nemission rate estimates and forecasts for up to 24 hours, so for short workloads, our findings will reflect gains observed\nin practice using the forecasts.", "metadata": {}}, {"text": "For longer workloads, our numbers give an upper bound on the realizable gains.", "metadata": {}}, {"text": "For\nexample, the Pause and Resume algorithm pauses the workload when emissions are above a threshold, and resumes\nwhen emissions are below that threshold.", "metadata": {}}, {"text": "In our evaluation here we set this threshold such that the total run time is\nincreased by, e.g., 24 hours;", "metadata": {}}, {"text": "a machine learning practitioner would have to estimate how much a particular threshold\nwould increase job duration, but would not know exactly.", "metadata": {}}, {"text": "The dynamic nature of the Pause and Resume optimizations\nsuggests that well-designed scheduling algorithms should be able to get rather close to the upper-bound.", "metadata": {}}, {"text": "We leave such\nalgorithms to future work and hope our tools can inspire further research into that type of scheduling.", "metadata": {}}, {"text": "Moreover, it is\nlikely that carbon intensity forecasting will improve over the years and eventually extend beyond 24 hours, allowing\ntime-shifting decisions to become increasingly accurate.", "metadata": {}}, {"text": "Model BERT BERT 6B Dense Dense Dense ViT ViT ViT ViT ViT\nfinetune LM Transf.", "metadata": {}}, {"text": "121 169 201 Tiny Small Base Large Huge\nFS 7.0% 4.1% 2.6% 1.8% 2.5% 2.7% 5.0% 4.8% 3.9% 3.3% 3.0%\nP&R 9.5% 11.0% 11.4% 2.0% 2.8% 3.1% 11.0% 11.0% 10.8% 11.4% 11.3%\nPauses / hr 0.42 0.29 0.27 1.5 1.88 2.0 0.31 0.32 0.31 0.27 0.26\nTable 5.", "metadata": {}}, {"text": "For the 11 models in our analysis: the gain in percent averaged over the year and across the 16 regions for the Flexible Start\n(FS) and Pause and Resume (P&R) optimizations allowing for a 100% increase in job duration.", "metadata": {}}, {"text": "The last line represents the average\nnumber of pauses per hour performed by the P&R optimization.", "metadata": {}}, {"text": "7 CONSIDERATIONS FOR MODEL DEVELOPMENT AND DEPLOYMENT\nGenerally speaking, we advocate that researchers and practitioners record and report the amount of emissions incurred\nby ML projects, starting with the initial exploratory training phases all the way through hyperparameter tuning and\ndeployment for the final model.", "metadata": {}}, {"text": "This can inform an Operational Lifecycle Analysis (OLCA) for a machine learning\nmodel, which would account for all phases of the ML lifecycle.", "metadata": {}}, {"text": "In the subsections below, we outline some ways in which\nthe proposed tool can be used at different stages of the model development and deployment process, and describe some\nenvironmental impacts due to ML modeling that are outside the scope of measurement of this tool.", "metadata": {}}, {"text": "13", "metadata": {}}], "metadata": {"page": 13}}], "metadata": {"page": 13}}, {"title": "Page 14", "paragraphs": [{"text": "FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea Dodge et al.\nWe see various ways in which our tool can help guide model training, for instance via carbon-informed optimization\n(similarly to what [22] proposed for energy efficiency in federated learning), or for cloud-based recommendations that\nenable users to opt-in for carbon-aware configurations (in terms of region, time, etc.) to reduce the carbon intensity of\ntheir training workloads. We believe that tracking and reducing greenhouse gas emissions can be a very important\nfeature for users deciding on how they will set up their cloud usage, but we recognize that there are natural trade-offs\nthat must be considered. We therefore recommend that the measurements provided by our tool be used to guide\ninformed decisions alongside other considerations as part of a holistic approach, and not as a single gold standard\nto optimize against. For example, even just within the scope of ML model development, it often takes engineering\ntime to optimize a workload to be more efficient (i.e., use less computational resources), and a user should consider\nwhether that time would be better spent elsewhere (e.g., transferring the workload to another region with lower average\nemissions). Furthermore, some projects have strict time constraints, and so scheduling jobs to only run at night would\nsignificantly delay progress, potentially leading to more emissions in other parts of the project. Thus, our suggestions\nare not meant as a one-size-fits-all solution which will eliminate carbon emissions, but instead as a set of options which\ncan be referenced by users and decided upon on a case-by-case basis. Finally, there are also many additional upstream\nand downstream emissions considerations due to the ML model lifecycle, due to, e.g., hardware manufacturing and\ndownstream uses or misuses of the model, that could eclipse the direct emissions due to model training alone. See ¬ß2\nfor further discussion of this crucial point.\nAnother important consideration is operating cost; it could be the case that Region A is lower emissions but higher\ncost than Region B for a particular workload, and thus a user could run their workload in Region B and have some\nbudget left over that could be used for other reductions in emissions. A final consideration is cost of data transfer; it\ncould be the case that Region A is lower emissions and monetary cost than Region B for a particular workload, but the\nenergetic, environmental, or monetary cost of moving the data could exceed the benefits gained.\nIf we see broad adoption of such reporting tools, we may see increases in cloud use in regions which have low\nemissions. In such a scenario, providers could be incentivized to build new data centers, and providers should consider\nthe local impact of such construction.\n8 FUTURE DIRECTIONS\nAs mentioned in ¬ß7, single-instance emissions are a well-defined starting place for quantifying, mitigating, and reducing\nthe environmental impact due to ML, but do not present a complete picture of the total emissions that should be\naccounted for when considering the overall carbon emissions of the ML life cycle. Here are some aspects that are yet to\nbe accounted for (and in some cases, yet to be defined) in terms of the overall OLCA of machine learning:\nScopes of emissions. The Greenhouse Gas Protocol (GHGP) is a standard created by the World Resources Institute\nand the Business Council for Sustainable Development, and has seen broad adoption internationally. It defines Scope 1,\nScope 2, and Scope 3 emissions as follows: Scope 1 emissions are those generated by direct actions of a company, such as\nrunning motor vehicles; Scope 2 emissions are those associated with purchase of electricity, steam, heating, or cooling;\nand Scope 3 emissions are those that the company indirectly participates in, such as those due to investments of the\ncompany and downstream use of products. In the present work, we have focused on the Scope 2 emissions incurred\ndue to electricity usage by cloud providers. The current GHGP Scope 2 is an attributional guidance that precludes the\nuse of marginal emissions rates, and primarily focuses on broad generation-based average rates. It is important to note\n14", "sentences": [{"text": "FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea Dodge et al.", "metadata": {}}, {"text": "We see various ways in which our tool can help guide model training, for instance via carbon-informed optimization\n(similarly to what [22] proposed for energy efficiency in federated learning), or for cloud-based recommendations that\nenable users to opt-in for carbon-aware configurations (in terms of region, time, etc.) to reduce the carbon intensity of\ntheir training workloads.", "metadata": {}}, {"text": "We believe that tracking and reducing greenhouse gas emissions can be a very important\nfeature for users deciding on how they will set up their cloud usage, but we recognize that there are natural trade-offs\nthat must be considered.", "metadata": {}}, {"text": "We therefore recommend that the measurements provided by our tool be used to guide\ninformed decisions alongside other considerations as part of a holistic approach, and not as a single gold standard\nto optimize against.", "metadata": {}}, {"text": "For example, even just within the scope of ML model development, it often takes engineering\ntime to optimize a workload to be more efficient (i.e., use less computational resources), and a user should consider\nwhether that time would be better spent elsewhere (e.g., transferring the workload to another region with lower average\nemissions).", "metadata": {}}, {"text": "Furthermore, some projects have strict time constraints, and so scheduling jobs to only run at night would\nsignificantly delay progress, potentially leading to more emissions in other parts of the project.", "metadata": {}}, {"text": "Thus, our suggestions\nare not meant as a one-size-fits-all solution which will eliminate carbon emissions, but instead as a set of options which\ncan be referenced by users and decided upon on a case-by-case basis.", "metadata": {}}, {"text": "Finally, there are also many additional upstream\nand downstream emissions considerations due to the ML model lifecycle, due to, e.g., hardware manufacturing and\ndownstream uses or misuses of the model, that could eclipse the direct emissions due to model training alone.", "metadata": {}}, {"text": "See ¬ß2\nfor further discussion of this crucial point.", "metadata": {}}, {"text": "Another important consideration is operating cost;", "metadata": {}}, {"text": "it could be the case that Region A is lower emissions but higher\ncost than Region B for a particular workload, and thus a user could run their workload in Region B and have some\nbudget left over that could be used for other reductions in emissions.", "metadata": {}}, {"text": "A final consideration is cost of data transfer;", "metadata": {}}, {"text": "it\ncould be the case that Region A is lower emissions and monetary cost than Region B for a particular workload, but the\nenergetic, environmental, or monetary cost of moving the data could exceed the benefits gained.", "metadata": {}}, {"text": "If we see broad adoption of such reporting tools, we may see increases in cloud use in regions which have low\nemissions.", "metadata": {}}, {"text": "In such a scenario, providers could be incentivized to build new data centers, and providers should consider\nthe local impact of such construction.", "metadata": {}}, {"text": "8 FUTURE DIRECTIONS\nAs mentioned in ¬ß7, single-instance emissions are a well-defined starting place for quantifying, mitigating, and reducing\nthe environmental impact due to ML, but do not present a complete picture of the total emissions that should be\naccounted for when considering the overall carbon emissions of the ML life cycle.", "metadata": {}}, {"text": "Here are some aspects that are yet to\nbe accounted for (and in some cases, yet to be defined) in terms of the overall OLCA of machine learning:\nScopes of emissions.", "metadata": {}}, {"text": "The Greenhouse Gas Protocol (GHGP) is a standard created by the World Resources Institute\nand the Business Council for Sustainable Development, and has seen broad adoption internationally.", "metadata": {}}, {"text": "It defines Scope 1,\nScope 2, and Scope 3 emissions as follows: Scope 1 emissions are those generated by direct actions of a company, such as\nrunning motor vehicles;", "metadata": {}}, {"text": "Scope 2 emissions are those associated with purchase of electricity, steam, heating, or cooling;", "metadata": {}}, {"text": "and Scope 3 emissions are those that the company indirectly participates in, such as those due to investments of the\ncompany and downstream use of products.", "metadata": {}}, {"text": "In the present work, we have focused on the Scope 2 emissions incurred\ndue to electricity usage by cloud providers.", "metadata": {}}, {"text": "The current GHGP Scope 2 is an attributional guidance that precludes the\nuse of marginal emissions rates, and primarily focuses on broad generation-based average rates.", "metadata": {}}, {"text": "It is important to note\n14", "metadata": {}}], "metadata": {"page": 14}}], "metadata": {"page": 14}}, {"title": "Page 15", "paragraphs": [{"text": "Measuring the Carbon Intensity of AI in Cloud Instances FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea\nthat the GHGP Scope 2 guidance is incompatible with the proposed method; this paper illustrates the need to revisit the\nScope 2 guidance to better align with consequential accounting methods.\nWe do not cover the Scope 1 emissions (e.g. emissions that directly result from business activities, such as stationary\ncombustion of fuels for backup power generation in cloud datacenters), for a more detailed discussion see e.g. Gupta\net al. [15], nor the Scope 3 emissions (e.g. emissions that indirectly result from all other business activities, such as\nthose associated with the upstream raw materials extraction, manufacturing, and delivery of cloud-based IT asset\ninfrastructure such as servers from suppliers to be used in a cloud provider‚Äôs datacenters). Both of these types of\nemissions warrant discussion and debate by the AI community‚Äî and indeed some work has begun on the subject,\ne.g., [21, 26]‚Äîbut we are missing a more concrete structure for categorizing, quantifying and mitigating the different\nscopes of emissions in our field. This would involve the active participation of specific stakeholders to establish the\ntooling and reporting required to better estimate these aspects, which is a challenge in itself.\nDeveloping certification systems for ‚ÄúGreen AI‚Äù. While initiatives like the Green Software Foundation are making\nimportant progress towards measuring and mitigating the carbon footprint of software in general, the decentralized\nand data-driven nature of ML will call for specific approaches and guidelines to ensure its efficiency. We anticipate that\nAI-specific initiatives, spanning both research and academia, will help establish certification systems (or badge systems)\nthat will allow both model developers and users make more informed choices with regards to sustainability. The current\nframing of Scopes 1, 2, and 3 may not encompass all the emissions reasonably associated with an AI program.\nImproving the carbon transparency of research and practice. Despite the existence of tools such as Code Carbon [38]\nand EvergyVis [41], both carbon estimation and reporting in ML publications and technical reports remain a relatively\nrare phenomenon. Conferences such as NeurIPS and NAACL have recently added emissions reporting as an optional part\nof the submission process; however, more encouragement will be necessary for this to become commonplace. Gathering\nmore data about the environmental impact of our field is a crucial step towards identifying room for improvement and,\neventually, reducing our emissions.\nSupporting improved estimates of emissions rates. The estimates of emissions rates providers would benefit from more\nand better data being provided by electric system operators. This is particularly true in areas of the world where it is\ncurrently not possible to produce hourly marginal estimates.\nReducing AI‚Äôs scope-enabled emissions. Responsible development and application of AI must account not only for the\nhidden costs of development, as discussed in this paper, but for the positive or negative carbon impact the application\nenables. AI models continue to be used for oil exploration [ 32], deforestation [30], and mining [ 18], among other\nenvironmentally-detrimental practices. When considering the net impacts of an AI application, it is imperative to\ndetermine the extent to which AI is incentivizing practices that have a negative impact on the environment, or the\nextent to which applications are directly reducing emissions or otherwise incentivizing practices that are beneficial to\nthe climate, and take these downstream direct and indirect effects into account in the overall environmental impact\nassessment of our field [4, 21].\nACKNOWLEDGMENTS\nWe thank Avi Allison (Microsoft) for insights associated with carbon accounting and Location-based Marginal Emissions\n(LME) data, Henry Richardson (WattTime) for insights on LME data and the Software Carbon Intensity (SCI) specification,\nAbhishek Gupta for his work on the SCI specification, and Ananya Ganesh (CU Boulder) for help in obtaining the\n15", "sentences": [{"text": "Measuring the Carbon Intensity of AI in Cloud Instances FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea\nthat the GHGP Scope 2 guidance is incompatible with the proposed method;", "metadata": {}}, {"text": "this paper illustrates the need to revisit the\nScope 2 guidance to better align with consequential accounting methods.", "metadata": {}}, {"text": "We do not cover the Scope 1 emissions (e.g.", "metadata": {}}, {"text": "emissions that directly result from business activities, such as stationary\ncombustion of fuels for backup power generation in cloud datacenters), for a more detailed discussion see e.g.", "metadata": {}}, {"text": "Gupta\net al.", "metadata": {}}, {"text": "[15], nor the Scope 3 emissions (e.g.", "metadata": {}}, {"text": "emissions that indirectly result from all other business activities, such as\nthose associated with the upstream raw materials extraction, manufacturing, and delivery of cloud-based IT asset\ninfrastructure such as servers from suppliers to be used in a cloud provider‚Äôs datacenters).", "metadata": {}}, {"text": "Both of these types of\nemissions warrant discussion and debate by the AI community‚Äî and indeed some work has begun on the subject,\ne.g., [21, 26]‚Äîbut we are missing a more concrete structure for categorizing, quantifying and mitigating the different\nscopes of emissions in our field.", "metadata": {}}, {"text": "This would involve the active participation of specific stakeholders to establish the\ntooling and reporting required to better estimate these aspects, which is a challenge in itself.", "metadata": {}}, {"text": "Developing certification systems for ‚ÄúGreen AI‚Äù.", "metadata": {}}, {"text": "While initiatives like the Green Software Foundation are making\nimportant progress towards measuring and mitigating the carbon footprint of software in general, the decentralized\nand data-driven nature of ML will call for specific approaches and guidelines to ensure its efficiency.", "metadata": {}}, {"text": "We anticipate that\nAI-specific initiatives, spanning both research and academia, will help establish certification systems (or badge systems)\nthat will allow both model developers and users make more informed choices with regards to sustainability.", "metadata": {}}, {"text": "The current\nframing of Scopes 1, 2, and 3 may not encompass all the emissions reasonably associated with an AI program.", "metadata": {}}, {"text": "Improving the carbon transparency of research and practice.", "metadata": {}}, {"text": "Despite the existence of tools such as Code Carbon [38]\nand EvergyVis [41], both carbon estimation and reporting in ML publications and technical reports remain a relatively\nrare phenomenon.", "metadata": {}}, {"text": "Conferences such as NeurIPS and NAACL have recently added emissions reporting as an optional part\nof the submission process;", "metadata": {}}, {"text": "however, more encouragement will be necessary for this to become commonplace.", "metadata": {}}, {"text": "Gathering\nmore data about the environmental impact of our field is a crucial step towards identifying room for improvement and,\neventually, reducing our emissions.", "metadata": {}}, {"text": "Supporting improved estimates of emissions rates.", "metadata": {}}, {"text": "The estimates of emissions rates providers would benefit from more\nand better data being provided by electric system operators.", "metadata": {}}, {"text": "This is particularly true in areas of the world where it is\ncurrently not possible to produce hourly marginal estimates.", "metadata": {}}, {"text": "Reducing AI‚Äôs scope-enabled emissions.", "metadata": {}}, {"text": "Responsible development and application of AI must account not only for the\nhidden costs of development, as discussed in this paper, but for the positive or negative carbon impact the application\nenables.", "metadata": {}}, {"text": "AI models continue to be used for oil exploration [ 32], deforestation [30], and mining [ 18], among other\nenvironmentally-detrimental practices.", "metadata": {}}, {"text": "When considering the net impacts of an AI application, it is imperative to\ndetermine the extent to which AI is incentivizing practices that have a negative impact on the environment, or the\nextent to which applications are directly reducing emissions or otherwise incentivizing practices that are beneficial to\nthe climate, and take these downstream direct and indirect effects into account in the overall environmental impact\nassessment of our field [4, 21].", "metadata": {}}, {"text": "ACKNOWLEDGMENTS\nWe thank Avi Allison (Microsoft) for insights associated with carbon accounting and Location-based Marginal Emissions\n(LME) data, Henry Richardson (WattTime) for insights on LME data and the Software Carbon Intensity (SCI) specification,\nAbhishek Gupta for his work on the SCI specification, and Ananya Ganesh (CU Boulder) for help in obtaining the\n15", "metadata": {}}], "metadata": {"page": 15}}], "metadata": {"page": 15}}, {"title": "Page 16", "paragraphs": [{"text": "FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea Dodge et al.\nmeasurements included in Table 1. We also thank Alessandro Sordoni, Payal Bajaj, and Vibhav Vineet for sharing their\ntraining and inference jobs, and Jon Borchardt for help with plotting.\nREFERENCES\n[1] Lasse F. Wolff Anthony, Benjamin Kanding, and Raghavendra Selvan. 2020. Carbontracker: Tracking and Predicting the Carbon Footprint of\nTraining Deep Learning Models. arXiv:2007.03051 [cs.CY]\n[2] Rhonda Ascierto and A Lawrence. 2020. Uptime institute global data center survey 2020. Uptime Institute 2 (2020).\n[3] Nesrine Bannour, Sahar Ghannay, Aur√©lie N√©v√©ol, and Anne-Laure Ligozat. 2021. Evaluating the carbon footprint of NLP methods: a survey and\nanalysis of existing tools. In EMNLP, Workshop SustaiNLP.\n[4] Abeba Birhane, Pratyusha Kalluri, Dallas Card, William Agnew, Ravit Dotan, and Michelle Bao. 2021. The values encoded in machine learning\nresearch. arXiv preprint arXiv:2106.15590 (2021).\n[5] Buildcomputers.net. 2021. Power Consumption of PC Components in Watts. https://www.buildcomputers.net/power-consumption-of-pc-\ncomponents.html\n[6] Jacques A de Chalendar and Sally M Benson. 2019. Why 100% renewable energy is not enough. Joule 3, 6 (2019), 1389‚Äì1393.\n[7] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. 2009. Imagenet: A large-scale hierarchical image database. In2009 IEEE conference\non computer vision and pattern recognition . Ieee, 248‚Äì255.\n[8] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language\nUnderstanding. arXiv:1810.04805 [cs.CL]\n[9] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias\nMinderer, Georg Heigold, Sylvain Gelly, et al. 2020. An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint\narXiv:2010.11929 (2020).\n[10] Jim Gao. 2014. Machine learning applications for data center optimization. (2014).\n[11] Michael Gillenwater. 2008. Redefining RECs‚ÄîPart 1: untangling attributes and offsets. Energy Policy 36, 6 (2008), 2109‚Äì2119.\n[12] Google. 2021. Carbon free energy for Google Cloud regions. https://cloud.google.com/sustainability/region-carbon\n[13] Google. 2021. Helping you pick the greenest region for your Google Cloud resources. https://cloud.google.com/blog/topics/sustainability/pick-the-\ngoogle-cloud-region-with-the-lowest-co2\n[14] Abhishek Gupta, Camylle Lanteigne, and Sara Kingsley. 2020. SECure: A Social and Environmental Certificate for AI Systems. arXiv preprint\narXiv:2006.06217 (2020).\n[15] Udit Gupta, Young Geun Kim, Sylvia Lee, Jordan Tse, Hsien-Hsin S Lee, Gu-Yeon Wei, David Brooks, and Carole-Jean Wu. 2021. Chasing Carbon:\nThe Elusive Environmental Footprint of Computing. In 2021 IEEE International Symposium on High-Performance Computer Architecture (HPCA) .\nIEEE, 854‚Äì867.\n[16] K. Hazelwood, S. Bird, D. Brooks, S. Chintala, U. Diril, D. Dzhulgakov, M. Fawzy, B. Jia, Y. Jia, A. Kalro, J. Law, K. Lee, J. Lu, P. Noordhuis, M.\nSmelyanskiy, L. Xiong, and X. Wang. 2018. Applied Machine Learning at Facebook: A Datacenter Infrastructure Perspective. In2018 IEEE International\nSymposium on High Performance Computer Architecture (HPCA) . 620‚Äì629. https://doi.org/10.1109/HPCA.2018.00059\n[17] Kees Hertogh. 2021. Empowering cloud sustainability with the Microsoft Emissions Impact Dashboard. https://azure.microsoft.com/en-\nus/blog/empowering-cloud-sustainability-with-the-microsoft-emissions-impact-dashboard/\n[18] Zeshan Hyder, Keng Siau, and Fiona Nah. 2019. Artificial intelligence, machine learning, and autonomous technologies in mining industry. Journal\nof Database Management (JDM) 30, 2 (2019), 67‚Äì79.\n[19] Forrest Iandola, Matt Moskewicz, Sergey Karayev, Ross Girshick, Trevor Darrell, and Kurt Keutzer. 2014. Densenet: Implementing efficient convnet\ndescriptor pyramids. arXiv preprint arXiv:1404.1869 (2014).\n[20] International Energy Authority (IEA). 2020. Energy Technology Perspectives 2020. https://www.iea.org/reports/energy-technology-perspectives-\n2020\n[21] Lynn Kaack, Priya Donti, Emma Strubell, George Kamiya, Felix Creutzig, and David Rolnick. 2021. Aligning artificial intelligence with climate\nchange mitigation. (2021).\n[22] Young Geun Kim and Carole-Jean Wu. 2021. AutoFL: Enabling Heterogeneity-Aware Energy Efficient Federated Learning. InMICRO-54: 54th Annual\nIEEE/ACM International Symposium on Microarchitecture . 183‚Äì198.\n[23] Alexandre Lacoste, Alexandra Luccioni, Victor Schmidt, and Thomas Dandres. 2019. Quantifying the carbon emissions of machine learning. arXiv\npreprint arXiv:1910.09700 (2019).\n[24] Nevena Lazic, Tyler Lu, Craig Boutilier, MK Ryu, Eehern Jay Wong, Binz Roy, and Greg Imwalle. 2018. Data center cooling using model-predictive\ncontrol. (2018).\n[25] Yann LeCun, L√©on Bottou, Yoshua Bengio, and Patrick Haffner. 1998. Gradient-based learning applied to document recognition. Proc. IEEE 86, 11\n(1998), 2278‚Äì2324.\n[26] Anne-Laure Ligozat, Julien Lef√®vre, Aur√©lie Bugeau, and Jacques Combaz. 2021. Unraveling the hidden environmental impacts of AI solutions for\nenvironment. arXiv preprint arXiv:2110.11822 (2021).\n16", "sentences": [{"text": "FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea Dodge et al.", "metadata": {}}, {"text": "measurements included in Table 1.", "metadata": {}}, {"text": "We also thank Alessandro Sordoni, Payal Bajaj, and Vibhav Vineet for sharing their\ntraining and inference jobs, and Jon Borchardt for help with plotting.", "metadata": {}}, {"text": "REFERENCES\n[1] Lasse F.", "metadata": {}}, {"text": "Wolff Anthony, Benjamin Kanding, and Raghavendra Selvan.", "metadata": {}}, {"text": "2020.", "metadata": {}}, {"text": "Carbontracker: Tracking and Predicting the Carbon Footprint of\nTraining Deep Learning Models.", "metadata": {}}, {"text": "arXiv:2007.03051 [cs.CY]\n[2] Rhonda Ascierto and A Lawrence.", "metadata": {}}, {"text": "2020.", "metadata": {}}, {"text": "Uptime institute global data center survey 2020.", "metadata": {}}, {"text": "Uptime Institute 2 (2020).", "metadata": {}}, {"text": "[3] Nesrine Bannour, Sahar Ghannay, Aur√©lie N√©v√©ol, and Anne-Laure Ligozat.", "metadata": {}}, {"text": "2021.", "metadata": {}}, {"text": "Evaluating the carbon footprint of NLP methods: a survey and\nanalysis of existing tools.", "metadata": {}}, {"text": "In EMNLP, Workshop SustaiNLP.", "metadata": {}}, {"text": "[4] Abeba Birhane, Pratyusha Kalluri, Dallas Card, William Agnew, Ravit Dotan, and Michelle Bao.", "metadata": {}}, {"text": "2021.", "metadata": {}}, {"text": "The values encoded in machine learning\nresearch.", "metadata": {}}, {"text": "arXiv preprint arXiv:2106.15590 (2021).", "metadata": {}}, {"text": "[5] Buildcomputers.net.", "metadata": {}}, {"text": "2021.", "metadata": {}}, {"text": "Power Consumption of PC Components in Watts.", "metadata": {}}, {"text": "https://www.buildcomputers.net/power-consumption-of-pc-\ncomponents.html\n[6] Jacques A de Chalendar and Sally M Benson.", "metadata": {}}, {"text": "2019.", "metadata": {}}, {"text": "Why 100% renewable energy is not enough.", "metadata": {}}, {"text": "Joule 3, 6 (2019), 1389‚Äì1393.", "metadata": {}}, {"text": "[7] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei.", "metadata": {}}, {"text": "2009.", "metadata": {}}, {"text": "Imagenet: A large-scale hierarchical image database.", "metadata": {}}, {"text": "In2009 IEEE conference\non computer vision and pattern recognition .", "metadata": {}}, {"text": "Ieee, 248‚Äì255.", "metadata": {}}, {"text": "[8] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.", "metadata": {}}, {"text": "2019.", "metadata": {}}, {"text": "BERT: Pre-training of Deep Bidirectional Transformers for Language\nUnderstanding.", "metadata": {}}, {"text": "arXiv:1810.04805 [cs.CL]\n[9] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias\nMinderer, Georg Heigold, Sylvain Gelly, et al.", "metadata": {}}, {"text": "2020.", "metadata": {}}, {"text": "An image is worth 16x16 words: Transformers for image recognition at scale.", "metadata": {}}, {"text": "arXiv preprint\narXiv:2010.11929 (2020).", "metadata": {}}, {"text": "[10] Jim Gao.", "metadata": {}}, {"text": "2014.", "metadata": {}}, {"text": "Machine learning applications for data center optimization.", "metadata": {}}, {"text": "(2014).", "metadata": {}}, {"text": "[11] Michael Gillenwater.", "metadata": {}}, {"text": "2008.", "metadata": {}}, {"text": "Redefining RECs‚ÄîPart 1: untangling attributes and offsets.", "metadata": {}}, {"text": "Energy Policy 36, 6 (2008), 2109‚Äì2119.", "metadata": {}}, {"text": "[12] Google.", "metadata": {}}, {"text": "2021.", "metadata": {}}, {"text": "Carbon free energy for Google Cloud regions.", "metadata": {}}, {"text": "https://cloud.google.com/sustainability/region-carbon\n[13] Google.", "metadata": {}}, {"text": "2021.", "metadata": {}}, {"text": "Helping you pick the greenest region for your Google Cloud resources.", "metadata": {}}, {"text": "https://cloud.google.com/blog/topics/sustainability/pick-the-\ngoogle-cloud-region-with-the-lowest-co2\n[14] Abhishek Gupta, Camylle Lanteigne, and Sara Kingsley.", "metadata": {}}, {"text": "2020.", "metadata": {}}, {"text": "SECure: A Social and Environmental Certificate for AI Systems.", "metadata": {}}, {"text": "arXiv preprint\narXiv:2006.06217 (2020).", "metadata": {}}, {"text": "[15] Udit Gupta, Young Geun Kim, Sylvia Lee, Jordan Tse, Hsien-Hsin S Lee, Gu-Yeon Wei, David Brooks, and Carole-Jean Wu.", "metadata": {}}, {"text": "2021.", "metadata": {}}, {"text": "Chasing Carbon:\nThe Elusive Environmental Footprint of Computing.", "metadata": {}}, {"text": "In 2021 IEEE International Symposium on High-Performance Computer Architecture (HPCA) .", "metadata": {}}, {"text": "IEEE, 854‚Äì867.", "metadata": {}}, {"text": "[16] K.", "metadata": {}}, {"text": "Hazelwood, S.", "metadata": {}}, {"text": "Bird, D.", "metadata": {}}, {"text": "Brooks, S.", "metadata": {}}, {"text": "Chintala, U.", "metadata": {}}, {"text": "Diril, D.", "metadata": {}}, {"text": "Dzhulgakov, M.", "metadata": {}}, {"text": "Fawzy, B.", "metadata": {}}, {"text": "Jia, Y.", "metadata": {}}, {"text": "Jia, A.", "metadata": {}}, {"text": "Kalro, J.", "metadata": {}}, {"text": "Law, K.", "metadata": {}}, {"text": "Lee, J.", "metadata": {}}, {"text": "Lu, P.", "metadata": {}}, {"text": "Noordhuis, M.", "metadata": {}}, {"text": "Smelyanskiy, L.", "metadata": {}}, {"text": "Xiong, and X.", "metadata": {}}, {"text": "Wang.", "metadata": {}}, {"text": "2018.", "metadata": {}}, {"text": "Applied Machine Learning at Facebook: A Datacenter Infrastructure Perspective.", "metadata": {}}, {"text": "In2018 IEEE International\nSymposium on High Performance Computer Architecture (HPCA) .", "metadata": {}}, {"text": "620‚Äì629.", "metadata": {}}, {"text": "https://doi.org/10.1109/HPCA.2018.00059\n[17] Kees Hertogh.", "metadata": {}}, {"text": "2021.", "metadata": {}}, {"text": "Empowering cloud sustainability with the Microsoft Emissions Impact Dashboard.", "metadata": {}}, {"text": "https://azure.microsoft.com/en-\nus/blog/empowering-cloud-sustainability-with-the-microsoft-emissions-impact-dashboard/\n[18] Zeshan Hyder, Keng Siau, and Fiona Nah.", "metadata": {}}, {"text": "2019.", "metadata": {}}, {"text": "Artificial intelligence, machine learning, and autonomous technologies in mining industry.", "metadata": {}}, {"text": "Journal\nof Database Management (JDM) 30, 2 (2019), 67‚Äì79.", "metadata": {}}, {"text": "[19] Forrest Iandola, Matt Moskewicz, Sergey Karayev, Ross Girshick, Trevor Darrell, and Kurt Keutzer.", "metadata": {}}, {"text": "2014.", "metadata": {}}, {"text": "Densenet: Implementing efficient convnet\ndescriptor pyramids.", "metadata": {}}, {"text": "arXiv preprint arXiv:1404.1869 (2014).", "metadata": {}}, {"text": "[20] International Energy Authority (IEA).", "metadata": {}}, {"text": "2020.", "metadata": {}}, {"text": "Energy Technology Perspectives 2020.", "metadata": {}}, {"text": "https://www.iea.org/reports/energy-technology-perspectives-\n2020\n[21] Lynn Kaack, Priya Donti, Emma Strubell, George Kamiya, Felix Creutzig, and David Rolnick.", "metadata": {}}, {"text": "2021.", "metadata": {}}, {"text": "Aligning artificial intelligence with climate\nchange mitigation.", "metadata": {}}, {"text": "(2021).", "metadata": {}}, {"text": "[22] Young Geun Kim and Carole-Jean Wu.", "metadata": {}}, {"text": "2021.", "metadata": {}}, {"text": "AutoFL: Enabling Heterogeneity-Aware Energy Efficient Federated Learning.", "metadata": {}}, {"text": "InMICRO-54: 54th Annual\nIEEE/ACM International Symposium on Microarchitecture .", "metadata": {}}, {"text": "183‚Äì198.", "metadata": {}}, {"text": "[23] Alexandre Lacoste, Alexandra Luccioni, Victor Schmidt, and Thomas Dandres.", "metadata": {}}, {"text": "2019.", "metadata": {}}, {"text": "Quantifying the carbon emissions of machine learning.", "metadata": {}}, {"text": "arXiv\npreprint arXiv:1910.09700 (2019).", "metadata": {}}, {"text": "[24] Nevena Lazic, Tyler Lu, Craig Boutilier, MK Ryu, Eehern Jay Wong, Binz Roy, and Greg Imwalle.", "metadata": {}}, {"text": "2018.", "metadata": {}}, {"text": "Data center cooling using model-predictive\ncontrol.", "metadata": {}}, {"text": "(2018).", "metadata": {}}, {"text": "[25] Yann LeCun, L√©on Bottou, Yoshua Bengio, and Patrick Haffner.", "metadata": {}}, {"text": "1998.", "metadata": {}}, {"text": "Gradient-based learning applied to document recognition.", "metadata": {}}, {"text": "Proc.", "metadata": {}}, {"text": "IEEE 86, 11\n(1998), 2278‚Äì2324.", "metadata": {}}, {"text": "[26] Anne-Laure Ligozat, Julien Lef√®vre, Aur√©lie Bugeau, and Jacques Combaz.", "metadata": {}}, {"text": "2021.", "metadata": {}}, {"text": "Unraveling the hidden environmental impacts of AI solutions for\nenvironment.", "metadata": {}}, {"text": "arXiv preprint arXiv:2110.11822 (2021).", "metadata": {}}, {"text": "16", "metadata": {}}], "metadata": {"page": 16}}], "metadata": {"page": 16}}, {"title": "Page 17", "paragraphs": [{"text": "Measuring the Carbon Intensity of AI in Cloud Instances FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea\n[27] Eric Masanet, Arman Shehabi, Nuoa Lei, Sarah Smith, and Jonathan Koomey. 2020. Recalibrating global data center energy-use estimates. Science\n367, 6481 (2020), 984‚Äì986.\n[28] Val√©rie Masson-Delmotte, Panmao Zhai, Hans-Otto P√∂rtner, Debra Roberts, Jim Skea, Priyadarshi R Shukla, Anna Pirani, Wilfran Moufouma-Okia,\nClotilde P√©an, Roz Pidcock, et al. 2018. Global warming of 1.5 C. An IPCC Special Report on the impacts of global warming of 1, 5 (2018).\n[29] Microsoft Azure. 2021. Azure sustainability. https://azure.microsoft.com/en-us/global-infrastructure/sustainability/#overview\n[30] Vasilii Mosin, Roberto Aguilar, Alexander Platonov, Albert Vasiliev, Alexander Kedrov, and Anton Ivanov. 2019. Remote sensing and machine\nlearning for tree detection and classification in forestry applications. InImage and Signal Processing for Remote Sensing XXV , Vol. 11155. International\nSociety for Optics and Photonics, 111550F.\n[31] NeurIPS 2021 Conference. 2021. NeurIPS 2021 Paper Checklist Guidelines. https://neurips.cc/Conferences/2021/PaperInformation/PaperChecklist\n[32] Vito Alexander Nordloh, Anna Roub√≠ckov√°, and Nick Brown. 2020. Machine Learning for Gas and Oil Exploration. arXiv preprint arXiv:2010.04186\n(2020).\n[33] David Patterson, Joseph Gonzalez, Urs H√∂lzle, Quoc Le, Chen Liang, Lluis-Miquel Munguia, Daniel Rothchild, David So, Maud Texier, and Jeff Dean.\n2022. The Carbon Footprint of Machine Learning Training Will Plateau, Then Shrink. TexRxiv (2022).\n[34] David Patterson, Joseph Gonzalez, Quoc Le, Chen Liang, Lluis-Miquel Munguia, Daniel Rothchild, David So, Maud Texier, and Jeff Dean. 2021.\nCarbon emissions and large neural network training. arXiv preprint arXiv:2104.10350 (2021).\n[35] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 2019. Exploring the\nlimits of transfer learning with a unified text-to-text transformer. arXiv preprint arXiv:1910.10683 (2019).\n[36] Joeri Rogelj, Oliver Geden, Annette Cowie, and Andy Reisinger. 2021. Net-zero emissions targets are vague: three ways to fix. Nature 591 (2021),\n365‚Äì368.\n[37] Victor Sanh, Albert Webson, Colin Raffel, Stephen H Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven Le Scao, Arun\nRaja, et al. 2021. Multitask prompted training enables zero-shot task generalization. arXiv preprint arXiv:2110.08207 (2021).\n[38] Victor Schmidt, Kamal Goyal, Aditya Joshi, Boris Feld, Liam Conell, Nikolas Laskaris, Doug Blank, Jonathan Wilson, Sorelle Friedler, and Sasha\nLuccioni. 2021. CodeCarbon: Estimate and Track Carbon Emissions from Machine Learning Computing.\n[39] Roy Schwartz, Jesse Dodge, Noah A Smith, and Oren Etzioni. 2020. Green AI. Commun. ACM 63, 12 (2020), 54‚Äì63.\n[40] Amazon Web Services. 2021. Sustainability in the Cloud. https://sustainability.aboutamazon.com/environment/the-cloud\n[41] Omar Shaikh, Jon Saad-Falcon, Austin P Wright, Nilaksh Das, Scott Freitas, Omar Asensio, and Duen Horng Chau. 2021. EnergyVis: Interactively\nTracking and Exploring Energy Consumption for ML Models . Association for Computing Machinery, New York, NY, USA. https://doi.org/10.1145/\n3411763.3451780\n[42] Emma Strubell, Ananya Ganesh, and Andrew McCallum. 2019. Energy and policy considerations for deep learning in NLP. arXiv preprint\narXiv:1906.02243 (2019).\n[43] Neil C Thompson, Kristjan Greenewald, Keeheon Lee, and Gabriel F Manso. 2020. The computational limits of deep learning. arXiv preprint\narXiv:2007.05558 (2020).\n[44] Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du,\nYaGuang Li, Hongrae Lee, Huaixiu Steven Zheng, Amin Ghafouri, Marcelo Menegali, Yanping Huang, Maxim Krikun, Dmitry Lepikhin, James Qin,\nDehao Chen, Yuanzhong Xu, Zhifeng Chen, Adam Roberts, Maarten Bosma, Yanqi Zhou, Chung-Ching Chang, Igor Krivokon, Will Rusch, Marc\nPickett, Kathleen Meier-Hellstern, Meredith Ringel Morris, Tulsee Doshi, Renelito Delos Santos, Toju Duke, Johnny Soraker, Ben Zevenbergen,\nVinodkumar Prabhakaran, Mark Diaz, Ben Hutchinson, Kristen Olson, Alejandra Molina, Erin Hoffman-John, Josh Lee, Lora Aroyo, Ravi Rajakumar,\nAlena Butryna, Matthew Lamm, Viktoriya Kuzmina, Joe Fenton, Aaron Cohen, Rachel Bernstein, Ray Kurzweil, Blaise Aguera-Arcas, Claire Cui,\nMarian Croak, Ed Chi, and Quoc Le. 2022. LaMDA: Language Models for Dialog Applications. arXiv:2201.08239 [cs.CL]\n[45] Georgina Torbet. 2019. How Much Energy Does Your PC Use? (And 8 Ways to Cut It Down). https://www.makeuseof.com/tag/much-energy-pc-\nuse-8-ways-cut/\n[46] United States Environmental Protection Agency. 2021. Greenhouse Gas Equivalencies Calculator. https://www.epa.gov/energy/greenhouse-gas-\nequivalencies-calculator\n[47] US Department of Energy. 2021. Energy-Efficient Cooling Control Systems for Data Centers. https://www.energy.gov/eere/amo/energy-efficient-\ncooling-control-systems-data-centers\n[48] Adina Williams, Nikita Nangia, and Samuel R Bowman. 2017. A broad-coverage challenge corpus for sentence understanding through inference.\narXiv preprint arXiv:1704.05426 (2017).\n[49] Carole-Jean Wu, Ramya Raghavendra, Udit Gupta, Bilge Acun, Newsha Ardalani, Kiwan Maeng, Gloria Chang, Fiona Aga Behram, James Huang,\nCharles Bai, et al. 2021. Sustainable ai: Environmental implications, challenges and opportunities. arXiv preprint arXiv:2111.00364 (2021).\n17", "sentences": [{"text": "Measuring the Carbon Intensity of AI in Cloud Instances FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea\n[27] Eric Masanet, Arman Shehabi, Nuoa Lei, Sarah Smith, and Jonathan Koomey.", "metadata": {}}, {"text": "2020.", "metadata": {}}, {"text": "Recalibrating global data center energy-use estimates.", "metadata": {}}, {"text": "Science\n367, 6481 (2020), 984‚Äì986.", "metadata": {}}, {"text": "[28] Val√©rie Masson-Delmotte, Panmao Zhai, Hans-Otto P√∂rtner, Debra Roberts, Jim Skea, Priyadarshi R Shukla, Anna Pirani, Wilfran Moufouma-Okia,\nClotilde P√©an, Roz Pidcock, et al.", "metadata": {}}, {"text": "2018.", "metadata": {}}, {"text": "Global warming of 1.5 C.", "metadata": {}}, {"text": "An IPCC Special Report on the impacts of global warming of 1, 5 (2018).", "metadata": {}}, {"text": "[29] Microsoft Azure.", "metadata": {}}, {"text": "2021.", "metadata": {}}, {"text": "Azure sustainability.", "metadata": {}}, {"text": "https://azure.microsoft.com/en-us/global-infrastructure/sustainability/#overview\n[30] Vasilii Mosin, Roberto Aguilar, Alexander Platonov, Albert Vasiliev, Alexander Kedrov, and Anton Ivanov.", "metadata": {}}, {"text": "2019.", "metadata": {}}, {"text": "Remote sensing and machine\nlearning for tree detection and classification in forestry applications.", "metadata": {}}, {"text": "InImage and Signal Processing for Remote Sensing XXV , Vol.", "metadata": {}}, {"text": "11155.", "metadata": {}}, {"text": "International\nSociety for Optics and Photonics, 111550F.", "metadata": {}}, {"text": "[31] NeurIPS 2021 Conference.", "metadata": {}}, {"text": "2021.", "metadata": {}}, {"text": "NeurIPS 2021 Paper Checklist Guidelines.", "metadata": {}}, {"text": "https://neurips.cc/Conferences/2021/PaperInformation/PaperChecklist\n[32] Vito Alexander Nordloh, Anna Roub√≠ckov√°, and Nick Brown.", "metadata": {}}, {"text": "2020.", "metadata": {}}, {"text": "Machine Learning for Gas and Oil Exploration.", "metadata": {}}, {"text": "arXiv preprint arXiv:2010.04186\n(2020).", "metadata": {}}, {"text": "[33] David Patterson, Joseph Gonzalez, Urs H√∂lzle, Quoc Le, Chen Liang, Lluis-Miquel Munguia, Daniel Rothchild, David So, Maud Texier, and Jeff Dean.", "metadata": {}}, {"text": "2022.", "metadata": {}}, {"text": "The Carbon Footprint of Machine Learning Training Will Plateau, Then Shrink.", "metadata": {}}, {"text": "TexRxiv (2022).", "metadata": {}}, {"text": "[34] David Patterson, Joseph Gonzalez, Quoc Le, Chen Liang, Lluis-Miquel Munguia, Daniel Rothchild, David So, Maud Texier, and Jeff Dean.", "metadata": {}}, {"text": "2021.", "metadata": {}}, {"text": "Carbon emissions and large neural network training.", "metadata": {}}, {"text": "arXiv preprint arXiv:2104.10350 (2021).", "metadata": {}}, {"text": "[35] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu.", "metadata": {}}, {"text": "2019.", "metadata": {}}, {"text": "Exploring the\nlimits of transfer learning with a unified text-to-text transformer.", "metadata": {}}, {"text": "arXiv preprint arXiv:1910.10683 (2019).", "metadata": {}}, {"text": "[36] Joeri Rogelj, Oliver Geden, Annette Cowie, and Andy Reisinger.", "metadata": {}}, {"text": "2021.", "metadata": {}}, {"text": "Net-zero emissions targets are vague: three ways to fix.", "metadata": {}}, {"text": "Nature 591 (2021),\n365‚Äì368.", "metadata": {}}, {"text": "[37] Victor Sanh, Albert Webson, Colin Raffel, Stephen H Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven Le Scao, Arun\nRaja, et al.", "metadata": {}}, {"text": "2021.", "metadata": {}}, {"text": "Multitask prompted training enables zero-shot task generalization.", "metadata": {}}, {"text": "arXiv preprint arXiv:2110.08207 (2021).", "metadata": {}}, {"text": "[38] Victor Schmidt, Kamal Goyal, Aditya Joshi, Boris Feld, Liam Conell, Nikolas Laskaris, Doug Blank, Jonathan Wilson, Sorelle Friedler, and Sasha\nLuccioni.", "metadata": {}}, {"text": "2021.", "metadata": {}}, {"text": "CodeCarbon: Estimate and Track Carbon Emissions from Machine Learning Computing.", "metadata": {}}, {"text": "[39] Roy Schwartz, Jesse Dodge, Noah A Smith, and Oren Etzioni.", "metadata": {}}, {"text": "2020.", "metadata": {}}, {"text": "Green AI.", "metadata": {}}, {"text": "Commun.", "metadata": {}}, {"text": "ACM 63, 12 (2020), 54‚Äì63.", "metadata": {}}, {"text": "[40] Amazon Web Services.", "metadata": {}}, {"text": "2021.", "metadata": {}}, {"text": "Sustainability in the Cloud.", "metadata": {}}, {"text": "https://sustainability.aboutamazon.com/environment/the-cloud\n[41] Omar Shaikh, Jon Saad-Falcon, Austin P Wright, Nilaksh Das, Scott Freitas, Omar Asensio, and Duen Horng Chau.", "metadata": {}}, {"text": "2021.", "metadata": {}}, {"text": "EnergyVis: Interactively\nTracking and Exploring Energy Consumption for ML Models .", "metadata": {}}, {"text": "Association for Computing Machinery, New York, NY, USA.", "metadata": {}}, {"text": "https://doi.org/10.1145/\n3411763.3451780\n[42] Emma Strubell, Ananya Ganesh, and Andrew McCallum.", "metadata": {}}, {"text": "2019.", "metadata": {}}, {"text": "Energy and policy considerations for deep learning in NLP.", "metadata": {}}, {"text": "arXiv preprint\narXiv:1906.02243 (2019).", "metadata": {}}, {"text": "[43] Neil C Thompson, Kristjan Greenewald, Keeheon Lee, and Gabriel F Manso.", "metadata": {}}, {"text": "2020.", "metadata": {}}, {"text": "The computational limits of deep learning.", "metadata": {}}, {"text": "arXiv preprint\narXiv:2007.05558 (2020).", "metadata": {}}, {"text": "[44] Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du,\nYaGuang Li, Hongrae Lee, Huaixiu Steven Zheng, Amin Ghafouri, Marcelo Menegali, Yanping Huang, Maxim Krikun, Dmitry Lepikhin, James Qin,\nDehao Chen, Yuanzhong Xu, Zhifeng Chen, Adam Roberts, Maarten Bosma, Yanqi Zhou, Chung-Ching Chang, Igor Krivokon, Will Rusch, Marc\nPickett, Kathleen Meier-Hellstern, Meredith Ringel Morris, Tulsee Doshi, Renelito Delos Santos, Toju Duke, Johnny Soraker, Ben Zevenbergen,\nVinodkumar Prabhakaran, Mark Diaz, Ben Hutchinson, Kristen Olson, Alejandra Molina, Erin Hoffman-John, Josh Lee, Lora Aroyo, Ravi Rajakumar,\nAlena Butryna, Matthew Lamm, Viktoriya Kuzmina, Joe Fenton, Aaron Cohen, Rachel Bernstein, Ray Kurzweil, Blaise Aguera-Arcas, Claire Cui,\nMarian Croak, Ed Chi, and Quoc Le.", "metadata": {}}, {"text": "2022.", "metadata": {}}, {"text": "LaMDA: Language Models for Dialog Applications.", "metadata": {}}, {"text": "arXiv:2201.08239 [cs.CL]\n[45] Georgina Torbet.", "metadata": {}}, {"text": "2019.", "metadata": {}}, {"text": "How Much Energy Does Your PC Use?", "metadata": {}}, {"text": "(And 8 Ways to Cut It Down).", "metadata": {}}, {"text": "https://www.makeuseof.com/tag/much-energy-pc-\nuse-8-ways-cut/\n[46] United States Environmental Protection Agency.", "metadata": {}}, {"text": "2021.", "metadata": {}}, {"text": "Greenhouse Gas Equivalencies Calculator.", "metadata": {}}, {"text": "https://www.epa.gov/energy/greenhouse-gas-\nequivalencies-calculator\n[47] US Department of Energy.", "metadata": {}}, {"text": "2021.", "metadata": {}}, {"text": "Energy-Efficient Cooling Control Systems for Data Centers.", "metadata": {}}, {"text": "https://www.energy.gov/eere/amo/energy-efficient-\ncooling-control-systems-data-centers\n[48] Adina Williams, Nikita Nangia, and Samuel R Bowman.", "metadata": {}}, {"text": "2017.", "metadata": {}}, {"text": "A broad-coverage challenge corpus for sentence understanding through inference.", "metadata": {}}, {"text": "arXiv preprint arXiv:1704.05426 (2017).", "metadata": {}}, {"text": "[49] Carole-Jean Wu, Ramya Raghavendra, Udit Gupta, Bilge Acun, Newsha Ardalani, Kiwan Maeng, Gloria Chang, Fiona Aga Behram, James Huang,\nCharles Bai, et al.", "metadata": {}}, {"text": "2021.", "metadata": {}}, {"text": "Sustainable ai: Environmental implications, challenges and opportunities.", "metadata": {}}, {"text": "arXiv preprint arXiv:2111.00364 (2021).", "metadata": {}}, {"text": "17", "metadata": {}}], "metadata": {"page": 17}}], "metadata": {"page": 17}}, {"title": "Page 18", "paragraphs": [{"text": "FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea Dodge et al.\nA ADDITIONAL PLOTS\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n2\n4\n6\n8\n10\n12CO2 emissions decrease in %\n6h\n12h\n18h\n24h\n(a) Flexible Start optimization.\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n5\n10\n15\n20\n25\n30CO2 emissions decrease in %\n25%\n50%\n75%\n100% (b) Pause and Resume optimization.\nFig. 5. Optimization results for the training of BERT small on 8 V100s. Without optimization, the job ran for approximately 36 hours\nand consumed 37.3 kWh.\nIn Figures 5, 6, 7, 8, 9, 10, 11, 12, 13, 14 and 15, we report the decrease in CO2 emissions (in percent) obtained when\nperforming the two optimizations introduced in the main text for all 16 regions, all 11 models, averaged over the year\nand for various values of the ùëÅ denoting the increase in job duration stemming from the optimization.\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n10\n20\n30\n40\n50CO2 emissions decrease in %\n6h\n12h\n18h\n24h\n(a) Flexible Start optimization.\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0.0\n2.5\n5.0\n7.5\n10.0\n12.5\n15.0\n17.5\n20.0CO2 emissions decrease in %\n25%\n50%\n75%\n100% (b) Pause and Resume optimization.\nFig. 6. Optimization results for the finetuning of BERT small on the MNLI dataset, using 4 V100s. Without optimization, the job ran\nfor approximately 6 hours and consumed 3.1 kWh.\n18", "sentences": [{"text": "FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea Dodge et al.", "metadata": {}}, {"text": "A ADDITIONAL PLOTS\nEast USWest USWest US2West US3Central US\nN.", "metadata": {}}, {"text": "Central USS.", "metadata": {}}, {"text": "Central USW.", "metadata": {}}, {"text": "Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n2\n4\n6\n8\n10\n12CO2 emissions decrease in %\n6h\n12h\n18h\n24h\n(a) Flexible Start optimization.", "metadata": {}}, {"text": "East USWest USWest US2West US3Central US\nN.", "metadata": {}}, {"text": "Central USS.", "metadata": {}}, {"text": "Central USW.", "metadata": {}}, {"text": "Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n5\n10\n15\n20\n25\n30CO2 emissions decrease in %\n25%\n50%\n75%\n100% (b) Pause and Resume optimization.", "metadata": {}}, {"text": "Fig.", "metadata": {}}, {"text": "5.", "metadata": {}}, {"text": "Optimization results for the training of BERT small on 8 V100s.", "metadata": {}}, {"text": "Without optimization, the job ran for approximately 36 hours\nand consumed 37.3 kWh.", "metadata": {}}, {"text": "In Figures 5, 6, 7, 8, 9, 10, 11, 12, 13, 14 and 15, we report the decrease in CO2 emissions (in percent) obtained when\nperforming the two optimizations introduced in the main text for all 16 regions, all 11 models, averaged over the year\nand for various values of the ùëÅ denoting the increase in job duration stemming from the optimization.", "metadata": {}}, {"text": "East USWest USWest US2West US3Central US\nN.", "metadata": {}}, {"text": "Central USS.", "metadata": {}}, {"text": "Central USW.", "metadata": {}}, {"text": "Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n10\n20\n30\n40\n50CO2 emissions decrease in %\n6h\n12h\n18h\n24h\n(a) Flexible Start optimization.", "metadata": {}}, {"text": "East USWest USWest US2West US3Central US\nN.", "metadata": {}}, {"text": "Central USS.", "metadata": {}}, {"text": "Central USW.", "metadata": {}}, {"text": "Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0.0\n2.5\n5.0\n7.5\n10.0\n12.5\n15.0\n17.5\n20.0CO2 emissions decrease in %\n25%\n50%\n75%\n100% (b) Pause and Resume optimization.", "metadata": {}}, {"text": "Fig.", "metadata": {}}, {"text": "6.", "metadata": {}}, {"text": "Optimization results for the finetuning of BERT small on the MNLI dataset, using 4 V100s.", "metadata": {}}, {"text": "Without optimization, the job ran\nfor approximately 6 hours and consumed 3.1 kWh.", "metadata": {}}, {"text": "18", "metadata": {}}], "metadata": {"page": 18}}], "metadata": {"page": 18}}, {"title": "Page 19", "paragraphs": [{"text": "Measuring the Carbon Intensity of AI in Cloud Instances FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\n1.2\n1.4CO2 emissions decrease in %\n6h\n12h\n18h\n24h\n(a) Flexible Start optimization.\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n5\n10\n15\n20\n25\n30CO2 emissions decrease in %\n25%\n50%\n75%\n100% (b) Pause and Resume optimization.\nFig. 7. Optimization results for the training of a 6B Parameter Transformer on 256 A100s. Without optimization, the job ran for\napproximately 8 days and consumed 13,812 kWh.\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n10\n20\n30\n40\n50\n60\n70\n80CO2 emissions decrease in %\n6h\n12h\n18h\n24h\n(a) Flexible Start optimization.\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n1\n2\n3\n4\n5CO2 emissions decrease in %\n25%\n50%\n75%\n100% (b) Pause and Resume optimization.\nFig. 8. Optimization results for a DenseNet 121 trained on MNIST on 1 P40. Without optimization, the job ran for approximately 20\nminutes and consumed 20 WH.\n19", "sentences": [{"text": "Measuring the Carbon Intensity of AI in Cloud Instances FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea\nEast USWest USWest US2West US3Central US\nN.", "metadata": {}}, {"text": "Central USS.", "metadata": {}}, {"text": "Central USW.", "metadata": {}}, {"text": "Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\n1.2\n1.4CO2 emissions decrease in %\n6h\n12h\n18h\n24h\n(a) Flexible Start optimization.", "metadata": {}}, {"text": "East USWest USWest US2West US3Central US\nN.", "metadata": {}}, {"text": "Central USS.", "metadata": {}}, {"text": "Central USW.", "metadata": {}}, {"text": "Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n5\n10\n15\n20\n25\n30CO2 emissions decrease in %\n25%\n50%\n75%\n100% (b) Pause and Resume optimization.", "metadata": {}}, {"text": "Fig.", "metadata": {}}, {"text": "7.", "metadata": {}}, {"text": "Optimization results for the training of a 6B Parameter Transformer on 256 A100s.", "metadata": {}}, {"text": "Without optimization, the job ran for\napproximately 8 days and consumed 13,812 kWh.", "metadata": {}}, {"text": "East USWest USWest US2West US3Central US\nN.", "metadata": {}}, {"text": "Central USS.", "metadata": {}}, {"text": "Central USW.", "metadata": {}}, {"text": "Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n10\n20\n30\n40\n50\n60\n70\n80CO2 emissions decrease in %\n6h\n12h\n18h\n24h\n(a) Flexible Start optimization.", "metadata": {}}, {"text": "East USWest USWest US2West US3Central US\nN.", "metadata": {}}, {"text": "Central USS.", "metadata": {}}, {"text": "Central USW.", "metadata": {}}, {"text": "Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n1\n2\n3\n4\n5CO2 emissions decrease in %\n25%\n50%\n75%\n100% (b) Pause and Resume optimization.", "metadata": {}}, {"text": "Fig.", "metadata": {}}, {"text": "8.", "metadata": {}}, {"text": "Optimization results for a DenseNet 121 trained on MNIST on 1 P40.", "metadata": {}}, {"text": "Without optimization, the job ran for approximately 20\nminutes and consumed 20 WH.", "metadata": {}}, {"text": "19", "metadata": {}}], "metadata": {"page": 19}}], "metadata": {"page": 19}}, {"title": "Page 20", "paragraphs": [{"text": "FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea Dodge et al.\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n10\n20\n30\n40\n50\n60\n70\n80CO2 emissions decrease in %\n6h\n12h\n18h\n24h\n(a) Flexible Start optimization.\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n1\n2\n3\n4\n5\n6\n7CO2 emissions decrease in %\n25%\n50%\n75%\n100% (b) Pause and Resume optimization.\nFig. 9. Optimization results for a DenseNet 169 trained on MNIST on 1 P40. Without optimization, the job ran for approximately 20\nminutes and consumed 28 WH.\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n10\n20\n30\n40\n50\n60\n70\n80CO2 emissions decrease in %\n6h\n12h\n18h\n24h\n(a) Flexible Start optimization.\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n1\n2\n3\n4\n5\n6\n7\n8CO2 emissions decrease in %\n25%\n50%\n75%\n100% (b) Pause and Resume optimization.\nFig. 10. Optimization results for a DenseNet 201 trained on MNIST on 1 P40. Without optimization, the job ran for approximately 25\nminutes and consumed 37 WH.\n20", "sentences": [{"text": "FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea Dodge et al.", "metadata": {}}, {"text": "East USWest USWest US2West US3Central US\nN.", "metadata": {}}, {"text": "Central USS.", "metadata": {}}, {"text": "Central USW.", "metadata": {}}, {"text": "Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n10\n20\n30\n40\n50\n60\n70\n80CO2 emissions decrease in %\n6h\n12h\n18h\n24h\n(a) Flexible Start optimization.", "metadata": {}}, {"text": "East USWest USWest US2West US3Central US\nN.", "metadata": {}}, {"text": "Central USS.", "metadata": {}}, {"text": "Central USW.", "metadata": {}}, {"text": "Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n1\n2\n3\n4\n5\n6\n7CO2 emissions decrease in %\n25%\n50%\n75%\n100% (b) Pause and Resume optimization.", "metadata": {}}, {"text": "Fig.", "metadata": {}}, {"text": "9.", "metadata": {}}, {"text": "Optimization results for a DenseNet 169 trained on MNIST on 1 P40.", "metadata": {}}, {"text": "Without optimization, the job ran for approximately 20\nminutes and consumed 28 WH.", "metadata": {}}, {"text": "East USWest USWest US2West US3Central US\nN.", "metadata": {}}, {"text": "Central USS.", "metadata": {}}, {"text": "Central USW.", "metadata": {}}, {"text": "Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n10\n20\n30\n40\n50\n60\n70\n80CO2 emissions decrease in %\n6h\n12h\n18h\n24h\n(a) Flexible Start optimization.", "metadata": {}}, {"text": "East USWest USWest US2West US3Central US\nN.", "metadata": {}}, {"text": "Central USS.", "metadata": {}}, {"text": "Central USW.", "metadata": {}}, {"text": "Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n1\n2\n3\n4\n5\n6\n7\n8CO2 emissions decrease in %\n25%\n50%\n75%\n100% (b) Pause and Resume optimization.", "metadata": {}}, {"text": "Fig.", "metadata": {}}, {"text": "10.", "metadata": {}}, {"text": "Optimization results for a DenseNet 201 trained on MNIST on 1 P40.", "metadata": {}}, {"text": "Without optimization, the job ran for approximately 25\nminutes and consumed 37 WH.", "metadata": {}}, {"text": "20", "metadata": {}}], "metadata": {"page": 20}}], "metadata": {"page": 20}}, {"title": "Page 21", "paragraphs": [{"text": "Measuring the Carbon Intensity of AI in Cloud Instances FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n2\n4\n6\n8\n10\n12\n14\n16CO2 emissions decrease in %\n6h\n12h\n18h\n24h\n(a) Flexible Start optimization.\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n5\n10\n15\n20\n25CO2 emissions decrease in %\n25%\n50%\n75%\n100% (b) Pause and Resume optimization.\nFig. 11. Optimization results for a Tiny ViT trained on 1 V100. Without optimization, the job ran for approximately 19 hours and\nconsumed 1.7 kWh.\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n2\n4\n6\n8\n10\n12\n14CO2 emissions decrease in %\n6h\n12h\n18h\n24h\n(a) Flexible Start optimization.\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n5\n10\n15\n20\n25CO2 emissions decrease in %\n25%\n50%\n75%\n100% (b) Pause and Resume optimization.\nFig. 12. Optimization results for a Small ViT trained on 1 V100. Without optimization, the job ran for approximately 19 hours and\nconsumed 2.2 kWh.\n21", "sentences": [{"text": "Measuring the Carbon Intensity of AI in Cloud Instances FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea\nEast USWest USWest US2West US3Central US\nN.", "metadata": {}}, {"text": "Central USS.", "metadata": {}}, {"text": "Central USW.", "metadata": {}}, {"text": "Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n2\n4\n6\n8\n10\n12\n14\n16CO2 emissions decrease in %\n6h\n12h\n18h\n24h\n(a) Flexible Start optimization.", "metadata": {}}, {"text": "East USWest USWest US2West US3Central US\nN.", "metadata": {}}, {"text": "Central USS.", "metadata": {}}, {"text": "Central USW.", "metadata": {}}, {"text": "Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n5\n10\n15\n20\n25CO2 emissions decrease in %\n25%\n50%\n75%\n100% (b) Pause and Resume optimization.", "metadata": {}}, {"text": "Fig.", "metadata": {}}, {"text": "11.", "metadata": {}}, {"text": "Optimization results for a Tiny ViT trained on 1 V100.", "metadata": {}}, {"text": "Without optimization, the job ran for approximately 19 hours and\nconsumed 1.7 kWh.", "metadata": {}}, {"text": "East USWest USWest US2West US3Central US\nN.", "metadata": {}}, {"text": "Central USS.", "metadata": {}}, {"text": "Central USW.", "metadata": {}}, {"text": "Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n2\n4\n6\n8\n10\n12\n14CO2 emissions decrease in %\n6h\n12h\n18h\n24h\n(a) Flexible Start optimization.", "metadata": {}}, {"text": "East USWest USWest US2West US3Central US\nN.", "metadata": {}}, {"text": "Central USS.", "metadata": {}}, {"text": "Central USW.", "metadata": {}}, {"text": "Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n5\n10\n15\n20\n25CO2 emissions decrease in %\n25%\n50%\n75%\n100% (b) Pause and Resume optimization.", "metadata": {}}, {"text": "Fig.", "metadata": {}}, {"text": "12.", "metadata": {}}, {"text": "Optimization results for a Small ViT trained on 1 V100.", "metadata": {}}, {"text": "Without optimization, the job ran for approximately 19 hours and\nconsumed 2.2 kWh.", "metadata": {}}, {"text": "21", "metadata": {}}], "metadata": {"page": 21}}], "metadata": {"page": 21}}, {"title": "Page 22", "paragraphs": [{"text": "FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea Dodge et al.\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n2\n4\n6\n8CO2 emissions decrease in %\n6h\n12h\n18h\n24h\n(a) Flexible Start optimization.\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n5\n10\n15\n20\n25CO2 emissions decrease in %\n25%\n50%\n75%\n100% (b) Pause and Resume optimization.\nFig. 13. Optimization results for a Base ViT trained on 1 V100. Without optimization, the job ran for approximately 21 hours and\nconsumed 4.7 kWh.\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0.0\n0.5\n1.0\n1.5\n2.0\n2.5\n3.0\n3.5CO2 emissions decrease in %\n6h\n12h\n18h\n24h\n(a) Flexible Start optimization.\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n5\n10\n15\n20\n25\n30CO2 emissions decrease in %\n25%\n50%\n75%\n100% (b) Pause and Resume optimization.\nFig. 14. Optimization results for a Large ViT trained on 4 V100. Without optimization, the job ran for approximately 90 hours and\nconsumed 93.3 kWh.\n22", "sentences": [{"text": "FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea Dodge et al.", "metadata": {}}, {"text": "East USWest USWest US2West US3Central US\nN.", "metadata": {}}, {"text": "Central USS.", "metadata": {}}, {"text": "Central USW.", "metadata": {}}, {"text": "Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n2\n4\n6\n8CO2 emissions decrease in %\n6h\n12h\n18h\n24h\n(a) Flexible Start optimization.", "metadata": {}}, {"text": "East USWest USWest US2West US3Central US\nN.", "metadata": {}}, {"text": "Central USS.", "metadata": {}}, {"text": "Central USW.", "metadata": {}}, {"text": "Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n5\n10\n15\n20\n25CO2 emissions decrease in %\n25%\n50%\n75%\n100% (b) Pause and Resume optimization.", "metadata": {}}, {"text": "Fig.", "metadata": {}}, {"text": "13.", "metadata": {}}, {"text": "Optimization results for a Base ViT trained on 1 V100.", "metadata": {}}, {"text": "Without optimization, the job ran for approximately 21 hours and\nconsumed 4.7 kWh.", "metadata": {}}, {"text": "East USWest USWest US2West US3Central US\nN.", "metadata": {}}, {"text": "Central USS.", "metadata": {}}, {"text": "Central USW.", "metadata": {}}, {"text": "Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0.0\n0.5\n1.0\n1.5\n2.0\n2.5\n3.0\n3.5CO2 emissions decrease in %\n6h\n12h\n18h\n24h\n(a) Flexible Start optimization.", "metadata": {}}, {"text": "East USWest USWest US2West US3Central US\nN.", "metadata": {}}, {"text": "Central USS.", "metadata": {}}, {"text": "Central USW.", "metadata": {}}, {"text": "Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n5\n10\n15\n20\n25\n30CO2 emissions decrease in %\n25%\n50%\n75%\n100% (b) Pause and Resume optimization.", "metadata": {}}, {"text": "Fig.", "metadata": {}}, {"text": "14.", "metadata": {}}, {"text": "Optimization results for a Large ViT trained on 4 V100.", "metadata": {}}, {"text": "Without optimization, the job ran for approximately 90 hours and\nconsumed 93.3 kWh.", "metadata": {}}, {"text": "22", "metadata": {}}], "metadata": {"page": 22}}], "metadata": {"page": 22}}, {"title": "Page 23", "paragraphs": [{"text": "Measuring the Carbon Intensity of AI in Cloud Instances FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\n1.2CO2 emissions decrease in %\n6h\n12h\n18h\n24h\n(a) Flexible Start optimization.\nEast USWest USWest US2West US3Central US\nN. Central USS. Central USW. Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n5\n10\n15\n20\n25CO2 emissions decrease in %\n25%\n50%\n75%\n100% (b) Pause and Resume optimization.\nFig. 15. Optimization results for a Huge ViT trained on 4 V100. Without optimization, the job ran for approximately 9 days and\nconsumed 237.6 kWh.\n23", "sentences": [{"text": "Measuring the Carbon Intensity of AI in Cloud Instances FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea\nEast USWest USWest US2West US3Central US\nN.", "metadata": {}}, {"text": "Central USS.", "metadata": {}}, {"text": "Central USW.", "metadata": {}}, {"text": "Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\n1.2CO2 emissions decrease in %\n6h\n12h\n18h\n24h\n(a) Flexible Start optimization.", "metadata": {}}, {"text": "East USWest USWest US2West US3Central US\nN.", "metadata": {}}, {"text": "Central USS.", "metadata": {}}, {"text": "Central USW.", "metadata": {}}, {"text": "Central US\nCanadaFrance\nGermany\nWest EuropeNorth Europe\nNorwayUK SouthAustralia\n0\n5\n10\n15\n20\n25CO2 emissions decrease in %\n25%\n50%\n75%\n100% (b) Pause and Resume optimization.", "metadata": {}}, {"text": "Fig.", "metadata": {}}, {"text": "15.", "metadata": {}}, {"text": "Optimization results for a Huge ViT trained on 4 V100.", "metadata": {}}, {"text": "Without optimization, the job ran for approximately 9 days and\nconsumed 237.6 kWh.", "metadata": {}}, {"text": "23", "metadata": {}}], "metadata": {"page": 23}}], "metadata": {"page": 23}}, {"title": "Page 24", "paragraphs": [{"text": "FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea Dodge et al.\nB ADDITIONAL TABLES\nIn Tables 6, 7, 8, 9, 10, 11, 12 and 13, we report the decrease in CO2 emissions (in percent) obtained when performing\nthe two optimizations introduced in the main text for all 11 models, averaged across the 16 regions we consider and\nover the year, for various values of the ùëÅ denoting the increase in job duration stemming from the optimization.\nModel BERT BERT 6B Dense Dense Dense ViT ViT ViT ViT ViT\nfinetune LM Transf. 121 169 201 Tiny Small Base Large Huge\nFS 1.9% 1.7% 0.8% 0.6% 0.4% 0.4% 1.8% 1.8% 1.6% 1.3% 0.9%\nP&R 3.1% 4.1% 4.5% 0.7% 0.6% 0.5% 4.5% 4.6% 4.4% 4.4% 4.5%\nPauses / hr 0.45 0.25 0.22 2.2 2.4 2.4 0.28 0.29 0.28 0.22 0.21\nTable 6. For the 11 models in our analysis: the gain in percent averaged over the year and across the 16 regions for the Flexible Start\n(FS) and Pause and Resume (P&R) optimizations allowing for a 25% increase in job duration. The last line represents the average\nnumber of pauses per hour performed by the P&R optimization.\nModel BERT BERT 6B Dense Dense Dense ViT ViT ViT ViT ViT\nfinetune LM Transf. 121 169 201 Tiny Small Base Large Huge\nFS 3.6% 2.9% 1.5% 1.0% 1.3% 1.2% 3.3% 3.1% 2.5% 2.1% 1.6%\nP&R 5.5% 7.0% 7.4% 1.1% 1.5% 1.6% 7.2% 7.0% 7.0% 7.3% 7.4%\nPauses / hr 0.47 0.29 0.27 1.83 2.33 2.33 0.32 0.33 0.32 0.27 0.26\nTable 7. For the 11 models in our analysis: the gain in percent averaged over the year and across the 16 regions for the Flexible Start\n(FS) and Pause and Resume (P&R) optimizations allowing for a 50% increase in job duration. The last line represents the average\nnumber of pauses per hour performed by the P&R optimization.\nModel BERT BERT 6B Dense Dense Dense ViT ViT ViT ViT ViT\nfinetune LM Transf. 121 169 201 Tiny Small Base Large Huge\nFS 5.4% 3.6% 2.0% 1.5% 1.7% 1.9% 4.2% 4.0% 3.3% 2.8% 2.2%\nP&R 7.6% 9.2% 9.6% 1.6% 2.0% 2.4% 9.2% 9.3% 9.2% 9.6% 9.6%\nPauses / hr 0.45 0.3 0.27 1.71 2.0 2.14 0.33 0.33 0.32 0.28 0.26\nTable 8. For the 11 models in our analysis: the gain in percent averaged over the year and across the 16 regions for the Flexible Start\n(FS) and Pause and Resume (P&R) optimizations allowing for a 75% increase in job duration. The last line represents the average\nnumber of pauses per hour performed by the P&R optimization.\nModel BERT BERT 6B Dense Dense Dense ViT ViT ViT ViT ViT\nfinetune LM Transf. 121 169 201 Tiny Small Base Large Huge\nFS 7.0% 4.1% 2.6% 1.8% 2.5% 2.7% 5.0% 4.8% 3.9% 3.3% 3.0%\nP&R 9.5% 11.0% 11.4% 2.0% 2.8% 3.1% 11.0% 11.0% 10.8% 11.4% 11.3%\nPauses / hr 0.42 0.29 0.27 1.5 1.88 2.0 0.31 0.32 0.31 0.27 0.26\nTable 9. For the 11 models in our analysis: the gain in percent averaged over the year and across the 16 regions for the Flexible Start\n(FS) and Pause and Resume (P&R) optimizations allowing for a 100% increase in job duration. The last line represents the average\nnumber of pauses per hour performed by the P&R optimization.\n24", "sentences": [{"text": "FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea Dodge et al.", "metadata": {}}, {"text": "B ADDITIONAL TABLES\nIn Tables 6, 7, 8, 9, 10, 11, 12 and 13, we report the decrease in CO2 emissions (in percent) obtained when performing\nthe two optimizations introduced in the main text for all 11 models, averaged across the 16 regions we consider and\nover the year, for various values of the ùëÅ denoting the increase in job duration stemming from the optimization.", "metadata": {}}, {"text": "Model BERT BERT 6B Dense Dense Dense ViT ViT ViT ViT ViT\nfinetune LM Transf.", "metadata": {}}, {"text": "121 169 201 Tiny Small Base Large Huge\nFS 1.9% 1.7% 0.8% 0.6% 0.4% 0.4% 1.8% 1.8% 1.6% 1.3% 0.9%\nP&R 3.1% 4.1% 4.5% 0.7% 0.6% 0.5% 4.5% 4.6% 4.4% 4.4% 4.5%\nPauses / hr 0.45 0.25 0.22 2.2 2.4 2.4 0.28 0.29 0.28 0.22 0.21\nTable 6.", "metadata": {}}, {"text": "For the 11 models in our analysis: the gain in percent averaged over the year and across the 16 regions for the Flexible Start\n(FS) and Pause and Resume (P&R) optimizations allowing for a 25% increase in job duration.", "metadata": {}}, {"text": "The last line represents the average\nnumber of pauses per hour performed by the P&R optimization.", "metadata": {}}, {"text": "Model BERT BERT 6B Dense Dense Dense ViT ViT ViT ViT ViT\nfinetune LM Transf.", "metadata": {}}, {"text": "121 169 201 Tiny Small Base Large Huge\nFS 3.6% 2.9% 1.5% 1.0% 1.3% 1.2% 3.3% 3.1% 2.5% 2.1% 1.6%\nP&R 5.5% 7.0% 7.4% 1.1% 1.5% 1.6% 7.2% 7.0% 7.0% 7.3% 7.4%\nPauses / hr 0.47 0.29 0.27 1.83 2.33 2.33 0.32 0.33 0.32 0.27 0.26\nTable 7.", "metadata": {}}, {"text": "For the 11 models in our analysis: the gain in percent averaged over the year and across the 16 regions for the Flexible Start\n(FS) and Pause and Resume (P&R) optimizations allowing for a 50% increase in job duration.", "metadata": {}}, {"text": "The last line represents the average\nnumber of pauses per hour performed by the P&R optimization.", "metadata": {}}, {"text": "Model BERT BERT 6B Dense Dense Dense ViT ViT ViT ViT ViT\nfinetune LM Transf.", "metadata": {}}, {"text": "121 169 201 Tiny Small Base Large Huge\nFS 5.4% 3.6% 2.0% 1.5% 1.7% 1.9% 4.2% 4.0% 3.3% 2.8% 2.2%\nP&R 7.6% 9.2% 9.6% 1.6% 2.0% 2.4% 9.2% 9.3% 9.2% 9.6% 9.6%\nPauses / hr 0.45 0.3 0.27 1.71 2.0 2.14 0.33 0.33 0.32 0.28 0.26\nTable 8.", "metadata": {}}, {"text": "For the 11 models in our analysis: the gain in percent averaged over the year and across the 16 regions for the Flexible Start\n(FS) and Pause and Resume (P&R) optimizations allowing for a 75% increase in job duration.", "metadata": {}}, {"text": "The last line represents the average\nnumber of pauses per hour performed by the P&R optimization.", "metadata": {}}, {"text": "Model BERT BERT 6B Dense Dense Dense ViT ViT ViT ViT ViT\nfinetune LM Transf.", "metadata": {}}, {"text": "121 169 201 Tiny Small Base Large Huge\nFS 7.0% 4.1% 2.6% 1.8% 2.5% 2.7% 5.0% 4.8% 3.9% 3.3% 3.0%\nP&R 9.5% 11.0% 11.4% 2.0% 2.8% 3.1% 11.0% 11.0% 10.8% 11.4% 11.3%\nPauses / hr 0.42 0.29 0.27 1.5 1.88 2.0 0.31 0.32 0.31 0.27 0.26\nTable 9.", "metadata": {}}, {"text": "For the 11 models in our analysis: the gain in percent averaged over the year and across the 16 regions for the Flexible Start\n(FS) and Pause and Resume (P&R) optimizations allowing for a 100% increase in job duration.", "metadata": {}}, {"text": "The last line represents the average\nnumber of pauses per hour performed by the P&R optimization.", "metadata": {}}, {"text": "24", "metadata": {}}], "metadata": {"page": 24}}], "metadata": {"page": 24}}, {"title": "Page 25", "paragraphs": [{"text": "Measuring the Carbon Intensity of AI in Cloud Instances FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea\nModel BERT BERT 6B Dense Dense Dense ViT ViT ViT ViT ViT\nfinetune LM Transf. 121 169 201 Tiny Small Base Large Huge\nFS 6.9% 1.2% 0.2% 15.3% 14.9% 14.5% 2.3% 2.2% 1.7% 0.5% 0.2%\nP&R 9.4% 2.9% 0.8% 15.8% 15.5% 15.3% 5.5% 5.3% 4.8% 1.5% 0.7%\nPauses / hr 0.41 0.21 0.06 0.22 0.27 0.28 0.29 0.3 0.29 0.11 0.06\nTable 10. For the 11 models in our analysis: the gain in percent averaged over the year and across the 16 regions for the Flexible\nStart (FS) and Pause and Resume (P&R) optimizations allowing for a 6h increase in job duration. The last line represents the average\nnumber of pauses per hour performed by the P&R optimization.\nModel BERT BERT 6B Dense Dense Dense ViT ViT ViT ViT ViT\nfinetune LM Transf. 121 169 201 Tiny Small Base Large Huge\nFS 10.1% 2.3% 0.3% 21.6% 21.1% 20.6% 3.8% 3.6% 2.7% 0.8% 0.3%\nP&R 13.8% 5.3% 1.4% 22.2% 21.7% 21.5% 8.3% 8.1% 7.7% 2.7% 1.3%\nPauses / hr 0.33 0.27 0.1 0.12 0.15 0.15 0.32 0.33 0.32 0.17 0.09\nTable 11. For the 11 models in our analysis: the gain in percent averaged over the year and across the 16 regions for the Flexible\nStart (FS) and Pause and Resume (P&R) optimizations allowing for a 12h increase in job duration. The last line represents the average\nnumber of pauses per hour performed by the P&R optimization.\nModel BERT BERT 6B Dense Dense Dense ViT ViT ViT ViT ViT\nfinetune LM Transf. 121 169 201 Tiny Small Base Large Huge\nFS 13.3% 2.9% 0.4% 24.1% 23.7% 23.2% 4.9% 4.6% 3.6% 1.1% 0.4%\nP&R 17.4% 7.0% 2.0% 24.9% 24.5% 24.2% 10.8% 10.5% 9.9% 3.8% 1.9%\nPauses / hr 0.26 0.29 0.13 0.08 0.09 0.1 0.31 0.32 0.32 0.2 0.12\nTable 12. For the 11 models in our analysis: the gain in percent averaged over the year and across the 16 regions for the Flexible\nStart (FS) and Pause and Resume (P&R) optimizations allowing for a 18h increase in job duration. The last line represents the average\nnumber of pauses per hour performed by the P&R optimization.\nModel BERT BERT 6B Dense Dense Dense ViT ViT ViT ViT ViT\nfinetune LM Transf. 121 169 201 Tiny Small Base Large Huge\nFS 14.5% 3.4% 0.5% 26.8% 26.4% 25.9% 5.6% 5.3% 4.2% 1.3% 0.5%\nP&R 19.0% 8.5% 2.5% 27.7% 27.3% 27.1% 12.5% 12.3% 11.7% 4.7% 2.4%\nPauses / hr 0.23 0.3 0.15 0.06 0.07 0.08 0.3 0.3 0.3 0.23 0.14\nTable 13. For the 11 models in our analysis: the gain in percent averaged over the year and across the 16 regions for the Flexible\nStart (FS) and Pause and Resume (P&R) optimizations allowing for a 24h increase in job duration. The last line represents the average\nnumber of pauses per hour performed by the P&R optimization.\n25", "sentences": [{"text": "Measuring the Carbon Intensity of AI in Cloud Instances FAccT ‚Äô22, June 21‚Äì24, 2022, Seoul, Republic of Korea\nModel BERT BERT 6B Dense Dense Dense ViT ViT ViT ViT ViT\nfinetune LM Transf.", "metadata": {}}, {"text": "121 169 201 Tiny Small Base Large Huge\nFS 6.9% 1.2% 0.2% 15.3% 14.9% 14.5% 2.3% 2.2% 1.7% 0.5% 0.2%\nP&R 9.4% 2.9% 0.8% 15.8% 15.5% 15.3% 5.5% 5.3% 4.8% 1.5% 0.7%\nPauses / hr 0.41 0.21 0.06 0.22 0.27 0.28 0.29 0.3 0.29 0.11 0.06\nTable 10.", "metadata": {}}, {"text": "For the 11 models in our analysis: the gain in percent averaged over the year and across the 16 regions for the Flexible\nStart (FS) and Pause and Resume (P&R) optimizations allowing for a 6h increase in job duration.", "metadata": {}}, {"text": "The last line represents the average\nnumber of pauses per hour performed by the P&R optimization.", "metadata": {}}, {"text": "Model BERT BERT 6B Dense Dense Dense ViT ViT ViT ViT ViT\nfinetune LM Transf.", "metadata": {}}, {"text": "121 169 201 Tiny Small Base Large Huge\nFS 10.1% 2.3% 0.3% 21.6% 21.1% 20.6% 3.8% 3.6% 2.7% 0.8% 0.3%\nP&R 13.8% 5.3% 1.4% 22.2% 21.7% 21.5% 8.3% 8.1% 7.7% 2.7% 1.3%\nPauses / hr 0.33 0.27 0.1 0.12 0.15 0.15 0.32 0.33 0.32 0.17 0.09\nTable 11.", "metadata": {}}, {"text": "For the 11 models in our analysis: the gain in percent averaged over the year and across the 16 regions for the Flexible\nStart (FS) and Pause and Resume (P&R) optimizations allowing for a 12h increase in job duration.", "metadata": {}}, {"text": "The last line represents the average\nnumber of pauses per hour performed by the P&R optimization.", "metadata": {}}, {"text": "Model BERT BERT 6B Dense Dense Dense ViT ViT ViT ViT ViT\nfinetune LM Transf.", "metadata": {}}, {"text": "121 169 201 Tiny Small Base Large Huge\nFS 13.3% 2.9% 0.4% 24.1% 23.7% 23.2% 4.9% 4.6% 3.6% 1.1% 0.4%\nP&R 17.4% 7.0% 2.0% 24.9% 24.5% 24.2% 10.8% 10.5% 9.9% 3.8% 1.9%\nPauses / hr 0.26 0.29 0.13 0.08 0.09 0.1 0.31 0.32 0.32 0.2 0.12\nTable 12.", "metadata": {}}, {"text": "For the 11 models in our analysis: the gain in percent averaged over the year and across the 16 regions for the Flexible\nStart (FS) and Pause and Resume (P&R) optimizations allowing for a 18h increase in job duration.", "metadata": {}}, {"text": "The last line represents the average\nnumber of pauses per hour performed by the P&R optimization.", "metadata": {}}, {"text": "Model BERT BERT 6B Dense Dense Dense ViT ViT ViT ViT ViT\nfinetune LM Transf.", "metadata": {}}, {"text": "121 169 201 Tiny Small Base Large Huge\nFS 14.5% 3.4% 0.5% 26.8% 26.4% 25.9% 5.6% 5.3% 4.2% 1.3% 0.5%\nP&R 19.0% 8.5% 2.5% 27.7% 27.3% 27.1% 12.5% 12.3% 11.7% 4.7% 2.4%\nPauses / hr 0.23 0.3 0.15 0.06 0.07 0.08 0.3 0.3 0.3 0.23 0.14\nTable 13.", "metadata": {}}, {"text": "For the 11 models in our analysis: the gain in percent averaged over the year and across the 16 regions for the Flexible\nStart (FS) and Pause and Resume (P&R) optimizations allowing for a 24h increase in job duration.", "metadata": {}}, {"text": "The last line represents the average\nnumber of pauses per hour performed by the P&R optimization.", "metadata": {}}, {"text": "25", "metadata": {}}], "metadata": {"page": 25}}], "metadata": {"page": 25}}]}