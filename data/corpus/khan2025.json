{"document_id": "khan2025", "title": "Optimizing Large Language Models: Metrics, Energy Efficiency, and Case Study Insights", "text": "Optimizing Large Language Models: Metrics,\nEnergy Efficiency, and Case Study Insights\nTahniat Khan\nIndustry Innovation, Vector Institute\nToronto, Canada\ntahniat.khan@vectorinstitute.ai\nSoroor Motie\nVector Institute, University of Ottawa\nOttawa, Canada\nsmoti088@uottawa.ca\nSedef Akinli Kocak\nIndustry Innovation, Vector Institute\nToronto, Canada\nsedef.kocak@vectorinstitute.ai\nShaina Raza\nAI Engineering, Vector Institute\nToronto, Canada\nshaina.raza@vectorinstitute.ai\nAbstract—The rapid adoption of large language models\n(LLMs) has led to significant energy consumption and carbon\nemissions, posing a critical challenge to the sustainability of\ngenerative AI technologies. This paper explores the integration\nof energy-efficient optimization techniques in the deployment\nof LLMs to address these environmental concerns. We present\na case study and framework that demonstrate how strategic\nquantization and local inference techniques can substantially\nlower the carbon footprints of LLMs without compromising their\noperational effectiveness. Experimental results reveal that these\nmethods can reduce energy consumption and carbon emissions\nby up to 45% post quantization, making them particularly\nsuitable for resource-constrained environments. The findings\nprovide actionable insights for achieving sustainability in AI while\nmaintaining high levels of accuracy and responsiveness.\nIndex Terms—Large Language Models (LLMs), Quantization,\nGreen AI, Carbon Emissions, Energy Efficiency\nI. I NTRODUCTION\nThe increasing computational demands of advanced artifi-\ncial intelligence (AI), particularly generative models including\nlarge language models (LLMs), have motivated significant\nresearch and development in Green AI . It highlights the\nimportance of adopting sustainable practices to mitigate the\nrising environmental impact of generative AI technologies\n[4]. However, despite these advances, many generative AI\napplications continue to consume substantial computational\nresources, leading to increased energy consumption and el-\nevated carbon emissions [27]. As these generative AI models\nand applications scale in both size and complexity, they\ndemand frequent data and model updates, creating a potentially\nunending cycle of energy-intensive processes that could hinder\noverall progress in sustainable AI [27].\nGenerative AI tools such as ChatGPT, GPT-3, Claude, and\nLlama demonstrate remarkable capabilities but come with sig-\nnificant ecological costs associated with their development and\ninfrastructure [4]. Data centers, which support the underlying\ncomputational needs of these tools, are estimated to contribute\napproximately 2–3 1. of global greenhouse gas emissions, with\n1https://dl.acm.org/doi/pdf/10.1145/3483410\nboth energy and water usage rising alongside the rapid growth\nof global data volumes. Moreover, hyperscale cloud providers,\nincluding Amazon AWS, Google Cloud, and Microsoft Azure,\ncommonly use power-intensive GPUs for hosting generative\nAI models; these GPUs can consume 10–15 times the energy\nof traditional CPUs, significantly enlarging the technology’s\ncarbon footprint [2]. Understanding the full lifecycle of emis-\nsions for machine learning models is therefore essential for\ntackling these environmental challenges [2]. Strategies aimed\nat lowering energy demands across this lifecycle—ranging\nfrom pre-training to inference—represent a critical step in\nachieving sustainable generative AI solutions [2].\na) Motivation: Motivated by the environmental impact\nof LLMs, this study seeks to quantify the carbon emissions\nassociated with training and inference for these models. While\nthere is growing recognition of the need for more energy-\nefficient LLMs, the research gap lies in the lack of awareness\nand practical demonstrations showing similar results can be\nachieved with lower energy consumption. Addressing this gap\nrequires not only quantifying the environmental footprint of\ngenerative AI models but also exploring effective optimization\nstrategies. Moreover, analyzing a specific use case can provide\nvaluable insights into the practical benefits of adopting energy-\nefficient methods while maintaining model performance.\nb) Objectives: In this work, we examine the metrics and\nunits currently used to measure the environmental footprint of\npopular generative AI models and evaluate how these metrics\nchange when implementing optimization strategies. We then\npresent a case study demonstrating how targeted optimizations\ncan make generative AI models more energy efficient without\ncompromising their performance in a real-world context.\nThe primary objectives of this study are threefold:\n• To enhance energy efficiency of LLMs by measuring and\nminimizing energy consumption during inference.\n• To reduce carbon emissions by assessing and mitigating\nthe carbon footprint generated in the deployment phase\nof LLMs.\n• To develop a methodology prioritizes performance preser-\nvation, ensuring that accuracy and responsiveness remain© 2025 IEEE. Accepted to IEEE CAI 2025, to appear in IEEE Xplore.\narXiv:2504.06307v1  [cs.LG]  7 Apr 2025\n\nat high levels even as we adopt energy-saving techniques.\nc) Contributions: This study offers several contributions\nto the growing field of Green AI . Primarily, it presents a\ncomprehensive analysis of carbon emissions generated during\nboth the training and inference phases of LLMs, a critical area\noften overlooked in performance evaluations. Furthermore, the\nstudy critically evaluates widely adopted emissions metrics,\nexploring their dynamic behavior under different optimization\nstrategies. Additional contribution lies in the implementation\nof a practical optimization framework designed to minimize\nenergy consumption across the model lifecycle. Finally, a\ndetailed case study provides empirical evidence of measur-\nable reductions in carbon footprint and energy consumption\nachieved without compromising model performance, offering\npractical guidance for sustainable AI development.\nII. R ELATED WORK\nIn recent years, the convergence of environmental sus-\ntainability and AI has led to the emergence of “in Green\nAI”, focusing on reducing the carbon footprint of large-scale\nmodels through optimization techniques. This section reviews\nkey studies that have contributed to this field, highlighting their\ncontributions to sustainable AI practices.\nEfforts to mitigate the environmental impact of LLMs have\nfocused on understanding and reducing their carbon footprint.\nStudies have quantified the CO 2 emissions associated with\nlarge-scale models [2], [4], highlighting significant environ-\nmental challenges posed by their extensive parameter sizes and\ncomputational demands [15]. Liu and Yin (2024), in particular,\nemphasizes the critical role of hardware choices in sustainable\nAI practices and proposes training methods without compro-\nmising performance to reduce carbon emissions [15]. These\nfoundational insights underscore the urgency of addressing\nsustainability in LLM development and deployment.\nBuilding on this foundation, several tools and frameworks\nhave been proposed. For example, GreenTrainer [12] has\nbeen introduced as a fine-tuning approach that dynamically\nevaluates backpropagation costs and contributions to model ac-\ncuracy. By reducing floating-point operations (FLOPs) during\nfine-tuning by up to 64%, GreenTrainer achieves significant\nenergy savings without compromising model performance\n[12]. Likewise, Avatar focuses on creating compact, energy-\nefficient models optimized for deployment on individual de-\nvices [23]. By reducing inference latency and model size,\nthis method significantly decreases the carbon footprint of\nLLM usage while maintaining competitive performance [20],\nillustrating the potential of targeted optimizations [17].\nIn addition to specific optimization techniques, broader\nframeworks for sustainable AI have been proposed. These\nframeworks advocate for the integration of energy-efficient\nalgorithms and the alignment of AI practices with global\nsustainability goals [25]. For instance, intersection of sustain-\nability and software engineering is well established research\narea [3], [7], [26] such as exploring strategies for creating eco-\nfriendly solutions that maintain functionality while reducing\nenergy consumption [24]. Collectively, these studies provide\nactionable insights and a roadmap for advancing Green AI,\naddressing immediate environmental concerns, and fostering\na sustainable future for AI technologies.\nA. Carbon Emission Metrics\nMeasuring carbon emissions is essential for understand-\ning and reducing the environmental impact of AI systems.\nVarious metrics have been developed to assess emissions\nacross different scopes, intensities, and stages. This subsection\noutlines widely used metrics, such as Carbon Dioxide Equiva-\nlent (CO 2e), Carbon Intensity, and Global Warming Potential\n(GWP) and highlights their role in promoting transparency and\nsustainability (Table I).\nTABLE I\nCOMMON CARBON EMISSION METRICS IN GREEN AI\nMetric Unit Definition Reference\nCarbon Dioxide\nEquivalent (CO2e)\nMetric\ntons\n(tCO2e)\nA measure of green-\nhouse gases expressed as\nCO2 equivalent\nIPCC, GHG\nProtocol\nCarbon Intensity gCO2/\nkWh\nCO2 emissions per unit\nof electricity consumed\nInternational\nEnergy\nAgency\nScope 1 Emissions tCO2e Direct emissions from\ncontrolled sources\nGHG Proto-\ncol\nScope 2 Emissions tCO2e Indirect emissions from\npurchased electricity\nGHG Proto-\ncol\nScope 3 Emissions tCO2e Indirect emissions\nacross value chains\nGHG Proto-\ncol\nNet Zero\nEmissions\ntCO2e Balance when emissions\nequal removals\nUNFCCC\nEnergy Consump-\ntion\nMWh Total energy consumed IEA, EIA\nGlobal Warming\nPotential (GWP)\nRatio Heat trapped by a gas\ncompared to CO 2\nIPCC\nCarbon Offsets tCO2e Credits for emissions re-\nduction or removal\nVCS, Gold\nStandard\nCarbon Capture\nand Storage (CCS)\ntCO2\ncaptured\nCO2 removed and stored\nto prevent release\nIEA, IPCC\nB. Quantization Techniques in LLMs\nQuantization [11] has emerged as a transformative approach\nin optimizing LLMs, addressing the dual challenges of com-\nputational efficiency and environmental sustainability. It works\nby converting model parameters from high-precision formats\n(e.g., 32-bit floating-point) to lower-precision formats (e.g., 8-\nbit or even 4-bit), thereby reducing memory requirements and\naccelerating computation. This technique aligns closely with\nthe goals of Green AI, as it minimizes resource usage while\nmaintaining acceptable accuracy.\nResearch efforts have showcased the potential of quanti-\nzation as a key technique for enhancing energy efficiency\nin AI systems. For instance, GPTQ (Accurate Post-Training\nQuantization for Generative Pre-trained Transformers) [9] in-\ntroduces a method for post-training quantization that retains\nhigh model performance despite significant reductions in pa-\nrameter precision. This method enables efficient deployment\nof LLMs on edge devices and other constrained environments,\ndirectly addressing the environmental concerns highlighted in\nstudies like GreenTrainer [12]. Another notable approach is\n\nLLM-QAT (Quantization-Aware Training for Large Language\nModels) [16], which integrates quantization during the training\nphase rather than applying it post-training. This method further\nimproves the trade-off between model size and performance,\nmaking LLMs more adaptable to energy-efficient deployments.\nAdditionally, SmoothQuant [16] employs layer-wise quantiza-\ntion to balance computation and accuracy, achieving state-of-\nthe-art results in reducing energy use during inference.\nC. Trade-Offs Between Accuracy and Optimization\nThe interplay between accuracy and optimization in ma-\nchine learning models, particularly LLMs, underscores the\nchallenges in balancing performance with resource efficiency.\nTechniques like FrugalGPT, described by Chen et al. (2023)\n[5], illustrate how cascading models and leveraging prompt\nadaptation can reduce costs by up to 98% without compromis-\ning accuracy. Similarly, FrugalML shows how selectively rout-\ning queries to different APIs can maintain performance while\ncutting costs by up to 90% [5], [6]. However, the effectiveness\nof these strategies varies across tasks. For example, reducing\ntoken lengths or approximating model outputs might preserve\ngeneral quality but risks performance drops in nuanced appli-\ncations like sentiment analysis or summarization [22]. These\nfindings reveal that while cost and carbon footprint reductions\nare achievable, ensuring minimal trade-offs in precision, recall,\nor F1 score remains a complex optimization problem, often\nrequiring task-specific calibrations [5], [22].\nIII. C ASE STUDY: SUSTAINABLE DEPLOYMENT OF LARGE\nLANGUAGE MODELS\nA. Problem Definition\nLLMs have become integral to various natural language\nprocessing applications, yet their soaring computational de-\nmands pose significant sustainability challenges. These include\nhigh energy consumption, carbon emissions, and escalating\noperational costs, particularly when using cloud-based infras-\ntructures [4]. To address these concerns, this study proposes\na framework for LLM deployment that emphasizes local\ninference, aiming to mitigate environmental impact while\npreserving model performance and user experience.\nFormally, consider a classification problem with input data\nX = {x1, x2, . . . , xN }, (1)\nand corresponding ground-truth labels\nY = {y1, y2, . . . , yN }, y i ∈ {1, 2, . . . , K}, (2)\nAn LLM-based classifier fθ(·) predicts ˆyi = fθ(xi). We\nseek to minimize energy consumption and carbon emissions\nwhile maintaining high predictive accuracy, where accuracy\ncan be quantified using standard metrics such as precision,\nrecall, and F1-score.\nB. Framework Overview\nThe proposed framework (Figure. 1) tackles energy effi-\nciency in LLM deployment through three interconnected com-\nponents: local inference optimization, the selection of energy-\nefficient LLMs, and a comprehensive evaluation methodology.\nThese components function synergistically to reduce energy\nconsumption without sacrificing predictive accuracy or respon-\nsiveness.\nFig. 1. Detailed Overview of the Proposed Optimization Framework\n1) Local Inference Optimization: Unlike traditional cloud-\nbased methods that rely on centralized data centers, local\ninference allows models to run directly on user devices while\nmaintaining data privacy. By minimizing data transmission\nbetween clients and remote servers, this method significantly\nreduces both network overhead and carbon footprint [10]. To\nachieve efficient local inference, the framework employs a\nquantization process [9], which lowers the numerical preci-\nsion of model parameters. Specifically, we define a uniform\nquantization function Qb(·) that maps 32-bit weight tensors to\na b-bit representation:\nQb(w) = round\n\u0010 w − min(w)\n∆\n\u0011\n, (3)\nwhere ∆ is a scaling factor determined by the range\n(max(w) − min(w)) of the weights. In this work, we use a 4-\nbit quantization strategy ( b = 4), which substantially reduces\ncomputational and memory requirements without significantly\ncompromising model performance. We apply quantization\nthrough Ollama [19], an open-source platform known for\nits support of edge computing principles and privacy-centric\ndeployments.\n2) Selection of Energy-Efficient Pre-trained LLMs: In ad-\ndition to local inference optimization, the framework includes\na careful selection of pre-trained LLMs that are specifically\ndesigned for low computational overhead. These models, in-\ncluding Llama3.2 [1], Phi3.2 [21], Mistral [13], Qwen [8],\nand Llava [14], stand out for their smaller parameter counts,\nstreamlined architectures, and selective attention mechanisms.\nSuch features align well with edge-oriented design principles,\n\n[Image page=3 idx=1 name=Im1.png] Size: 1602x1140, Data: 282039 bytes\n\nmaking the models easier to run on devices with limited\nhardware resources.\n3) Evaluation Methodology: The central problem tackled\nhere is a classification task for which we use standard evalu-\nation metrics, including precision, recall, and F1-score. We\nmeasure these metrics both before and after applying our\nquantization approach to understand any performance trade-\noffs. Furthermore, we track energy usage and estimate carbon\nfootprints by monitoring power consumption and utilizing\nemission factor data. Let E denote the total energy consumed\n(in kWh), and let α be the emission factor (kg CO 2 per kWh).\nWe define the carbon footprint CF as:\nCF = E × α., (4)\nC. Expected Outcomes\nThe proposed framework is expected to significantly reduce\nenergy consumption and carbon emissions during LLM infer-\nence, while maintaining accuracy and responsiveness compa-\nrable to standard cloud-based methods. These findings support\nthe goals of Green AI , showing that sustainable solutions\ncan deliver high performance without burdening users or\ncompromising model quality.\nIV. E XPERIMENTAL SETUP\nA. Hardware and Software Setting\nThe hardware used includes an 11th Gen Intel(R) Core(TM)\ni7-1165G7 processor operating at 2.80 GHz (1.69 GHz base\nfrequency), supported by 16.0 GB of installed memory (15.7\nGB usable). The system type is a 64-bit operating system with\nan x64-based processor, running on Windows 11 Pro.\nWe use Ollama [19] for local AI model deployment, which\nensures data privacy by processing entirely on-device, ideal\nfor sensitive applications. It supports a variety of pre-trained\nand fine-tuned models, offering flexibility across use cases.\nIts lightweight design makes it suitable for both individuals\nand organizations seeking efficient, secure, and localized AI\nsolutions.\nBaselines\nWe used the following instruction-tuned models in Table. II\nfor inference, each configured with specific hyperparameters\ntailored to their architecture and target tasks.\nTABLE II\nBASELINE MODELS AND INFERENCE HYPERPARAMETERS\nModel Batch Max Temp. Top-p Top-k Beam\nName Size Tokens Size\nLlama-3.2-1B 8 512 0.7 0.9 50 4\nPhi-3-mini 8 512 0.7 0.9 50 4\nQwen2-7B 8 512 0.8 0.85 40 4\nMistral-7B 16 256 0.9 0.95 30 2\nLLaV A-Llama3 8 512 0.7 0.9 50 4\nThe models used are as follows:\n• Llama-3.2-1B-Instruct: An instruction-tuned large lan-\nguage model for general-purpose tasks.\n• Phi-3-mini-128k-Instruct: An instruction-tuned multi-\nmodal model designed for text and vision integration tasks.\n• Qwen2-7B-Instruct: A transformer-based language model\ntuned for general-purpose tasks.\n• Mistral-7B-Instruct-v0.3: An instruction-tuned model op-\ntimized for efficient NLP tasks.\n• LLaV A-Llama3-Instruct: A fine-tuned version of Llama-3\nInstruct with improvements in multiple benchmarks.\nB. Data\nOur dataset, Financial Sentiment Analysis [18], comprises\n5,842 entries organized into two columns: ”text” and ”label”.\nThe ”text” column contains the textual data for analysis, while\nthe ”label” column indicates the sentiment classification (e.g.,\npositive, negative, or neutral). The dataset is well-structured\nand contains no missing values, making it highly suitable for\nsentiment analysis tasks in machine learning studies Figure. 2.\nSentiment Assessment Instructions\nInstructions: Assess the sentiment of the given text by\nidentifying the presence of sentiment indicators such as\nemotional language, positive or negative expressions, and\ntone shifts. Mark the sentiment as positive, negative, or\nneutral and provide reasoning.\nText: content\nSentiment Indicators Checklist:\n• Emotional Language: Words that convey strong feel-\nings (e.g., joy, anger, sadness, excitement).\n• Positive Expressions: Words or phrases that promote\npositive feelings or optimism.\n• Negative Expressions: Words or phrases that express\ncriticism or negativity.\n• Tone Shifts: Noticeable changes in tone that affect how\nthe content is perceived.\n• Balanced or Neutral Tone: The absence of strong\nemotional language, implying neutrality.\nResponse Format:\nPositive/Negative/Neutral [Reasoning]\nPositive/Negative/Neutral [Reasoning]\nPositive/Negative/Neutral [Reasoning]\nFig. 2. Sentiment Assessment Instructions and Indicators Checklist.\nV. R ESULTS\nA. Accuracy vs Memory Usage\nTable III shows significant reductions in carbon emissions\nacross all models, with some achieving up to 45% after\noptimization. These results demonstrate the effectiveness of\nquantization and local inference in lowering energy use and\ncomputational overhead, while maintaining model perfor-\nmance. Such improvements make these methods well-suited\nfor deployment on edge devices and in resource-constrained\nenvironments.\nHowever, the impact on performance metrics such as accu-\nracy, F1 score, recall, and precision varies. While the reduction\nin carbon footprint is consistent, performance trade-offs are ev-\nident, with some metrics experiencing marginal improvements\n\nand others showing slight declines. For instance, precision\nand recall generally exhibit minor increases in specific cases,\nsuggesting that optimization can enhance certain aspects of\nthe models’ ability to correctly identify relevant patterns in the\ndata. On the other hand, metrics like accuracy and F1 score are\nslightly lower after optimization, indicating a potential trade-\noff between energy efficiency and overall predictive perfor-\nmance. This underscores the importance of carefully balancing\nsustainability and performance when applying optimization\ntechniques, as the ideal solution will depend on the specific\nuse case and application requirements.\nTABLE III\nCOMPARISON OF PERFORMANCE METRICS AND CARBON EMISSIONS FOR\nFIVE LLM S BEFORE AND AFTER OPTIMIZATION . CARBON EMISSIONS ARE\nCALCULATED PER INFERENCE TASK .\nModel Name Precision Recall F1 Accuracy CO2\n(kg)\nBefore\nOptimization\nBaseline metrics for comparison\nLlama 3.2 0.55 0.45 0.44 0.45 0.012\nPhi 3.2 0.97 0.82 0.88 0.82 0.012\nQwen 0.77 0.79 0.76 0.79 0.009\nMistral-small 0.70 0.67 0.65 0.67 0.020\nLlava-Llama 3 0.58 0.50 0.48 0.50 0.014\nAfter\nOptimization\nMetrics following quantization and local\ninference techniques\nLlama 3.2 0.57 0.48 0.47 0.48 0.005\nPhi 3.2 1.00 0.84 0.91 0.84 0.007\nQwen 0.80 0.81 0.80 0.81 0.004\nMistral-small 0.73 0.70 0.69 0.70 0.015\nLlava-Llama 3 0.61 0.54 0.51 0.54 0.006\nB. Post-Quantization Performance Evaluation\nThe goal of this evaluation is to ensure that, after op-\ntimization, predictions remain consistent with ground truth\nlabels and reasoning aligns with the predicted labels. Two\nsubject matter experts assessed predictions based on con-\nsistency (alignment with ground truth), clarity (logical and\ninterpretable reasoning), and alignment (agreement between\npredicted sentiment and reasoning). Our results show that most\nlabels and reasoning align well with the model’s expectations.\nBelow, we present key examples in Figure. 3 .\nVI. D ISCUSSION\nA. Practical impact\nThe demonstrated reduction in carbon emissions through\noptimization techniques such as quantization and local infer-\nence holds significant value for industries aiming to enhance\nsustainability. With models achieving up to 45% reductions\nin energy consumption, this work directly aligns with corpo-\nrate environmental, social, and governance (ESG) goals by\nlowering operational costs and carbon footprints. These tech-\nniques enable the deployment of AI models on edge devices\nand in resource-constrained environments, expanding their\napplicability to sectors like IoT, healthcare, and autonomous\nsystems. Industries can leverage this work to build greener AI\nsolutions, reduce reliance on cloud computing, and improve\nreal-time processing capabilities, all while contributing to\nbroader sustainability initiatives.\nB. Limitations\nWhile the demonstrated optimization techniques such as\nquantization and local inference offer significant reductions in\ncarbon emissions and computational overhead, more work will\nbe needed in incorporating additional optimization techniques\nand evaluating performance across diverse datasets for further\ninvestigation, also they are not without limitations. A notable\ntrade-off is the potential loss of accuracy and predictive\nperformance. Metrics such as F1 score and overall accuracy\nmay decline slightly post-optimization, which could be critical\nfor applications requiring high precision, such as medical\ndiagnostics or financial modeling. This degradation can limit\nthe applicability of optimized models to tasks where even\nminor errors have significant consequences.\nFurthermore, the reliance on local inference can lead to\nslower performance if the underlying hardware is not suffi-\nciently powerful. Devices with limited processing capabilities\nmay experience delays in real-time applications, undermining\nthe efficiency gains achieved through optimization. Addition-\nally, while quantization reduces the size of models, it may\nintroduce numerical instability or rounding errors that could\naffect the robustness of the predictions, particularly in complex\nor highly dynamic environments. These limitations highlight\nthe need for careful evaluation of optimization techniques\nagainst the specific requirements of a given use case to ensure\nthat the trade-offs are acceptable. Future work will also explore\nablation studies to isolate confounding factors such as system-\nlevel effects like caching, dataset characteristics, and model\narchitecture.\nVII. C ONCLUSION\nThis paper highlights the critical need for sustainable AI\npractices, particularly in the deployment of LLMs. By inte-\ngrating optimization techniques such as quantization and local\ninference, we successfully demonstrated significant reductions\nin carbon emissions and energy consumption. The proposed\nframework provides a practical roadmap for industries and re-\nsearchers seeking to balance sustainability with effectiveness.\nFuture research should explore adaptive optimization strategies\nto minimize trade-offs and develop new metrics balancing\nsustainability with predictive performance. Additionally, ex-\npanding the framework to address challenges such as numer-\nical instability and task-specific performance degradation will\nenhance applicability across diverse domains.\nACKNOWLEDGMENT\nThe authors extend their gratitude to the Province of On-\ntario, the Government of Canada through CIFAR, and the\ncorporate sponsors of the Vector Institute for their gener-\nous support and provision of resources essential for this\nresearch. Further details on our sponsors can be found at\nwww.vectorinstitute.ai/# partners.\n\nSentiment Evaluation\nText: $AAPL afternoon selloff as usual will be brutal. Get\nready to lose a ton of money.\nLabel: Negative Predicted: Negative\nReasoning: “afternoon selloff as usual will be brutal”, “get\nready to lose a ton of money” strongly negative sentiment.\nEvaluation: Consistent and correct; matches Negative sen-\ntiment with reasoning (e.g., “brutal” and financial loss).\nSentiment Evaluation\nText: Dealers said the share was hit by investor disappoint-\nment over a refining margin of 9.48 USD per barrel and\nshipping performance decline.\nLabel: Negative Predicted: Neutral\nReasoning: Negative: “disappointment” and declining EBIT\nsuggest negativity; Neutral: data tone is factual.\nEvaluation: Inconsistent prediction; factual tone doesn’t\nnegate “disappointment” and negative financial performance.\nSentiment Evaluation\nText: Recent deliveries include refinery technology to Anrak\nAluminium and sintering plants to Bhushan Steel.\nLabel: Neutral Predicted: Neutral\nReasoning: Purely factual information, no emotive or eval-\nuative language.\nEvaluation: Consistent and correct; neutral tone matches\nfactual details.\nSentiment Evaluation\nText: Cinema Series concludes with a profile of Finnish\ninventor Olavi Linden, whose work has led to dozens of\ndesign awards.\nLabel: Neutral Predicted: Positive\nReasoning: Positive: “dozens of design awards” implies\nachievement; Neutral: factual and descriptive tone; “con-\ncludes” is neutral.\nEvaluation: Inconsistent; factual tone suggests Neutral, de-\nspite positive implications of “awards.”\nFig. 3. Key Examples of Sentiment Analysis Experiments\nREFERENCES\n[1] Meta AI. Llama 3.2 model card, 2024. Accessed: 2024-09-25.\n[2] Enrico Barbierato and Alice Gatti. Towards green ai. a methodological\nsurvey of the scientific literature. IEEE Access, 2024.\n[3] Stefanie Betz, Birgit Penzenstadler, Leticia Duboc, Ruzanna Chitchyan,\nSedef Akinli Kocak, Ian Brooks, Shola Oyedeji, Jari Porras, Norbert\nSeyff, and Colin C Venters. Lessons learned from developing a sus-\ntainability awareness framework for software engineering using design\nscience. ACM Transactions on Software Engineering and Methodology ,\n33(5):1–39, 2024.\n[4] Ver ´onica Bol ´on-Canedo, Laura Mor ´an-Fern´andez, Brais Cancela, and\nAmparo Alonso-Betanzos. A review of green artificial intelligence:\nTowards a more sustainable future.Neurocomputing, page 128096, 2024.\n[5] Lingjiao Chen, Matei Zaharia, and James Zou. Frugalgpt: How to use\nlarge language models while reducing cost and improving performance.\narXiv preprint arXiv:2305.05176 , 2023.\n[6] Lingjiao Chen, Matei Zaharia, and James Y Zou. Frugalml: How to\nuse ml prediction apis more accurately and cheaply. Advances in neural\ninformation processing systems , 33:10685–10696, 2020.\n[7] Leticia Duboc, Stefanie Betz, Birgit Penzenstadler, Sedef Akinli Kocak,\nRuzanna Chitchyan, Ola Leifler, Jari Porras, Norbert Seyff, and Colin C\nVenters. Do we really know what we are building? raising awareness\nof potential sustainability effects of software systems in requirements\nengineering. In 2019 IEEE 27th international requirements engineering\nconference (RE), pages 6–16. IEEE, 2019.\n[8] Jinze Bai et al. Qwen technical report, 2023. Accessed: 2024-09-25.\n[9] Elias Frantar, Saleh Ashkboos, Torsten Hoefler, and Dan Alistarh.\nGptq: Accurate post-training quantization for generative pre-trained\ntransformers. arXiv preprint arXiv:2210.17323 , 2022.\n[10] Robin Geens, Man Shi, Arne Symons, Chao Fang, and Marian Verhelst.\nEnergy cost modelling for optimizing large language model inference on\nhardware accelerators. In 2024 IEEE 37th International System-on-Chip\nConference (SOCC), pages 1–6. IEEE, 2024.\n[11] Song Han, Huizi Mao, and William J Dally. Deep compression:\nCompressing deep neural networks with pruning, trained quantization\nand huffman coding. arXiv preprint arXiv:1510.00149 , 2015.\n[12] Kai Huang, Hanyun Yin, Heng Huang, and Wei Gao. Towards green\nai in fine-tuning large language models via adaptive backpropagation.\narXiv preprint arXiv:2309.13192 , 2023.\n[13] Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford,\nDevendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna\nLengyel, Guillaume Lample, Lucile Saulnier, L ´elio Renard Lavaud,\nMarie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril,\nThomas Wang, Timoth ´ee Lacroix, and William El Sayed. Mistral 7b,\n2023. Accessed: 2024-09-25.\n[14] Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee. Visual\ninstruction tuning, 2023. Accessed: 2024-09-25.\n[15] Vivian Liu and Yiqiao Yin. Green ai: exploring carbon footprints,\nmitigation strategies, and trade offs in large language model training.\nDiscover Artificial Intelligence, 4(1):49, 2024.\n[16] Zechun Liu, Barlas Oguz, Changsheng Zhao, Ernie Chang, Pierre Stock,\nYashar Mehdad, Yangyang Shi, Raghuraman Krishnamoorthi, and Vikas\nChandra. Llm-qat: Data-free quantization aware training for large\nlanguage models. arXiv preprint arXiv:2305.17888 , 2023.\n[17] Alexandra Sasha Luccioni, Sylvain Viguier, and Anne-Laure Ligozat.\nEstimating the carbon footprint of bloom, a 176b parameter language\nmodel. Journal of Machine Learning Research , 24(253):1–15, 2023.\n[18] Pekka Malo, Ankur Sinha, Pekka Korhonen, Jyrki Wallenius, and Pyry\nTakala. Good debt or bad debt: Detecting semantic orientations in\neconomic texts. Journal of the Association for Information Science and\nTechnology, 65(4):782–796, 2014.\n[19] Ollama Technologies. Ollama: Ai-powered insights for language models,\n2023. Accessed: [Access Date].\n[20] Shaina Raza, Oluwanifemi Bamgbose, Shardul Ghuge, Fatemeh\nTavakoli, and Deepak John Reji. Developing safe and responsible\nlarge language models–a comprehensive framework. arXiv preprint\narXiv:2404.01399, 2024.\n[21] Microsoft AI Research. Phi-3 technical report: A highly capable\nlanguage model locally on your phone, 2024. Accessed: 2024-09-25.\n[22] Shivanshu Shekhar, Tanishq Dubey, Koyel Mukherjee, Apoorv Saxena,\nAtharv Tyagi, and Nishanth Kotla. Towards optimizing the costs of llm\nusage. arXiv preprint arXiv:2402.01742 , 2024.\n[23] Jieke Shi, Zhou Yang, Hong Jin Kang, Bowen Xu, Junda He, and\nDavid Lo. Greening large language models of code. In Proceedings of\nthe 46th International Conference on Software Engineering: Software\nEngineering in Society , pages 142–153, 2024.\n[24] Jieke Shi, Zhou Yang, and David Lo. Efficient and green large language\nmodels for software engineering: Vision and the road ahead. ACM\nTransactions on Software Engineering and Methodology , 2024.\n[25] Abdulaziz Tabbakh, Lisan Al Amin, Mahbubul Islam, GM Iqbal Mah-\nmud, Imranul Kabir Chowdhury, and Md Saddam Hossain Mukta. To-\nwards sustainable ai: a comprehensive framework for green ai. Discover\nSustainability, 5(1):408, 2024.\n[26] Colin C Venters, Sedef Akinli Kocak, Stefanie Betz, Ian Brooks,\nRafael Capilla, Ruzanna Chitchyan, Let ´ıcia Duboc, Rogardt Heldal,\nAna Moreira, Shola Oyedeji, et al. Software sustainability: beyond the\ntower of babel. In 2021 IEEE/ACM International Workshop on Body of\nKnowledge for Software Sustainability (BoKSS), pages 3–4. IEEE, 2021.\n[27] Roberto Verdecchia, June Sallou, and Lu ´ıs Cruz. A systematic review of\ngreen ai. Wiley Interdisciplinary Reviews: Data Mining and Knowledge\nDiscovery, 13(4):e1507, 2023.", "metadata": {"url": "https://arxiv.org/pdf/2504.06307", "type": "paper", "year": "2025"}, "sections": [{"title": "Page 1", "paragraphs": [{"text": "Optimizing Large Language Models: Metrics,\nEnergy Efficiency, and Case Study Insights\nTahniat Khan\nIndustry Innovation, Vector Institute\nToronto, Canada\ntahniat.khan@vectorinstitute.ai\nSoroor Motie\nVector Institute, University of Ottawa\nOttawa, Canada\nsmoti088@uottawa.ca\nSedef Akinli Kocak\nIndustry Innovation, Vector Institute\nToronto, Canada\nsedef.kocak@vectorinstitute.ai\nShaina Raza\nAI Engineering, Vector Institute\nToronto, Canada\nshaina.raza@vectorinstitute.ai\nAbstract—The rapid adoption of large language models\n(LLMs) has led to significant energy consumption and carbon\nemissions, posing a critical challenge to the sustainability of\ngenerative AI technologies. This paper explores the integration\nof energy-efficient optimization techniques in the deployment\nof LLMs to address these environmental concerns. We present\na case study and framework that demonstrate how strategic\nquantization and local inference techniques can substantially\nlower the carbon footprints of LLMs without compromising their\noperational effectiveness. Experimental results reveal that these\nmethods can reduce energy consumption and carbon emissions\nby up to 45% post quantization, making them particularly\nsuitable for resource-constrained environments. The findings\nprovide actionable insights for achieving sustainability in AI while\nmaintaining high levels of accuracy and responsiveness.\nIndex Terms—Large Language Models (LLMs), Quantization,\nGreen AI, Carbon Emissions, Energy Efficiency\nI. I NTRODUCTION\nThe increasing computational demands of advanced artifi-\ncial intelligence (AI), particularly generative models including\nlarge language models (LLMs), have motivated significant\nresearch and development in Green AI . It highlights the\nimportance of adopting sustainable practices to mitigate the\nrising environmental impact of generative AI technologies\n[4]. However, despite these advances, many generative AI\napplications continue to consume substantial computational\nresources, leading to increased energy consumption and el-\nevated carbon emissions [27]. As these generative AI models\nand applications scale in both size and complexity, they\ndemand frequent data and model updates, creating a potentially\nunending cycle of energy-intensive processes that could hinder\noverall progress in sustainable AI [27].\nGenerative AI tools such as ChatGPT, GPT-3, Claude, and\nLlama demonstrate remarkable capabilities but come with sig-\nnificant ecological costs associated with their development and\ninfrastructure [4]. Data centers, which support the underlying\ncomputational needs of these tools, are estimated to contribute\napproximately 2–3 1. of global greenhouse gas emissions, with\n1https://dl.acm.org/doi/pdf/10.1145/3483410\nboth energy and water usage rising alongside the rapid growth\nof global data volumes. Moreover, hyperscale cloud providers,\nincluding Amazon AWS, Google Cloud, and Microsoft Azure,\ncommonly use power-intensive GPUs for hosting generative\nAI models; these GPUs can consume 10–15 times the energy\nof traditional CPUs, significantly enlarging the technology’s\ncarbon footprint [2]. Understanding the full lifecycle of emis-\nsions for machine learning models is therefore essential for\ntackling these environmental challenges [2]. Strategies aimed\nat lowering energy demands across this lifecycle—ranging\nfrom pre-training to inference—represent a critical step in\nachieving sustainable generative AI solutions [2].\na) Motivation: Motivated by the environmental impact\nof LLMs, this study seeks to quantify the carbon emissions\nassociated with training and inference for these models. While\nthere is growing recognition of the need for more energy-\nefficient LLMs, the research gap lies in the lack of awareness\nand practical demonstrations showing similar results can be\nachieved with lower energy consumption. Addressing this gap\nrequires not only quantifying the environmental footprint of\ngenerative AI models but also exploring effective optimization\nstrategies. Moreover, analyzing a specific use case can provide\nvaluable insights into the practical benefits of adopting energy-\nefficient methods while maintaining model performance.\nb) Objectives: In this work, we examine the metrics and\nunits currently used to measure the environmental footprint of\npopular generative AI models and evaluate how these metrics\nchange when implementing optimization strategies. We then\npresent a case study demonstrating how targeted optimizations\ncan make generative AI models more energy efficient without\ncompromising their performance in a real-world context.\nThe primary objectives of this study are threefold:\n• To enhance energy efficiency of LLMs by measuring and\nminimizing energy consumption during inference.\n• To reduce carbon emissions by assessing and mitigating\nthe carbon footprint generated in the deployment phase\nof LLMs.\n• To develop a methodology prioritizes performance preser-\nvation, ensuring that accuracy and responsiveness remain© 2025 IEEE. Accepted to IEEE CAI 2025, to appear in IEEE Xplore.\narXiv:2504.06307v1  [cs.LG]  7 Apr 2025", "sentences": [{"text": "Optimizing Large Language Models: Metrics,\nEnergy Efficiency, and Case Study Insights\nTahniat Khan\nIndustry Innovation, Vector Institute\nToronto, Canada\ntahniat.khan@vectorinstitute.ai\nSoroor Motie\nVector Institute, University of Ottawa\nOttawa, Canada\nsmoti088@uottawa.ca\nSedef Akinli Kocak\nIndustry Innovation, Vector Institute\nToronto, Canada\nsedef.kocak@vectorinstitute.ai\nShaina Raza\nAI Engineering, Vector Institute\nToronto, Canada\nshaina.raza@vectorinstitute.ai\nAbstract—The rapid adoption of large language models\n(LLMs) has led to significant energy consumption and carbon\nemissions, posing a critical challenge to the sustainability of\ngenerative AI technologies.", "metadata": {}}, {"text": "This paper explores the integration\nof energy-efficient optimization techniques in the deployment\nof LLMs to address these environmental concerns.", "metadata": {}}, {"text": "We present\na case study and framework that demonstrate how strategic\nquantization and local inference techniques can substantially\nlower the carbon footprints of LLMs without compromising their\noperational effectiveness.", "metadata": {}}, {"text": "Experimental results reveal that these\nmethods can reduce energy consumption and carbon emissions\nby up to 45% post quantization, making them particularly\nsuitable for resource-constrained environments.", "metadata": {}}, {"text": "The findings\nprovide actionable insights for achieving sustainability in AI while\nmaintaining high levels of accuracy and responsiveness.", "metadata": {}}, {"text": "Index Terms—Large Language Models (LLMs), Quantization,\nGreen AI, Carbon Emissions, Energy Efficiency\nI.", "metadata": {}}, {"text": "I NTRODUCTION\nThe increasing computational demands of advanced artifi-\ncial intelligence (AI), particularly generative models including\nlarge language models (LLMs), have motivated significant\nresearch and development in Green AI .", "metadata": {}}, {"text": "It highlights the\nimportance of adopting sustainable practices to mitigate the\nrising environmental impact of generative AI technologies\n[4].", "metadata": {}}, {"text": "However, despite these advances, many generative AI\napplications continue to consume substantial computational\nresources, leading to increased energy consumption and el-\nevated carbon emissions [27].", "metadata": {}}, {"text": "As these generative AI models\nand applications scale in both size and complexity, they\ndemand frequent data and model updates, creating a potentially\nunending cycle of energy-intensive processes that could hinder\noverall progress in sustainable AI [27].", "metadata": {}}, {"text": "Generative AI tools such as ChatGPT, GPT-3, Claude, and\nLlama demonstrate remarkable capabilities but come with sig-\nnificant ecological costs associated with their development and\ninfrastructure [4].", "metadata": {}}, {"text": "Data centers, which support the underlying\ncomputational needs of these tools, are estimated to contribute\napproximately 2–3 1.", "metadata": {}}, {"text": "of global greenhouse gas emissions, with\n1https://dl.acm.org/doi/pdf/10.1145/3483410\nboth energy and water usage rising alongside the rapid growth\nof global data volumes.", "metadata": {}}, {"text": "Moreover, hyperscale cloud providers,\nincluding Amazon AWS, Google Cloud, and Microsoft Azure,\ncommonly use power-intensive GPUs for hosting generative\nAI models;", "metadata": {}}, {"text": "these GPUs can consume 10–15 times the energy\nof traditional CPUs, significantly enlarging the technology’s\ncarbon footprint [2].", "metadata": {}}, {"text": "Understanding the full lifecycle of emis-\nsions for machine learning models is therefore essential for\ntackling these environmental challenges [2].", "metadata": {}}, {"text": "Strategies aimed\nat lowering energy demands across this lifecycle—ranging\nfrom pre-training to inference—represent a critical step in\nachieving sustainable generative AI solutions [2].", "metadata": {}}, {"text": "a) Motivation: Motivated by the environmental impact\nof LLMs, this study seeks to quantify the carbon emissions\nassociated with training and inference for these models.", "metadata": {}}, {"text": "While\nthere is growing recognition of the need for more energy-\nefficient LLMs, the research gap lies in the lack of awareness\nand practical demonstrations showing similar results can be\nachieved with lower energy consumption.", "metadata": {}}, {"text": "Addressing this gap\nrequires not only quantifying the environmental footprint of\ngenerative AI models but also exploring effective optimization\nstrategies.", "metadata": {}}, {"text": "Moreover, analyzing a specific use case can provide\nvaluable insights into the practical benefits of adopting energy-\nefficient methods while maintaining model performance.", "metadata": {}}, {"text": "b) Objectives: In this work, we examine the metrics and\nunits currently used to measure the environmental footprint of\npopular generative AI models and evaluate how these metrics\nchange when implementing optimization strategies.", "metadata": {}}, {"text": "We then\npresent a case study demonstrating how targeted optimizations\ncan make generative AI models more energy efficient without\ncompromising their performance in a real-world context.", "metadata": {}}, {"text": "The primary objectives of this study are threefold:\n• To enhance energy efficiency of LLMs by measuring and\nminimizing energy consumption during inference.", "metadata": {}}, {"text": "• To reduce carbon emissions by assessing and mitigating\nthe carbon footprint generated in the deployment phase\nof LLMs.", "metadata": {}}, {"text": "• To develop a methodology prioritizes performance preser-\nvation, ensuring that accuracy and responsiveness remain© 2025 IEEE.", "metadata": {}}, {"text": "Accepted to IEEE CAI 2025, to appear in IEEE Xplore.", "metadata": {}}, {"text": "arXiv:2504.06307v1  [cs.LG]  7 Apr 2025", "metadata": {}}], "metadata": {"page": 1}}], "metadata": {"page": 1}}, {"title": "Page 2", "paragraphs": [{"text": "at high levels even as we adopt energy-saving techniques.\nc) Contributions: This study offers several contributions\nto the growing field of Green AI . Primarily, it presents a\ncomprehensive analysis of carbon emissions generated during\nboth the training and inference phases of LLMs, a critical area\noften overlooked in performance evaluations. Furthermore, the\nstudy critically evaluates widely adopted emissions metrics,\nexploring their dynamic behavior under different optimization\nstrategies. Additional contribution lies in the implementation\nof a practical optimization framework designed to minimize\nenergy consumption across the model lifecycle. Finally, a\ndetailed case study provides empirical evidence of measur-\nable reductions in carbon footprint and energy consumption\nachieved without compromising model performance, offering\npractical guidance for sustainable AI development.\nII. R ELATED WORK\nIn recent years, the convergence of environmental sus-\ntainability and AI has led to the emergence of “in Green\nAI”, focusing on reducing the carbon footprint of large-scale\nmodels through optimization techniques. This section reviews\nkey studies that have contributed to this field, highlighting their\ncontributions to sustainable AI practices.\nEfforts to mitigate the environmental impact of LLMs have\nfocused on understanding and reducing their carbon footprint.\nStudies have quantified the CO 2 emissions associated with\nlarge-scale models [2], [4], highlighting significant environ-\nmental challenges posed by their extensive parameter sizes and\ncomputational demands [15]. Liu and Yin (2024), in particular,\nemphasizes the critical role of hardware choices in sustainable\nAI practices and proposes training methods without compro-\nmising performance to reduce carbon emissions [15]. These\nfoundational insights underscore the urgency of addressing\nsustainability in LLM development and deployment.\nBuilding on this foundation, several tools and frameworks\nhave been proposed. For example, GreenTrainer [12] has\nbeen introduced as a fine-tuning approach that dynamically\nevaluates backpropagation costs and contributions to model ac-\ncuracy. By reducing floating-point operations (FLOPs) during\nfine-tuning by up to 64%, GreenTrainer achieves significant\nenergy savings without compromising model performance\n[12]. Likewise, Avatar focuses on creating compact, energy-\nefficient models optimized for deployment on individual de-\nvices [23]. By reducing inference latency and model size,\nthis method significantly decreases the carbon footprint of\nLLM usage while maintaining competitive performance [20],\nillustrating the potential of targeted optimizations [17].\nIn addition to specific optimization techniques, broader\nframeworks for sustainable AI have been proposed. These\nframeworks advocate for the integration of energy-efficient\nalgorithms and the alignment of AI practices with global\nsustainability goals [25]. For instance, intersection of sustain-\nability and software engineering is well established research\narea [3], [7], [26] such as exploring strategies for creating eco-\nfriendly solutions that maintain functionality while reducing\nenergy consumption [24]. Collectively, these studies provide\nactionable insights and a roadmap for advancing Green AI,\naddressing immediate environmental concerns, and fostering\na sustainable future for AI technologies.\nA. Carbon Emission Metrics\nMeasuring carbon emissions is essential for understand-\ning and reducing the environmental impact of AI systems.\nVarious metrics have been developed to assess emissions\nacross different scopes, intensities, and stages. This subsection\noutlines widely used metrics, such as Carbon Dioxide Equiva-\nlent (CO 2e), Carbon Intensity, and Global Warming Potential\n(GWP) and highlights their role in promoting transparency and\nsustainability (Table I).\nTABLE I\nCOMMON CARBON EMISSION METRICS IN GREEN AI\nMetric Unit Definition Reference\nCarbon Dioxide\nEquivalent (CO2e)\nMetric\ntons\n(tCO2e)\nA measure of green-\nhouse gases expressed as\nCO2 equivalent\nIPCC, GHG\nProtocol\nCarbon Intensity gCO2/\nkWh\nCO2 emissions per unit\nof electricity consumed\nInternational\nEnergy\nAgency\nScope 1 Emissions tCO2e Direct emissions from\ncontrolled sources\nGHG Proto-\ncol\nScope 2 Emissions tCO2e Indirect emissions from\npurchased electricity\nGHG Proto-\ncol\nScope 3 Emissions tCO2e Indirect emissions\nacross value chains\nGHG Proto-\ncol\nNet Zero\nEmissions\ntCO2e Balance when emissions\nequal removals\nUNFCCC\nEnergy Consump-\ntion\nMWh Total energy consumed IEA, EIA\nGlobal Warming\nPotential (GWP)\nRatio Heat trapped by a gas\ncompared to CO 2\nIPCC\nCarbon Offsets tCO2e Credits for emissions re-\nduction or removal\nVCS, Gold\nStandard\nCarbon Capture\nand Storage (CCS)\ntCO2\ncaptured\nCO2 removed and stored\nto prevent release\nIEA, IPCC\nB. Quantization Techniques in LLMs\nQuantization [11] has emerged as a transformative approach\nin optimizing LLMs, addressing the dual challenges of com-\nputational efficiency and environmental sustainability. It works\nby converting model parameters from high-precision formats\n(e.g., 32-bit floating-point) to lower-precision formats (e.g., 8-\nbit or even 4-bit), thereby reducing memory requirements and\naccelerating computation. This technique aligns closely with\nthe goals of Green AI, as it minimizes resource usage while\nmaintaining acceptable accuracy.\nResearch efforts have showcased the potential of quanti-\nzation as a key technique for enhancing energy efficiency\nin AI systems. For instance, GPTQ (Accurate Post-Training\nQuantization for Generative Pre-trained Transformers) [9] in-\ntroduces a method for post-training quantization that retains\nhigh model performance despite significant reductions in pa-\nrameter precision. This method enables efficient deployment\nof LLMs on edge devices and other constrained environments,\ndirectly addressing the environmental concerns highlighted in\nstudies like GreenTrainer [12]. Another notable approach is", "sentences": [{"text": "at high levels even as we adopt energy-saving techniques.", "metadata": {}}, {"text": "c) Contributions: This study offers several contributions\nto the growing field of Green AI .", "metadata": {}}, {"text": "Primarily, it presents a\ncomprehensive analysis of carbon emissions generated during\nboth the training and inference phases of LLMs, a critical area\noften overlooked in performance evaluations.", "metadata": {}}, {"text": "Furthermore, the\nstudy critically evaluates widely adopted emissions metrics,\nexploring their dynamic behavior under different optimization\nstrategies.", "metadata": {}}, {"text": "Additional contribution lies in the implementation\nof a practical optimization framework designed to minimize\nenergy consumption across the model lifecycle.", "metadata": {}}, {"text": "Finally, a\ndetailed case study provides empirical evidence of measur-\nable reductions in carbon footprint and energy consumption\nachieved without compromising model performance, offering\npractical guidance for sustainable AI development.", "metadata": {}}, {"text": "II.", "metadata": {}}, {"text": "R ELATED WORK\nIn recent years, the convergence of environmental sus-\ntainability and AI has led to the emergence of “in Green\nAI”, focusing on reducing the carbon footprint of large-scale\nmodels through optimization techniques.", "metadata": {}}, {"text": "This section reviews\nkey studies that have contributed to this field, highlighting their\ncontributions to sustainable AI practices.", "metadata": {}}, {"text": "Efforts to mitigate the environmental impact of LLMs have\nfocused on understanding and reducing their carbon footprint.", "metadata": {}}, {"text": "Studies have quantified the CO 2 emissions associated with\nlarge-scale models [2], [4], highlighting significant environ-\nmental challenges posed by their extensive parameter sizes and\ncomputational demands [15].", "metadata": {}}, {"text": "Liu and Yin (2024), in particular,\nemphasizes the critical role of hardware choices in sustainable\nAI practices and proposes training methods without compro-\nmising performance to reduce carbon emissions [15].", "metadata": {}}, {"text": "These\nfoundational insights underscore the urgency of addressing\nsustainability in LLM development and deployment.", "metadata": {}}, {"text": "Building on this foundation, several tools and frameworks\nhave been proposed.", "metadata": {}}, {"text": "For example, GreenTrainer [12] has\nbeen introduced as a fine-tuning approach that dynamically\nevaluates backpropagation costs and contributions to model ac-\ncuracy.", "metadata": {}}, {"text": "By reducing floating-point operations (FLOPs) during\nfine-tuning by up to 64%, GreenTrainer achieves significant\nenergy savings without compromising model performance\n[12].", "metadata": {}}, {"text": "Likewise, Avatar focuses on creating compact, energy-\nefficient models optimized for deployment on individual de-\nvices [23].", "metadata": {}}, {"text": "By reducing inference latency and model size,\nthis method significantly decreases the carbon footprint of\nLLM usage while maintaining competitive performance [20],\nillustrating the potential of targeted optimizations [17].", "metadata": {}}, {"text": "In addition to specific optimization techniques, broader\nframeworks for sustainable AI have been proposed.", "metadata": {}}, {"text": "These\nframeworks advocate for the integration of energy-efficient\nalgorithms and the alignment of AI practices with global\nsustainability goals [25].", "metadata": {}}, {"text": "For instance, intersection of sustain-\nability and software engineering is well established research\narea [3], [7], [26] such as exploring strategies for creating eco-\nfriendly solutions that maintain functionality while reducing\nenergy consumption [24].", "metadata": {}}, {"text": "Collectively, these studies provide\nactionable insights and a roadmap for advancing Green AI,\naddressing immediate environmental concerns, and fostering\na sustainable future for AI technologies.", "metadata": {}}, {"text": "A.", "metadata": {}}, {"text": "Carbon Emission Metrics\nMeasuring carbon emissions is essential for understand-\ning and reducing the environmental impact of AI systems.", "metadata": {}}, {"text": "Various metrics have been developed to assess emissions\nacross different scopes, intensities, and stages.", "metadata": {}}, {"text": "This subsection\noutlines widely used metrics, such as Carbon Dioxide Equiva-\nlent (CO 2e), Carbon Intensity, and Global Warming Potential\n(GWP) and highlights their role in promoting transparency and\nsustainability (Table I).", "metadata": {}}, {"text": "TABLE I\nCOMMON CARBON EMISSION METRICS IN GREEN AI\nMetric Unit Definition Reference\nCarbon Dioxide\nEquivalent (CO2e)\nMetric\ntons\n(tCO2e)\nA measure of green-\nhouse gases expressed as\nCO2 equivalent\nIPCC, GHG\nProtocol\nCarbon Intensity gCO2/\nkWh\nCO2 emissions per unit\nof electricity consumed\nInternational\nEnergy\nAgency\nScope 1 Emissions tCO2e Direct emissions from\ncontrolled sources\nGHG Proto-\ncol\nScope 2 Emissions tCO2e Indirect emissions from\npurchased electricity\nGHG Proto-\ncol\nScope 3 Emissions tCO2e Indirect emissions\nacross value chains\nGHG Proto-\ncol\nNet Zero\nEmissions\ntCO2e Balance when emissions\nequal removals\nUNFCCC\nEnergy Consump-\ntion\nMWh Total energy consumed IEA, EIA\nGlobal Warming\nPotential (GWP)\nRatio Heat trapped by a gas\ncompared to CO 2\nIPCC\nCarbon Offsets tCO2e Credits for emissions re-\nduction or removal\nVCS, Gold\nStandard\nCarbon Capture\nand Storage (CCS)\ntCO2\ncaptured\nCO2 removed and stored\nto prevent release\nIEA, IPCC\nB.", "metadata": {}}, {"text": "Quantization Techniques in LLMs\nQuantization [11] has emerged as a transformative approach\nin optimizing LLMs, addressing the dual challenges of com-\nputational efficiency and environmental sustainability.", "metadata": {}}, {"text": "It works\nby converting model parameters from high-precision formats\n(e.g., 32-bit floating-point) to lower-precision formats (e.g., 8-\nbit or even 4-bit), thereby reducing memory requirements and\naccelerating computation.", "metadata": {}}, {"text": "This technique aligns closely with\nthe goals of Green AI, as it minimizes resource usage while\nmaintaining acceptable accuracy.", "metadata": {}}, {"text": "Research efforts have showcased the potential of quanti-\nzation as a key technique for enhancing energy efficiency\nin AI systems.", "metadata": {}}, {"text": "For instance, GPTQ (Accurate Post-Training\nQuantization for Generative Pre-trained Transformers) [9] in-\ntroduces a method for post-training quantization that retains\nhigh model performance despite significant reductions in pa-\nrameter precision.", "metadata": {}}, {"text": "This method enables efficient deployment\nof LLMs on edge devices and other constrained environments,\ndirectly addressing the environmental concerns highlighted in\nstudies like GreenTrainer [12].", "metadata": {}}, {"text": "Another notable approach is", "metadata": {}}], "metadata": {"page": 2}}], "metadata": {"page": 2}}, {"title": "Page 3", "paragraphs": [{"text": "LLM-QAT (Quantization-Aware Training for Large Language\nModels) [16], which integrates quantization during the training\nphase rather than applying it post-training. This method further\nimproves the trade-off between model size and performance,\nmaking LLMs more adaptable to energy-efficient deployments.\nAdditionally, SmoothQuant [16] employs layer-wise quantiza-\ntion to balance computation and accuracy, achieving state-of-\nthe-art results in reducing energy use during inference.\nC. Trade-Offs Between Accuracy and Optimization\nThe interplay between accuracy and optimization in ma-\nchine learning models, particularly LLMs, underscores the\nchallenges in balancing performance with resource efficiency.\nTechniques like FrugalGPT, described by Chen et al. (2023)\n[5], illustrate how cascading models and leveraging prompt\nadaptation can reduce costs by up to 98% without compromis-\ning accuracy. Similarly, FrugalML shows how selectively rout-\ning queries to different APIs can maintain performance while\ncutting costs by up to 90% [5], [6]. However, the effectiveness\nof these strategies varies across tasks. For example, reducing\ntoken lengths or approximating model outputs might preserve\ngeneral quality but risks performance drops in nuanced appli-\ncations like sentiment analysis or summarization [22]. These\nfindings reveal that while cost and carbon footprint reductions\nare achievable, ensuring minimal trade-offs in precision, recall,\nor F1 score remains a complex optimization problem, often\nrequiring task-specific calibrations [5], [22].\nIII. C ASE STUDY: SUSTAINABLE DEPLOYMENT OF LARGE\nLANGUAGE MODELS\nA. Problem Definition\nLLMs have become integral to various natural language\nprocessing applications, yet their soaring computational de-\nmands pose significant sustainability challenges. These include\nhigh energy consumption, carbon emissions, and escalating\noperational costs, particularly when using cloud-based infras-\ntructures [4]. To address these concerns, this study proposes\na framework for LLM deployment that emphasizes local\ninference, aiming to mitigate environmental impact while\npreserving model performance and user experience.\nFormally, consider a classification problem with input data\nX = {x1, x2, . . . , xN }, (1)\nand corresponding ground-truth labels\nY = {y1, y2, . . . , yN }, y i ∈ {1, 2, . . . , K}, (2)\nAn LLM-based classifier fθ(·) predicts ˆyi = fθ(xi). We\nseek to minimize energy consumption and carbon emissions\nwhile maintaining high predictive accuracy, where accuracy\ncan be quantified using standard metrics such as precision,\nrecall, and F1-score.\nB. Framework Overview\nThe proposed framework (Figure. 1) tackles energy effi-\nciency in LLM deployment through three interconnected com-\nponents: local inference optimization, the selection of energy-\nefficient LLMs, and a comprehensive evaluation methodology.\nThese components function synergistically to reduce energy\nconsumption without sacrificing predictive accuracy or respon-\nsiveness.\nFig. 1. Detailed Overview of the Proposed Optimization Framework\n1) Local Inference Optimization: Unlike traditional cloud-\nbased methods that rely on centralized data centers, local\ninference allows models to run directly on user devices while\nmaintaining data privacy. By minimizing data transmission\nbetween clients and remote servers, this method significantly\nreduces both network overhead and carbon footprint [10]. To\nachieve efficient local inference, the framework employs a\nquantization process [9], which lowers the numerical preci-\nsion of model parameters. Specifically, we define a uniform\nquantization function Qb(·) that maps 32-bit weight tensors to\na b-bit representation:\nQb(w) = round\n\u0010 w − min(w)\n∆\n\u0011\n, (3)\nwhere ∆ is a scaling factor determined by the range\n(max(w) − min(w)) of the weights. In this work, we use a 4-\nbit quantization strategy ( b = 4), which substantially reduces\ncomputational and memory requirements without significantly\ncompromising model performance. We apply quantization\nthrough Ollama [19], an open-source platform known for\nits support of edge computing principles and privacy-centric\ndeployments.\n2) Selection of Energy-Efficient Pre-trained LLMs: In ad-\ndition to local inference optimization, the framework includes\na careful selection of pre-trained LLMs that are specifically\ndesigned for low computational overhead. These models, in-\ncluding Llama3.2 [1], Phi3.2 [21], Mistral [13], Qwen [8],\nand Llava [14], stand out for their smaller parameter counts,\nstreamlined architectures, and selective attention mechanisms.\nSuch features align well with edge-oriented design principles,", "sentences": [{"text": "LLM-QAT (Quantization-Aware Training for Large Language\nModels) [16], which integrates quantization during the training\nphase rather than applying it post-training.", "metadata": {}}, {"text": "This method further\nimproves the trade-off between model size and performance,\nmaking LLMs more adaptable to energy-efficient deployments.", "metadata": {}}, {"text": "Additionally, SmoothQuant [16] employs layer-wise quantiza-\ntion to balance computation and accuracy, achieving state-of-\nthe-art results in reducing energy use during inference.", "metadata": {}}, {"text": "C.", "metadata": {}}, {"text": "Trade-Offs Between Accuracy and Optimization\nThe interplay between accuracy and optimization in ma-\nchine learning models, particularly LLMs, underscores the\nchallenges in balancing performance with resource efficiency.", "metadata": {}}, {"text": "Techniques like FrugalGPT, described by Chen et al.", "metadata": {}}, {"text": "(2023)\n[5], illustrate how cascading models and leveraging prompt\nadaptation can reduce costs by up to 98% without compromis-\ning accuracy.", "metadata": {}}, {"text": "Similarly, FrugalML shows how selectively rout-\ning queries to different APIs can maintain performance while\ncutting costs by up to 90% [5], [6].", "metadata": {}}, {"text": "However, the effectiveness\nof these strategies varies across tasks.", "metadata": {}}, {"text": "For example, reducing\ntoken lengths or approximating model outputs might preserve\ngeneral quality but risks performance drops in nuanced appli-\ncations like sentiment analysis or summarization [22].", "metadata": {}}, {"text": "These\nfindings reveal that while cost and carbon footprint reductions\nare achievable, ensuring minimal trade-offs in precision, recall,\nor F1 score remains a complex optimization problem, often\nrequiring task-specific calibrations [5], [22].", "metadata": {}}, {"text": "III.", "metadata": {}}, {"text": "C ASE STUDY: SUSTAINABLE DEPLOYMENT OF LARGE\nLANGUAGE MODELS\nA.", "metadata": {}}, {"text": "Problem Definition\nLLMs have become integral to various natural language\nprocessing applications, yet their soaring computational de-\nmands pose significant sustainability challenges.", "metadata": {}}, {"text": "These include\nhigh energy consumption, carbon emissions, and escalating\noperational costs, particularly when using cloud-based infras-\ntructures [4].", "metadata": {}}, {"text": "To address these concerns, this study proposes\na framework for LLM deployment that emphasizes local\ninference, aiming to mitigate environmental impact while\npreserving model performance and user experience.", "metadata": {}}, {"text": "Formally, consider a classification problem with input data\nX = {x1, x2, .", "metadata": {}}, {"text": ".", "metadata": {}}, {"text": ".", "metadata": {}}, {"text": ", xN }, (1)\nand corresponding ground-truth labels\nY = {y1, y2, .", "metadata": {}}, {"text": ".", "metadata": {}}, {"text": ".", "metadata": {}}, {"text": ", yN }, y i ∈ {1, 2, .", "metadata": {}}, {"text": ".", "metadata": {}}, {"text": ".", "metadata": {}}, {"text": ", K}, (2)\nAn LLM-based classifier fθ(·) predicts ˆyi = fθ(xi).", "metadata": {}}, {"text": "We\nseek to minimize energy consumption and carbon emissions\nwhile maintaining high predictive accuracy, where accuracy\ncan be quantified using standard metrics such as precision,\nrecall, and F1-score.", "metadata": {}}, {"text": "B.", "metadata": {}}, {"text": "Framework Overview\nThe proposed framework (Figure.", "metadata": {}}, {"text": "1) tackles energy effi-\nciency in LLM deployment through three interconnected com-\nponents: local inference optimization, the selection of energy-\nefficient LLMs, and a comprehensive evaluation methodology.", "metadata": {}}, {"text": "These components function synergistically to reduce energy\nconsumption without sacrificing predictive accuracy or respon-\nsiveness.", "metadata": {}}, {"text": "Fig.", "metadata": {}}, {"text": "1.", "metadata": {}}, {"text": "Detailed Overview of the Proposed Optimization Framework\n1) Local Inference Optimization: Unlike traditional cloud-\nbased methods that rely on centralized data centers, local\ninference allows models to run directly on user devices while\nmaintaining data privacy.", "metadata": {}}, {"text": "By minimizing data transmission\nbetween clients and remote servers, this method significantly\nreduces both network overhead and carbon footprint [10].", "metadata": {}}, {"text": "To\nachieve efficient local inference, the framework employs a\nquantization process [9], which lowers the numerical preci-\nsion of model parameters.", "metadata": {}}, {"text": "Specifically, we define a uniform\nquantization function Qb(·) that maps 32-bit weight tensors to\na b-bit representation:\nQb(w) = round\n\u0010 w − min(w)\n∆\n\u0011\n, (3)\nwhere ∆ is a scaling factor determined by the range\n(max(w) − min(w)) of the weights.", "metadata": {}}, {"text": "In this work, we use a 4-\nbit quantization strategy ( b = 4), which substantially reduces\ncomputational and memory requirements without significantly\ncompromising model performance.", "metadata": {}}, {"text": "We apply quantization\nthrough Ollama [19], an open-source platform known for\nits support of edge computing principles and privacy-centric\ndeployments.", "metadata": {}}, {"text": "2) Selection of Energy-Efficient Pre-trained LLMs: In ad-\ndition to local inference optimization, the framework includes\na careful selection of pre-trained LLMs that are specifically\ndesigned for low computational overhead.", "metadata": {}}, {"text": "These models, in-\ncluding Llama3.2 [1], Phi3.2 [21], Mistral [13], Qwen [8],\nand Llava [14], stand out for their smaller parameter counts,\nstreamlined architectures, and selective attention mechanisms.", "metadata": {}}, {"text": "Such features align well with edge-oriented design principles,", "metadata": {}}], "metadata": {"page": 3}}, {"text": "[Image page=3 idx=1 name=Im1.png] Size: 1602x1140, Data: 282039 bytes", "sentences": [{"text": "[Image page=3 idx=1 name=Im1.png] Size: 1602x1140, Data: 282039 bytes", "metadata": {}}], "metadata": {"page": 3, "image_index": 1, "image_name": "Im1.png", "image_width": 1602, "image_height": 1140, "attachment_type": "image", "has_image_data": true, "image_data_size": 282039}}], "metadata": {"page": 3}}, {"title": "Page 4", "paragraphs": [{"text": "making the models easier to run on devices with limited\nhardware resources.\n3) Evaluation Methodology: The central problem tackled\nhere is a classification task for which we use standard evalu-\nation metrics, including precision, recall, and F1-score. We\nmeasure these metrics both before and after applying our\nquantization approach to understand any performance trade-\noffs. Furthermore, we track energy usage and estimate carbon\nfootprints by monitoring power consumption and utilizing\nemission factor data. Let E denote the total energy consumed\n(in kWh), and let α be the emission factor (kg CO 2 per kWh).\nWe define the carbon footprint CF as:\nCF = E × α., (4)\nC. Expected Outcomes\nThe proposed framework is expected to significantly reduce\nenergy consumption and carbon emissions during LLM infer-\nence, while maintaining accuracy and responsiveness compa-\nrable to standard cloud-based methods. These findings support\nthe goals of Green AI , showing that sustainable solutions\ncan deliver high performance without burdening users or\ncompromising model quality.\nIV. E XPERIMENTAL SETUP\nA. Hardware and Software Setting\nThe hardware used includes an 11th Gen Intel(R) Core(TM)\ni7-1165G7 processor operating at 2.80 GHz (1.69 GHz base\nfrequency), supported by 16.0 GB of installed memory (15.7\nGB usable). The system type is a 64-bit operating system with\nan x64-based processor, running on Windows 11 Pro.\nWe use Ollama [19] for local AI model deployment, which\nensures data privacy by processing entirely on-device, ideal\nfor sensitive applications. It supports a variety of pre-trained\nand fine-tuned models, offering flexibility across use cases.\nIts lightweight design makes it suitable for both individuals\nand organizations seeking efficient, secure, and localized AI\nsolutions.\nBaselines\nWe used the following instruction-tuned models in Table. II\nfor inference, each configured with specific hyperparameters\ntailored to their architecture and target tasks.\nTABLE II\nBASELINE MODELS AND INFERENCE HYPERPARAMETERS\nModel Batch Max Temp. Top-p Top-k Beam\nName Size Tokens Size\nLlama-3.2-1B 8 512 0.7 0.9 50 4\nPhi-3-mini 8 512 0.7 0.9 50 4\nQwen2-7B 8 512 0.8 0.85 40 4\nMistral-7B 16 256 0.9 0.95 30 2\nLLaV A-Llama3 8 512 0.7 0.9 50 4\nThe models used are as follows:\n• Llama-3.2-1B-Instruct: An instruction-tuned large lan-\nguage model for general-purpose tasks.\n• Phi-3-mini-128k-Instruct: An instruction-tuned multi-\nmodal model designed for text and vision integration tasks.\n• Qwen2-7B-Instruct: A transformer-based language model\ntuned for general-purpose tasks.\n• Mistral-7B-Instruct-v0.3: An instruction-tuned model op-\ntimized for efficient NLP tasks.\n• LLaV A-Llama3-Instruct: A fine-tuned version of Llama-3\nInstruct with improvements in multiple benchmarks.\nB. Data\nOur dataset, Financial Sentiment Analysis [18], comprises\n5,842 entries organized into two columns: ”text” and ”label”.\nThe ”text” column contains the textual data for analysis, while\nthe ”label” column indicates the sentiment classification (e.g.,\npositive, negative, or neutral). The dataset is well-structured\nand contains no missing values, making it highly suitable for\nsentiment analysis tasks in machine learning studies Figure. 2.\nSentiment Assessment Instructions\nInstructions: Assess the sentiment of the given text by\nidentifying the presence of sentiment indicators such as\nemotional language, positive or negative expressions, and\ntone shifts. Mark the sentiment as positive, negative, or\nneutral and provide reasoning.\nText: content\nSentiment Indicators Checklist:\n• Emotional Language: Words that convey strong feel-\nings (e.g., joy, anger, sadness, excitement).\n• Positive Expressions: Words or phrases that promote\npositive feelings or optimism.\n• Negative Expressions: Words or phrases that express\ncriticism or negativity.\n• Tone Shifts: Noticeable changes in tone that affect how\nthe content is perceived.\n• Balanced or Neutral Tone: The absence of strong\nemotional language, implying neutrality.\nResponse Format:\nPositive/Negative/Neutral [Reasoning]\nPositive/Negative/Neutral [Reasoning]\nPositive/Negative/Neutral [Reasoning]\nFig. 2. Sentiment Assessment Instructions and Indicators Checklist.\nV. R ESULTS\nA. Accuracy vs Memory Usage\nTable III shows significant reductions in carbon emissions\nacross all models, with some achieving up to 45% after\noptimization. These results demonstrate the effectiveness of\nquantization and local inference in lowering energy use and\ncomputational overhead, while maintaining model perfor-\nmance. Such improvements make these methods well-suited\nfor deployment on edge devices and in resource-constrained\nenvironments.\nHowever, the impact on performance metrics such as accu-\nracy, F1 score, recall, and precision varies. While the reduction\nin carbon footprint is consistent, performance trade-offs are ev-\nident, with some metrics experiencing marginal improvements", "sentences": [{"text": "making the models easier to run on devices with limited\nhardware resources.", "metadata": {}}, {"text": "3) Evaluation Methodology: The central problem tackled\nhere is a classification task for which we use standard evalu-\nation metrics, including precision, recall, and F1-score.", "metadata": {}}, {"text": "We\nmeasure these metrics both before and after applying our\nquantization approach to understand any performance trade-\noffs.", "metadata": {}}, {"text": "Furthermore, we track energy usage and estimate carbon\nfootprints by monitoring power consumption and utilizing\nemission factor data.", "metadata": {}}, {"text": "Let E denote the total energy consumed\n(in kWh), and let α be the emission factor (kg CO 2 per kWh).", "metadata": {}}, {"text": "We define the carbon footprint CF as:\nCF = E × α., (4)\nC.", "metadata": {}}, {"text": "Expected Outcomes\nThe proposed framework is expected to significantly reduce\nenergy consumption and carbon emissions during LLM infer-\nence, while maintaining accuracy and responsiveness compa-\nrable to standard cloud-based methods.", "metadata": {}}, {"text": "These findings support\nthe goals of Green AI , showing that sustainable solutions\ncan deliver high performance without burdening users or\ncompromising model quality.", "metadata": {}}, {"text": "IV.", "metadata": {}}, {"text": "E XPERIMENTAL SETUP\nA.", "metadata": {}}, {"text": "Hardware and Software Setting\nThe hardware used includes an 11th Gen Intel(R) Core(TM)\ni7-1165G7 processor operating at 2.80 GHz (1.69 GHz base\nfrequency), supported by 16.0 GB of installed memory (15.7\nGB usable).", "metadata": {}}, {"text": "The system type is a 64-bit operating system with\nan x64-based processor, running on Windows 11 Pro.", "metadata": {}}, {"text": "We use Ollama [19] for local AI model deployment, which\nensures data privacy by processing entirely on-device, ideal\nfor sensitive applications.", "metadata": {}}, {"text": "It supports a variety of pre-trained\nand fine-tuned models, offering flexibility across use cases.", "metadata": {}}, {"text": "Its lightweight design makes it suitable for both individuals\nand organizations seeking efficient, secure, and localized AI\nsolutions.", "metadata": {}}, {"text": "Baselines\nWe used the following instruction-tuned models in Table.", "metadata": {}}, {"text": "II\nfor inference, each configured with specific hyperparameters\ntailored to their architecture and target tasks.", "metadata": {}}, {"text": "TABLE II\nBASELINE MODELS AND INFERENCE HYPERPARAMETERS\nModel Batch Max Temp.", "metadata": {}}, {"text": "Top-p Top-k Beam\nName Size Tokens Size\nLlama-3.2-1B 8 512 0.7 0.9 50 4\nPhi-3-mini 8 512 0.7 0.9 50 4\nQwen2-7B 8 512 0.8 0.85 40 4\nMistral-7B 16 256 0.9 0.95 30 2\nLLaV A-Llama3 8 512 0.7 0.9 50 4\nThe models used are as follows:\n• Llama-3.2-1B-Instruct: An instruction-tuned large lan-\nguage model for general-purpose tasks.", "metadata": {}}, {"text": "• Phi-3-mini-128k-Instruct: An instruction-tuned multi-\nmodal model designed for text and vision integration tasks.", "metadata": {}}, {"text": "• Qwen2-7B-Instruct: A transformer-based language model\ntuned for general-purpose tasks.", "metadata": {}}, {"text": "• Mistral-7B-Instruct-v0.3: An instruction-tuned model op-\ntimized for efficient NLP tasks.", "metadata": {}}, {"text": "• LLaV A-Llama3-Instruct: A fine-tuned version of Llama-3\nInstruct with improvements in multiple benchmarks.", "metadata": {}}, {"text": "B.", "metadata": {}}, {"text": "Data\nOur dataset, Financial Sentiment Analysis [18], comprises\n5,842 entries organized into two columns: ”text” and ”label”.", "metadata": {}}, {"text": "The ”text” column contains the textual data for analysis, while\nthe ”label” column indicates the sentiment classification (e.g.,\npositive, negative, or neutral).", "metadata": {}}, {"text": "The dataset is well-structured\nand contains no missing values, making it highly suitable for\nsentiment analysis tasks in machine learning studies Figure.", "metadata": {}}, {"text": "2.", "metadata": {}}, {"text": "Sentiment Assessment Instructions\nInstructions: Assess the sentiment of the given text by\nidentifying the presence of sentiment indicators such as\nemotional language, positive or negative expressions, and\ntone shifts.", "metadata": {}}, {"text": "Mark the sentiment as positive, negative, or\nneutral and provide reasoning.", "metadata": {}}, {"text": "Text: content\nSentiment Indicators Checklist:\n• Emotional Language: Words that convey strong feel-\nings (e.g., joy, anger, sadness, excitement).", "metadata": {}}, {"text": "• Positive Expressions: Words or phrases that promote\npositive feelings or optimism.", "metadata": {}}, {"text": "• Negative Expressions: Words or phrases that express\ncriticism or negativity.", "metadata": {}}, {"text": "• Tone Shifts: Noticeable changes in tone that affect how\nthe content is perceived.", "metadata": {}}, {"text": "• Balanced or Neutral Tone: The absence of strong\nemotional language, implying neutrality.", "metadata": {}}, {"text": "Response Format:\nPositive/Negative/Neutral [Reasoning]\nPositive/Negative/Neutral [Reasoning]\nPositive/Negative/Neutral [Reasoning]\nFig.", "metadata": {}}, {"text": "2.", "metadata": {}}, {"text": "Sentiment Assessment Instructions and Indicators Checklist.", "metadata": {}}, {"text": "V.", "metadata": {}}, {"text": "R ESULTS\nA.", "metadata": {}}, {"text": "Accuracy vs Memory Usage\nTable III shows significant reductions in carbon emissions\nacross all models, with some achieving up to 45% after\noptimization.", "metadata": {}}, {"text": "These results demonstrate the effectiveness of\nquantization and local inference in lowering energy use and\ncomputational overhead, while maintaining model perfor-\nmance.", "metadata": {}}, {"text": "Such improvements make these methods well-suited\nfor deployment on edge devices and in resource-constrained\nenvironments.", "metadata": {}}, {"text": "However, the impact on performance metrics such as accu-\nracy, F1 score, recall, and precision varies.", "metadata": {}}, {"text": "While the reduction\nin carbon footprint is consistent, performance trade-offs are ev-\nident, with some metrics experiencing marginal improvements", "metadata": {}}], "metadata": {"page": 4}}], "metadata": {"page": 4}}, {"title": "Page 5", "paragraphs": [{"text": "and others showing slight declines. For instance, precision\nand recall generally exhibit minor increases in specific cases,\nsuggesting that optimization can enhance certain aspects of\nthe models’ ability to correctly identify relevant patterns in the\ndata. On the other hand, metrics like accuracy and F1 score are\nslightly lower after optimization, indicating a potential trade-\noff between energy efficiency and overall predictive perfor-\nmance. This underscores the importance of carefully balancing\nsustainability and performance when applying optimization\ntechniques, as the ideal solution will depend on the specific\nuse case and application requirements.\nTABLE III\nCOMPARISON OF PERFORMANCE METRICS AND CARBON EMISSIONS FOR\nFIVE LLM S BEFORE AND AFTER OPTIMIZATION . CARBON EMISSIONS ARE\nCALCULATED PER INFERENCE TASK .\nModel Name Precision Recall F1 Accuracy CO2\n(kg)\nBefore\nOptimization\nBaseline metrics for comparison\nLlama 3.2 0.55 0.45 0.44 0.45 0.012\nPhi 3.2 0.97 0.82 0.88 0.82 0.012\nQwen 0.77 0.79 0.76 0.79 0.009\nMistral-small 0.70 0.67 0.65 0.67 0.020\nLlava-Llama 3 0.58 0.50 0.48 0.50 0.014\nAfter\nOptimization\nMetrics following quantization and local\ninference techniques\nLlama 3.2 0.57 0.48 0.47 0.48 0.005\nPhi 3.2 1.00 0.84 0.91 0.84 0.007\nQwen 0.80 0.81 0.80 0.81 0.004\nMistral-small 0.73 0.70 0.69 0.70 0.015\nLlava-Llama 3 0.61 0.54 0.51 0.54 0.006\nB. Post-Quantization Performance Evaluation\nThe goal of this evaluation is to ensure that, after op-\ntimization, predictions remain consistent with ground truth\nlabels and reasoning aligns with the predicted labels. Two\nsubject matter experts assessed predictions based on con-\nsistency (alignment with ground truth), clarity (logical and\ninterpretable reasoning), and alignment (agreement between\npredicted sentiment and reasoning). Our results show that most\nlabels and reasoning align well with the model’s expectations.\nBelow, we present key examples in Figure. 3 .\nVI. D ISCUSSION\nA. Practical impact\nThe demonstrated reduction in carbon emissions through\noptimization techniques such as quantization and local infer-\nence holds significant value for industries aiming to enhance\nsustainability. With models achieving up to 45% reductions\nin energy consumption, this work directly aligns with corpo-\nrate environmental, social, and governance (ESG) goals by\nlowering operational costs and carbon footprints. These tech-\nniques enable the deployment of AI models on edge devices\nand in resource-constrained environments, expanding their\napplicability to sectors like IoT, healthcare, and autonomous\nsystems. Industries can leverage this work to build greener AI\nsolutions, reduce reliance on cloud computing, and improve\nreal-time processing capabilities, all while contributing to\nbroader sustainability initiatives.\nB. Limitations\nWhile the demonstrated optimization techniques such as\nquantization and local inference offer significant reductions in\ncarbon emissions and computational overhead, more work will\nbe needed in incorporating additional optimization techniques\nand evaluating performance across diverse datasets for further\ninvestigation, also they are not without limitations. A notable\ntrade-off is the potential loss of accuracy and predictive\nperformance. Metrics such as F1 score and overall accuracy\nmay decline slightly post-optimization, which could be critical\nfor applications requiring high precision, such as medical\ndiagnostics or financial modeling. This degradation can limit\nthe applicability of optimized models to tasks where even\nminor errors have significant consequences.\nFurthermore, the reliance on local inference can lead to\nslower performance if the underlying hardware is not suffi-\nciently powerful. Devices with limited processing capabilities\nmay experience delays in real-time applications, undermining\nthe efficiency gains achieved through optimization. Addition-\nally, while quantization reduces the size of models, it may\nintroduce numerical instability or rounding errors that could\naffect the robustness of the predictions, particularly in complex\nor highly dynamic environments. These limitations highlight\nthe need for careful evaluation of optimization techniques\nagainst the specific requirements of a given use case to ensure\nthat the trade-offs are acceptable. Future work will also explore\nablation studies to isolate confounding factors such as system-\nlevel effects like caching, dataset characteristics, and model\narchitecture.\nVII. C ONCLUSION\nThis paper highlights the critical need for sustainable AI\npractices, particularly in the deployment of LLMs. By inte-\ngrating optimization techniques such as quantization and local\ninference, we successfully demonstrated significant reductions\nin carbon emissions and energy consumption. The proposed\nframework provides a practical roadmap for industries and re-\nsearchers seeking to balance sustainability with effectiveness.\nFuture research should explore adaptive optimization strategies\nto minimize trade-offs and develop new metrics balancing\nsustainability with predictive performance. Additionally, ex-\npanding the framework to address challenges such as numer-\nical instability and task-specific performance degradation will\nenhance applicability across diverse domains.\nACKNOWLEDGMENT\nThe authors extend their gratitude to the Province of On-\ntario, the Government of Canada through CIFAR, and the\ncorporate sponsors of the Vector Institute for their gener-\nous support and provision of resources essential for this\nresearch. Further details on our sponsors can be found at\nwww.vectorinstitute.ai/# partners.", "sentences": [{"text": "and others showing slight declines.", "metadata": {}}, {"text": "For instance, precision\nand recall generally exhibit minor increases in specific cases,\nsuggesting that optimization can enhance certain aspects of\nthe models’ ability to correctly identify relevant patterns in the\ndata.", "metadata": {}}, {"text": "On the other hand, metrics like accuracy and F1 score are\nslightly lower after optimization, indicating a potential trade-\noff between energy efficiency and overall predictive perfor-\nmance.", "metadata": {}}, {"text": "This underscores the importance of carefully balancing\nsustainability and performance when applying optimization\ntechniques, as the ideal solution will depend on the specific\nuse case and application requirements.", "metadata": {}}, {"text": "TABLE III\nCOMPARISON OF PERFORMANCE METRICS AND CARBON EMISSIONS FOR\nFIVE LLM S BEFORE AND AFTER OPTIMIZATION .", "metadata": {}}, {"text": "CARBON EMISSIONS ARE\nCALCULATED PER INFERENCE TASK .", "metadata": {}}, {"text": "Model Name Precision Recall F1 Accuracy CO2\n(kg)\nBefore\nOptimization\nBaseline metrics for comparison\nLlama 3.2 0.55 0.45 0.44 0.45 0.012\nPhi 3.2 0.97 0.82 0.88 0.82 0.012\nQwen 0.77 0.79 0.76 0.79 0.009\nMistral-small 0.70 0.67 0.65 0.67 0.020\nLlava-Llama 3 0.58 0.50 0.48 0.50 0.014\nAfter\nOptimization\nMetrics following quantization and local\ninference techniques\nLlama 3.2 0.57 0.48 0.47 0.48 0.005\nPhi 3.2 1.00 0.84 0.91 0.84 0.007\nQwen 0.80 0.81 0.80 0.81 0.004\nMistral-small 0.73 0.70 0.69 0.70 0.015\nLlava-Llama 3 0.61 0.54 0.51 0.54 0.006\nB.", "metadata": {}}, {"text": "Post-Quantization Performance Evaluation\nThe goal of this evaluation is to ensure that, after op-\ntimization, predictions remain consistent with ground truth\nlabels and reasoning aligns with the predicted labels.", "metadata": {}}, {"text": "Two\nsubject matter experts assessed predictions based on con-\nsistency (alignment with ground truth), clarity (logical and\ninterpretable reasoning), and alignment (agreement between\npredicted sentiment and reasoning).", "metadata": {}}, {"text": "Our results show that most\nlabels and reasoning align well with the model’s expectations.", "metadata": {}}, {"text": "Below, we present key examples in Figure.", "metadata": {}}, {"text": "3 .", "metadata": {}}, {"text": "VI.", "metadata": {}}, {"text": "D ISCUSSION\nA.", "metadata": {}}, {"text": "Practical impact\nThe demonstrated reduction in carbon emissions through\noptimization techniques such as quantization and local infer-\nence holds significant value for industries aiming to enhance\nsustainability.", "metadata": {}}, {"text": "With models achieving up to 45% reductions\nin energy consumption, this work directly aligns with corpo-\nrate environmental, social, and governance (ESG) goals by\nlowering operational costs and carbon footprints.", "metadata": {}}, {"text": "These tech-\nniques enable the deployment of AI models on edge devices\nand in resource-constrained environments, expanding their\napplicability to sectors like IoT, healthcare, and autonomous\nsystems.", "metadata": {}}, {"text": "Industries can leverage this work to build greener AI\nsolutions, reduce reliance on cloud computing, and improve\nreal-time processing capabilities, all while contributing to\nbroader sustainability initiatives.", "metadata": {}}, {"text": "B.", "metadata": {}}, {"text": "Limitations\nWhile the demonstrated optimization techniques such as\nquantization and local inference offer significant reductions in\ncarbon emissions and computational overhead, more work will\nbe needed in incorporating additional optimization techniques\nand evaluating performance across diverse datasets for further\ninvestigation, also they are not without limitations.", "metadata": {}}, {"text": "A notable\ntrade-off is the potential loss of accuracy and predictive\nperformance.", "metadata": {}}, {"text": "Metrics such as F1 score and overall accuracy\nmay decline slightly post-optimization, which could be critical\nfor applications requiring high precision, such as medical\ndiagnostics or financial modeling.", "metadata": {}}, {"text": "This degradation can limit\nthe applicability of optimized models to tasks where even\nminor errors have significant consequences.", "metadata": {}}, {"text": "Furthermore, the reliance on local inference can lead to\nslower performance if the underlying hardware is not suffi-\nciently powerful.", "metadata": {}}, {"text": "Devices with limited processing capabilities\nmay experience delays in real-time applications, undermining\nthe efficiency gains achieved through optimization.", "metadata": {}}, {"text": "Addition-\nally, while quantization reduces the size of models, it may\nintroduce numerical instability or rounding errors that could\naffect the robustness of the predictions, particularly in complex\nor highly dynamic environments.", "metadata": {}}, {"text": "These limitations highlight\nthe need for careful evaluation of optimization techniques\nagainst the specific requirements of a given use case to ensure\nthat the trade-offs are acceptable.", "metadata": {}}, {"text": "Future work will also explore\nablation studies to isolate confounding factors such as system-\nlevel effects like caching, dataset characteristics, and model\narchitecture.", "metadata": {}}, {"text": "VII.", "metadata": {}}, {"text": "C ONCLUSION\nThis paper highlights the critical need for sustainable AI\npractices, particularly in the deployment of LLMs.", "metadata": {}}, {"text": "By inte-\ngrating optimization techniques such as quantization and local\ninference, we successfully demonstrated significant reductions\nin carbon emissions and energy consumption.", "metadata": {}}, {"text": "The proposed\nframework provides a practical roadmap for industries and re-\nsearchers seeking to balance sustainability with effectiveness.", "metadata": {}}, {"text": "Future research should explore adaptive optimization strategies\nto minimize trade-offs and develop new metrics balancing\nsustainability with predictive performance.", "metadata": {}}, {"text": "Additionally, ex-\npanding the framework to address challenges such as numer-\nical instability and task-specific performance degradation will\nenhance applicability across diverse domains.", "metadata": {}}, {"text": "ACKNOWLEDGMENT\nThe authors extend their gratitude to the Province of On-\ntario, the Government of Canada through CIFAR, and the\ncorporate sponsors of the Vector Institute for their gener-\nous support and provision of resources essential for this\nresearch.", "metadata": {}}, {"text": "Further details on our sponsors can be found at\nwww.vectorinstitute.ai/# partners.", "metadata": {}}], "metadata": {"page": 5}}], "metadata": {"page": 5}}, {"title": "Page 6", "paragraphs": [{"text": "Sentiment Evaluation\nText: $AAPL afternoon selloff as usual will be brutal. Get\nready to lose a ton of money.\nLabel: Negative Predicted: Negative\nReasoning: “afternoon selloff as usual will be brutal”, “get\nready to lose a ton of money” strongly negative sentiment.\nEvaluation: Consistent and correct; matches Negative sen-\ntiment with reasoning (e.g., “brutal” and financial loss).\nSentiment Evaluation\nText: Dealers said the share was hit by investor disappoint-\nment over a refining margin of 9.48 USD per barrel and\nshipping performance decline.\nLabel: Negative Predicted: Neutral\nReasoning: Negative: “disappointment” and declining EBIT\nsuggest negativity; Neutral: data tone is factual.\nEvaluation: Inconsistent prediction; factual tone doesn’t\nnegate “disappointment” and negative financial performance.\nSentiment Evaluation\nText: Recent deliveries include refinery technology to Anrak\nAluminium and sintering plants to Bhushan Steel.\nLabel: Neutral Predicted: Neutral\nReasoning: Purely factual information, no emotive or eval-\nuative language.\nEvaluation: Consistent and correct; neutral tone matches\nfactual details.\nSentiment Evaluation\nText: Cinema Series concludes with a profile of Finnish\ninventor Olavi Linden, whose work has led to dozens of\ndesign awards.\nLabel: Neutral Predicted: Positive\nReasoning: Positive: “dozens of design awards” implies\nachievement; Neutral: factual and descriptive tone; “con-\ncludes” is neutral.\nEvaluation: Inconsistent; factual tone suggests Neutral, de-\nspite positive implications of “awards.”\nFig. 3. Key Examples of Sentiment Analysis Experiments\nREFERENCES\n[1] Meta AI. Llama 3.2 model card, 2024. Accessed: 2024-09-25.\n[2] Enrico Barbierato and Alice Gatti. Towards green ai. a methodological\nsurvey of the scientific literature. IEEE Access, 2024.\n[3] Stefanie Betz, Birgit Penzenstadler, Leticia Duboc, Ruzanna Chitchyan,\nSedef Akinli Kocak, Ian Brooks, Shola Oyedeji, Jari Porras, Norbert\nSeyff, and Colin C Venters. Lessons learned from developing a sus-\ntainability awareness framework for software engineering using design\nscience. ACM Transactions on Software Engineering and Methodology ,\n33(5):1–39, 2024.\n[4] Ver ´onica Bol ´on-Canedo, Laura Mor ´an-Fern´andez, Brais Cancela, and\nAmparo Alonso-Betanzos. A review of green artificial intelligence:\nTowards a more sustainable future.Neurocomputing, page 128096, 2024.\n[5] Lingjiao Chen, Matei Zaharia, and James Zou. Frugalgpt: How to use\nlarge language models while reducing cost and improving performance.\narXiv preprint arXiv:2305.05176 , 2023.\n[6] Lingjiao Chen, Matei Zaharia, and James Y Zou. Frugalml: How to\nuse ml prediction apis more accurately and cheaply. Advances in neural\ninformation processing systems , 33:10685–10696, 2020.\n[7] Leticia Duboc, Stefanie Betz, Birgit Penzenstadler, Sedef Akinli Kocak,\nRuzanna Chitchyan, Ola Leifler, Jari Porras, Norbert Seyff, and Colin C\nVenters. Do we really know what we are building? raising awareness\nof potential sustainability effects of software systems in requirements\nengineering. In 2019 IEEE 27th international requirements engineering\nconference (RE), pages 6–16. IEEE, 2019.\n[8] Jinze Bai et al. Qwen technical report, 2023. Accessed: 2024-09-25.\n[9] Elias Frantar, Saleh Ashkboos, Torsten Hoefler, and Dan Alistarh.\nGptq: Accurate post-training quantization for generative pre-trained\ntransformers. arXiv preprint arXiv:2210.17323 , 2022.\n[10] Robin Geens, Man Shi, Arne Symons, Chao Fang, and Marian Verhelst.\nEnergy cost modelling for optimizing large language model inference on\nhardware accelerators. In 2024 IEEE 37th International System-on-Chip\nConference (SOCC), pages 1–6. IEEE, 2024.\n[11] Song Han, Huizi Mao, and William J Dally. Deep compression:\nCompressing deep neural networks with pruning, trained quantization\nand huffman coding. arXiv preprint arXiv:1510.00149 , 2015.\n[12] Kai Huang, Hanyun Yin, Heng Huang, and Wei Gao. Towards green\nai in fine-tuning large language models via adaptive backpropagation.\narXiv preprint arXiv:2309.13192 , 2023.\n[13] Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford,\nDevendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna\nLengyel, Guillaume Lample, Lucile Saulnier, L ´elio Renard Lavaud,\nMarie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril,\nThomas Wang, Timoth ´ee Lacroix, and William El Sayed. Mistral 7b,\n2023. Accessed: 2024-09-25.\n[14] Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee. Visual\ninstruction tuning, 2023. Accessed: 2024-09-25.\n[15] Vivian Liu and Yiqiao Yin. Green ai: exploring carbon footprints,\nmitigation strategies, and trade offs in large language model training.\nDiscover Artificial Intelligence, 4(1):49, 2024.\n[16] Zechun Liu, Barlas Oguz, Changsheng Zhao, Ernie Chang, Pierre Stock,\nYashar Mehdad, Yangyang Shi, Raghuraman Krishnamoorthi, and Vikas\nChandra. Llm-qat: Data-free quantization aware training for large\nlanguage models. arXiv preprint arXiv:2305.17888 , 2023.\n[17] Alexandra Sasha Luccioni, Sylvain Viguier, and Anne-Laure Ligozat.\nEstimating the carbon footprint of bloom, a 176b parameter language\nmodel. Journal of Machine Learning Research , 24(253):1–15, 2023.\n[18] Pekka Malo, Ankur Sinha, Pekka Korhonen, Jyrki Wallenius, and Pyry\nTakala. Good debt or bad debt: Detecting semantic orientations in\neconomic texts. Journal of the Association for Information Science and\nTechnology, 65(4):782–796, 2014.\n[19] Ollama Technologies. Ollama: Ai-powered insights for language models,\n2023. Accessed: [Access Date].\n[20] Shaina Raza, Oluwanifemi Bamgbose, Shardul Ghuge, Fatemeh\nTavakoli, and Deepak John Reji. Developing safe and responsible\nlarge language models–a comprehensive framework. arXiv preprint\narXiv:2404.01399, 2024.\n[21] Microsoft AI Research. Phi-3 technical report: A highly capable\nlanguage model locally on your phone, 2024. Accessed: 2024-09-25.\n[22] Shivanshu Shekhar, Tanishq Dubey, Koyel Mukherjee, Apoorv Saxena,\nAtharv Tyagi, and Nishanth Kotla. Towards optimizing the costs of llm\nusage. arXiv preprint arXiv:2402.01742 , 2024.\n[23] Jieke Shi, Zhou Yang, Hong Jin Kang, Bowen Xu, Junda He, and\nDavid Lo. Greening large language models of code. In Proceedings of\nthe 46th International Conference on Software Engineering: Software\nEngineering in Society , pages 142–153, 2024.\n[24] Jieke Shi, Zhou Yang, and David Lo. Efficient and green large language\nmodels for software engineering: Vision and the road ahead. ACM\nTransactions on Software Engineering and Methodology , 2024.\n[25] Abdulaziz Tabbakh, Lisan Al Amin, Mahbubul Islam, GM Iqbal Mah-\nmud, Imranul Kabir Chowdhury, and Md Saddam Hossain Mukta. To-\nwards sustainable ai: a comprehensive framework for green ai. Discover\nSustainability, 5(1):408, 2024.\n[26] Colin C Venters, Sedef Akinli Kocak, Stefanie Betz, Ian Brooks,\nRafael Capilla, Ruzanna Chitchyan, Let ´ıcia Duboc, Rogardt Heldal,\nAna Moreira, Shola Oyedeji, et al. Software sustainability: beyond the\ntower of babel. In 2021 IEEE/ACM International Workshop on Body of\nKnowledge for Software Sustainability (BoKSS), pages 3–4. IEEE, 2021.\n[27] Roberto Verdecchia, June Sallou, and Lu ´ıs Cruz. A systematic review of\ngreen ai. Wiley Interdisciplinary Reviews: Data Mining and Knowledge\nDiscovery, 13(4):e1507, 2023.", "sentences": [{"text": "Sentiment Evaluation\nText: $AAPL afternoon selloff as usual will be brutal.", "metadata": {}}, {"text": "Get\nready to lose a ton of money.", "metadata": {}}, {"text": "Label: Negative Predicted: Negative\nReasoning: “afternoon selloff as usual will be brutal”, “get\nready to lose a ton of money” strongly negative sentiment.", "metadata": {}}, {"text": "Evaluation: Consistent and correct;", "metadata": {}}, {"text": "matches Negative sen-\ntiment with reasoning (e.g., “brutal” and financial loss).", "metadata": {}}, {"text": "Sentiment Evaluation\nText: Dealers said the share was hit by investor disappoint-\nment over a refining margin of 9.48 USD per barrel and\nshipping performance decline.", "metadata": {}}, {"text": "Label: Negative Predicted: Neutral\nReasoning: Negative: “disappointment” and declining EBIT\nsuggest negativity;", "metadata": {}}, {"text": "Neutral: data tone is factual.", "metadata": {}}, {"text": "Evaluation: Inconsistent prediction;", "metadata": {}}, {"text": "factual tone doesn’t\nnegate “disappointment” and negative financial performance.", "metadata": {}}, {"text": "Sentiment Evaluation\nText: Recent deliveries include refinery technology to Anrak\nAluminium and sintering plants to Bhushan Steel.", "metadata": {}}, {"text": "Label: Neutral Predicted: Neutral\nReasoning: Purely factual information, no emotive or eval-\nuative language.", "metadata": {}}, {"text": "Evaluation: Consistent and correct;", "metadata": {}}, {"text": "neutral tone matches\nfactual details.", "metadata": {}}, {"text": "Sentiment Evaluation\nText: Cinema Series concludes with a profile of Finnish\ninventor Olavi Linden, whose work has led to dozens of\ndesign awards.", "metadata": {}}, {"text": "Label: Neutral Predicted: Positive\nReasoning: Positive: “dozens of design awards” implies\nachievement;", "metadata": {}}, {"text": "Neutral: factual and descriptive tone;", "metadata": {}}, {"text": "“con-\ncludes” is neutral.", "metadata": {}}, {"text": "Evaluation: Inconsistent;", "metadata": {}}, {"text": "factual tone suggests Neutral, de-\nspite positive implications of “awards.”\nFig.", "metadata": {}}, {"text": "3.", "metadata": {}}, {"text": "Key Examples of Sentiment Analysis Experiments\nREFERENCES\n[1] Meta AI.", "metadata": {}}, {"text": "Llama 3.2 model card, 2024.", "metadata": {}}, {"text": "Accessed: 2024-09-25.", "metadata": {}}, {"text": "[2] Enrico Barbierato and Alice Gatti.", "metadata": {}}, {"text": "Towards green ai.", "metadata": {}}, {"text": "a methodological\nsurvey of the scientific literature.", "metadata": {}}, {"text": "IEEE Access, 2024.", "metadata": {}}, {"text": "[3] Stefanie Betz, Birgit Penzenstadler, Leticia Duboc, Ruzanna Chitchyan,\nSedef Akinli Kocak, Ian Brooks, Shola Oyedeji, Jari Porras, Norbert\nSeyff, and Colin C Venters.", "metadata": {}}, {"text": "Lessons learned from developing a sus-\ntainability awareness framework for software engineering using design\nscience.", "metadata": {}}, {"text": "ACM Transactions on Software Engineering and Methodology ,\n33(5):1–39, 2024.", "metadata": {}}, {"text": "[4] Ver ´onica Bol ´on-Canedo, Laura Mor ´an-Fern´andez, Brais Cancela, and\nAmparo Alonso-Betanzos.", "metadata": {}}, {"text": "A review of green artificial intelligence:\nTowards a more sustainable future.Neurocomputing, page 128096, 2024.", "metadata": {}}, {"text": "[5] Lingjiao Chen, Matei Zaharia, and James Zou.", "metadata": {}}, {"text": "Frugalgpt: How to use\nlarge language models while reducing cost and improving performance.", "metadata": {}}, {"text": "arXiv preprint arXiv:2305.05176 , 2023.", "metadata": {}}, {"text": "[6] Lingjiao Chen, Matei Zaharia, and James Y Zou.", "metadata": {}}, {"text": "Frugalml: How to\nuse ml prediction apis more accurately and cheaply.", "metadata": {}}, {"text": "Advances in neural\ninformation processing systems , 33:10685–10696, 2020.", "metadata": {}}, {"text": "[7] Leticia Duboc, Stefanie Betz, Birgit Penzenstadler, Sedef Akinli Kocak,\nRuzanna Chitchyan, Ola Leifler, Jari Porras, Norbert Seyff, and Colin C\nVenters.", "metadata": {}}, {"text": "Do we really know what we are building?", "metadata": {}}, {"text": "raising awareness\nof potential sustainability effects of software systems in requirements\nengineering.", "metadata": {}}, {"text": "In 2019 IEEE 27th international requirements engineering\nconference (RE), pages 6–16.", "metadata": {}}, {"text": "IEEE, 2019.", "metadata": {}}, {"text": "[8] Jinze Bai et al.", "metadata": {}}, {"text": "Qwen technical report, 2023.", "metadata": {}}, {"text": "Accessed: 2024-09-25.", "metadata": {}}, {"text": "[9] Elias Frantar, Saleh Ashkboos, Torsten Hoefler, and Dan Alistarh.", "metadata": {}}, {"text": "Gptq: Accurate post-training quantization for generative pre-trained\ntransformers.", "metadata": {}}, {"text": "arXiv preprint arXiv:2210.17323 , 2022.", "metadata": {}}, {"text": "[10] Robin Geens, Man Shi, Arne Symons, Chao Fang, and Marian Verhelst.", "metadata": {}}, {"text": "Energy cost modelling for optimizing large language model inference on\nhardware accelerators.", "metadata": {}}, {"text": "In 2024 IEEE 37th International System-on-Chip\nConference (SOCC), pages 1–6.", "metadata": {}}, {"text": "IEEE, 2024.", "metadata": {}}, {"text": "[11] Song Han, Huizi Mao, and William J Dally.", "metadata": {}}, {"text": "Deep compression:\nCompressing deep neural networks with pruning, trained quantization\nand huffman coding.", "metadata": {}}, {"text": "arXiv preprint arXiv:1510.00149 , 2015.", "metadata": {}}, {"text": "[12] Kai Huang, Hanyun Yin, Heng Huang, and Wei Gao.", "metadata": {}}, {"text": "Towards green\nai in fine-tuning large language models via adaptive backpropagation.", "metadata": {}}, {"text": "arXiv preprint arXiv:2309.13192 , 2023.", "metadata": {}}, {"text": "[13] Albert Q.", "metadata": {}}, {"text": "Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford,\nDevendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna\nLengyel, Guillaume Lample, Lucile Saulnier, L ´elio Renard Lavaud,\nMarie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril,\nThomas Wang, Timoth ´ee Lacroix, and William El Sayed.", "metadata": {}}, {"text": "Mistral 7b,\n2023.", "metadata": {}}, {"text": "Accessed: 2024-09-25.", "metadata": {}}, {"text": "[14] Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee.", "metadata": {}}, {"text": "Visual\ninstruction tuning, 2023.", "metadata": {}}, {"text": "Accessed: 2024-09-25.", "metadata": {}}, {"text": "[15] Vivian Liu and Yiqiao Yin.", "metadata": {}}, {"text": "Green ai: exploring carbon footprints,\nmitigation strategies, and trade offs in large language model training.", "metadata": {}}, {"text": "Discover Artificial Intelligence, 4(1):49, 2024.", "metadata": {}}, {"text": "[16] Zechun Liu, Barlas Oguz, Changsheng Zhao, Ernie Chang, Pierre Stock,\nYashar Mehdad, Yangyang Shi, Raghuraman Krishnamoorthi, and Vikas\nChandra.", "metadata": {}}, {"text": "Llm-qat: Data-free quantization aware training for large\nlanguage models.", "metadata": {}}, {"text": "arXiv preprint arXiv:2305.17888 , 2023.", "metadata": {}}, {"text": "[17] Alexandra Sasha Luccioni, Sylvain Viguier, and Anne-Laure Ligozat.", "metadata": {}}, {"text": "Estimating the carbon footprint of bloom, a 176b parameter language\nmodel.", "metadata": {}}, {"text": "Journal of Machine Learning Research , 24(253):1–15, 2023.", "metadata": {}}, {"text": "[18] Pekka Malo, Ankur Sinha, Pekka Korhonen, Jyrki Wallenius, and Pyry\nTakala.", "metadata": {}}, {"text": "Good debt or bad debt: Detecting semantic orientations in\neconomic texts.", "metadata": {}}, {"text": "Journal of the Association for Information Science and\nTechnology, 65(4):782–796, 2014.", "metadata": {}}, {"text": "[19] Ollama Technologies.", "metadata": {}}, {"text": "Ollama: Ai-powered insights for language models,\n2023.", "metadata": {}}, {"text": "Accessed: [Access Date].", "metadata": {}}, {"text": "[20] Shaina Raza, Oluwanifemi Bamgbose, Shardul Ghuge, Fatemeh\nTavakoli, and Deepak John Reji.", "metadata": {}}, {"text": "Developing safe and responsible\nlarge language models–a comprehensive framework.", "metadata": {}}, {"text": "arXiv preprint\narXiv:2404.01399, 2024.", "metadata": {}}, {"text": "[21] Microsoft AI Research.", "metadata": {}}, {"text": "Phi-3 technical report: A highly capable\nlanguage model locally on your phone, 2024.", "metadata": {}}, {"text": "Accessed: 2024-09-25.", "metadata": {}}, {"text": "[22] Shivanshu Shekhar, Tanishq Dubey, Koyel Mukherjee, Apoorv Saxena,\nAtharv Tyagi, and Nishanth Kotla.", "metadata": {}}, {"text": "Towards optimizing the costs of llm\nusage.", "metadata": {}}, {"text": "arXiv preprint arXiv:2402.01742 , 2024.", "metadata": {}}, {"text": "[23] Jieke Shi, Zhou Yang, Hong Jin Kang, Bowen Xu, Junda He, and\nDavid Lo.", "metadata": {}}, {"text": "Greening large language models of code.", "metadata": {}}, {"text": "In Proceedings of\nthe 46th International Conference on Software Engineering: Software\nEngineering in Society , pages 142–153, 2024.", "metadata": {}}, {"text": "[24] Jieke Shi, Zhou Yang, and David Lo.", "metadata": {}}, {"text": "Efficient and green large language\nmodels for software engineering: Vision and the road ahead.", "metadata": {}}, {"text": "ACM\nTransactions on Software Engineering and Methodology , 2024.", "metadata": {}}, {"text": "[25] Abdulaziz Tabbakh, Lisan Al Amin, Mahbubul Islam, GM Iqbal Mah-\nmud, Imranul Kabir Chowdhury, and Md Saddam Hossain Mukta.", "metadata": {}}, {"text": "To-\nwards sustainable ai: a comprehensive framework for green ai.", "metadata": {}}, {"text": "Discover\nSustainability, 5(1):408, 2024.", "metadata": {}}, {"text": "[26] Colin C Venters, Sedef Akinli Kocak, Stefanie Betz, Ian Brooks,\nRafael Capilla, Ruzanna Chitchyan, Let ´ıcia Duboc, Rogardt Heldal,\nAna Moreira, Shola Oyedeji, et al.", "metadata": {}}, {"text": "Software sustainability: beyond the\ntower of babel.", "metadata": {}}, {"text": "In 2021 IEEE/ACM International Workshop on Body of\nKnowledge for Software Sustainability (BoKSS), pages 3–4.", "metadata": {}}, {"text": "IEEE, 2021.", "metadata": {}}, {"text": "[27] Roberto Verdecchia, June Sallou, and Lu ´ıs Cruz.", "metadata": {}}, {"text": "A systematic review of\ngreen ai.", "metadata": {}}, {"text": "Wiley Interdisciplinary Reviews: Data Mining and Knowledge\nDiscovery, 13(4):e1507, 2023.", "metadata": {}}], "metadata": {"page": 6}}], "metadata": {"page": 6}}]}