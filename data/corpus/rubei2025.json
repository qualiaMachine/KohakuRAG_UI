{"document_id": "rubei2025", "title": "Prompt engineering and its implications on the energy consumption of Large Language Models", "text": "Prompt engineering and its implications on the\nenergy consumption of Large Language Models\nRiccardo Rubei\nUniversity of L’Aquila\nL’Aquila, Italy\nriccardo.rubei@univaq.it\nAicha Moussaid\nUniversity of L’Aquila\nL’Aquila, Italy\naicha.moussaid@student.univaq.it\nClaudio Di Sipio\nUniversity of L’Aquila\nL’Aquila, Italy\nclaudio.disipio@univaq.it\nDavide Di Ruscio\nUniversity of L’Aquila\nL’Aquila, Italy\ndavide.diruscio@univaq.it\nAbstract—Reducing the environmental impact of AI-based\nsoftware systems has become critical. The intensive use of large\nlanguage models (LLMs) in software engineering poses severe\nchallenges regarding computational resources, data centers, and\ncarbon emissions. In this paper, we investigate how prompt\nengineering techniques (PETs) can impact the carbon emission of\nthe Llama 3 model for the code generation task. We experimented\nwith the CodeXGLUE benchmark to evaluate both energy\nconsumption and the accuracy of the generated code using an\nisolated testing environment. Our initial results show that the\nenergy consumption of LLMs can be reduced by using specific\ntags that distinguish different prompt parts. Even though a\nmore in-depth evaluation is needed to confirm our findings, this\nwork suggests that prompt engineering can reduce LLMs’ energy\nconsumption during the inference phase without compromising\nperformance, paving the way for further investigations.\nIndex Terms —LLMs, Generative AI, Prompt Engineering,\nEnergy Consumption.\nI. I NTRODUCTION\nThe environmental impact of software systems has been\na growing concern in recent years [1], [2], thus fostering\nthe development of green software engineering (GSE) [3] by\nproposing dedicated methodologies [4], frameworks [5], [6],\nand guidelines [7]. Nevertheless, the rise of AI-intensive sys-\ntems has posed new challenges regarding energy consumption\nand carbon emissions [8].\nIn particular, both training and querying large language\nmodels (LLMs) to outperform traditional techniques in code-\nrelated tasks [9]–[11] is computationally expensive and re-\nquires large amounts of resources and has a significant carbon\nfootprint [12]. Moreover, assessing them is challenging due\nto i) higher variability in the generated code and ii) the\nlack of standardized guidelines and information for measur-\ning carbon emissions even in dedicated model repositories\n[12]. While a plethora of approaches have been proposed to\nmeasure the impact on the hardware [13], we focus on the\nusage of prompt engineering techniques (PETs) to mitigate\nthe energy consumption of LLMs during the inference phase\nwhile supporting the code completion task. By relying on\nthe CodeXGLUE [14] dataset, we first devise a dedicated\ncomponent that selects and tests different prompts on Llama\n3 [15] to assess their impact on the energy consumption using\nthe CodeCarbon tool [16]. Concretely, we used traditional\nPETs as baselines and devise four additional configurations\nusing additional tags and explanations to enhance the baseline\nprompts. In particular, we aim to answer the following research\nquestions:\n➢ RQ1: To what extent does the usage of custom tags\nin prompts improve the energy efficiency of Llama 3 while\nperforming code completion tasks? We explore the effects of\nspecifically introduced custom tags on the energy consump-\ntion of LLMs during the inference phase to support code\ncompletion tasks. To this end, we first calculate the energy\nconsumption of three well-known PETs, i.e., zero-shot, one-\nshot, and few-shots, without any modifications. Afterward, we\ncompare these baseline prompts with an enhanced version\nusing additional tags that we introduced to help the inference\nphase of the model. In addition, we also measure the overall\ntime required to perform the assigned task.\n➢ RQ2: How do custom tags influence predictive accuracy of\nLlama 3 while performing code completion tasks? We aim\nto analyze the impact of custom tags on the performance\nof Llama 3, focusing on well-established accuracy metrics,\ni.e., exact matches and edit distance. We chose to use these\nmetrics because they have been successfully applied in the\nCodeXGLUE benchmark and are recognized as effective tools\nfor evaluating code completion when using LLMs [17].\nOur findings reveal that the energy consumption of LLMs\nfor the inference phase can be reduced by using the introduced\ncustom tags. Moreover, we show that the energy consumption\nof LLMs is highly dependent on the used PETs. Although\nfurther experimentation involving additional tasks and LLMs\nis needed, the presented work suggests that prompt engineering\ncan play a key role in reducing the energy consumption of\nLLMs without compromising their performance.\nThe main contributions of this work are as follows:\n• We investigate the effects of several prompt engineering\ntechniques and custom tags on the energy consumption\nof LLMs while performing code completion tasks;\n• Our research examines the trade-offs between energy\nconsumption in terms of carbon emission, execution time,\nand generated code accuracy to investigate the balance\nbetween energy efficiency and model accuracy;\n• We provide a replication package 1 to foster further re-\nsearch on the topic.\n1https://github.com/riccardoRubei/Greens-2025-Replication-Package\narXiv:2501.05899v1  [cs.SE]  10 Jan 2025\n\nFig. 1: Carbon emissions of GPT-3 models as reported in [18].\nII. B ACKGROUND\nWhile measuring traditional software impact in terms of\nemissions is well-established [1], [7], assessing LLMs con-\nsumption is still challenging, as High-Performance Computing\n(HPC) clusters are often required to run the training process,\nwhich can last for weeks or even months. Therefore, measuring\nthe energy consumption in terms of carbon emissions is\nparticularly challenging in those environments due to several\nfactors, e.g., parallel jobs or the non-exclusive use of the\ncluster.\nMoreover, even well-maintained LLMs leaderboard bench-\nmarks [19]–[21] do not report energy consumption, focusing\ninstead on accuracy metrics. Figure 1 shows the carbon\nemissions of the GPT-3 model in different server regions for\nthree big IT players, i.e., Google, Amazon, and Microsoft. For\ninstance, some models emit carbon that is equivalent to the\naverage of five cars over their lifetimes [22], thus underlining\nsignificant sustainability concerns, especially when consider-\ning the growing scope of LLM-based implementations and\ntheir integration into everyday life. This highlights the need\nto reduce the carbon footprint of LLMs and to examine the\ndetails that contribute to the reported figures.\nTo address the environmental impact of software, a range of\nenergy monitoring tools [5], [6] has been recently developed to\nmeasure the carbon emissions associated with code execution.\nAmong these, the CodeCarbon tool [16] is a widely adopted\nPython library that estimates the energy consumption of code\nexecutions. It can also calculate the carbon footprint by\nmeasuring the electricity power consumption of the underlying\nhardware architecture, i.e., GPU, CPU, and RAM. In addition,\nit can estimate the carbon intensity of the region where\nthe computing is done. This study focuses on the energy\nconsumption related to GPU usage without considering the\ncarbon emission.\nConcerning the inference phase of LLMs, prompt engineer-\ning is pivotal to enhancing LLMs’ generation capabilities. The\nmost basic PET is zero-shot, in which the LLM is given a\nquery without any example of outputs, which are expected\nfrom the given inputs [23]. In contrast, one-shot prompting\nprovides the model with a single example, offering a minimal\ncontext to guide responses. The few-shots prompting [24]\ninvolves multiple examples, allowing the model to generalize\nmore effectively with limited supervision [25]. In the scope of\nthis paper, we focus on different shot techniques i.e., zero-shot,\none-shot, and few-shots given their efficiency and success in\nimproving the performance of LLMs in source code-related\ntasks.\nQuantization [26] is a technique that reduces the compu-\ntational and memory requirements of LLMs by lowering the\nprecision of their numerical representations (e.g., from 32-bit\nto 8-bit). This compression speeds up inference, making LLMs\nmore efficient with minimal impact on accuracy. In this paper,\nwe leverage quantization alongside PETs to minimize the\ncomputational cost while maintaining performance in code-\nrelated tasks.\nWhile developing a comprehensive methodology for mea-\nsuring LLM energy consumption is beyond this paper’s scope,\nwe focus on reducing these emissions through efficient PETs.\nBy utilizing custom tags, we aim to lower energy consumption\nin LLMs used for code-related tasks, offering an approach that\nbalances sustainability with performance.\n\n[Image page=2 idx=1 name=Im0.png] Size: 2048x1025, Data: 691912 bytes\n\nCodeXGlueDataset\n1\nLlama 3PET Selector Prompt Augmenter\n2 3\n 4\nCode Carbon \nEnergy Measurer\n5\nMonitors\nLLM Answers\nEnergy Measurements\n6\n7\nPrompt Creator\nProduces\nGeneratesSnippets PET Query\nFig. 2: Workflow of the performed experiments.\nIII. P ERFORMED EXPERIMENTS\nFigure 2 depicts the workflow of the experiments we per-\nformed to answer the two research questions. Starting from the\nCodeXGLUE dataset [14] 1 , prompt creator 2 translates\ninput prompts into a format that Llama 3 can understand,\nbefore augmenting them with tags that we specifically in-\ntroduced 3 . Afterward, the crafted prompts are used to\nquery the LLM locally deployed 4 . For each snippet, we\nexecuted 75 queries.2 Each Llama run is monitored 5 by the\nCodeCarbon energy monitoring tool. For each execution, we\nstore three artifacts (question, answer 6 , and measurement\n7 ), to enable both efficiency and accuracy analysis.\nA. Dataset\nAmong different benchmarks, we select CodeXGLUE as it\nis tailored for supporting and evaluating LLMs in code-related\ntasks [27], [28]. In this paper, we consider the code completion\ntask as it is widely supported by LLMs as recently investigated\n[29], [30]. This task leverages established evaluation method-\nologies in the literature, enabling straightforward comparisons\nwith ground truth data.\nB. Prompt Creator\nThis component is responsible for defining and augmenting\nprompts that have been used to query the model under analysis.\nIn particular, we use standard PETs, i.e., zero-shot, one-shot,\nand few-shots, as a baseline to evaluate the effect of custom\ntags in terms of energy impact. The Llama 3 model card 3\ndefines several tokens which form the model’s input. We aim to\ninvestigate the impact of custom tags on energy consumption\nand performance metrics for Llama 3. To this end, we define\nfive distinct prompt configurations. Each prompt comprises\ntwo key components: a role attribute and content speci-\nfication, as illustrated in Listing 1. The role attribute can be\nassigned as either system or user. In the case of system,\nthe accompanying content attribute specifies the task to be\n2Three prompting techniques (i.e., zero-shot, one-shot, and few-shots) ×\nfive prompt configurations × five repetitions to mitigate possible energy\nmeasurement inaccuracies.\n3www.llama.com/docs/model-cards-and-prompt-formats/meta-llama-3/\nperformed, thus clarifying the expected contribution from the\nmodel. For example, in Listing 1, the system role is configured\nto instruct the model on a code completion task for given code\nfragments. The user role, on the other hand, introduces the\ninput code snippet that the model is expected to complete.\nAccording to the different configurations, the content can\nbe enhanced with custom tags or explanations related to the\ntask. The configurations are defined as follows:\nC0 - default : We define the model’s role and provide the\nincomplete snippet without any customization. In the case of\none-shot and few-shots, we describe one and five examples,\nrespectively. We fix the number of examples equal to five for\nthe few-shots technique since it obtains adequate accuracy with\nlimited token size [31]. Nonetheless, we acknowledge that\na deep study concerning the different shot sizes is needed.\nListing 1 depicts an example of prompt in its default repre-\nsentation.\nListing 1: Example of a zero-shot prompt.\n1{\n2\"role\": \"system\",\n3\"content\" : \"You are an AI assistant\nspecialized in code completion for Java.\nYour task is to complete the provided Java\ncode segment with one line. Give only the\ncode completion.\",\n4},{\n5\"role\": \"user\",\n6\"content\": \"package com.lmax.disruptor.support\n; import java.util.concurrent.\nThreadFactory; public final\"\n7}\nC1 - use of custom tags without explanation : We augment\nprompts by using custom tags i.e., <code> and <incomplete>\nto support the inference phase to distinguish the input source\ncode, and the fragment that needs to be completed. We do not\nprovide any explanation of what is the meaning of such custom\ntags. Therefore, we aim to explore the LLM’s capability to\nunderstand the customization. Listing 2 is an example of a\ncode fragment augmented with custom tags.\n\n[Image page=3 idx=1 name=X11.png] Size: 500x500, Data: 16883 bytes\n\n[Image page=3 idx=2 name=X8.png] Size: 200x200, Data: 18037 bytes\n\nListing 2: Fragment of a prompt including custom tags.\n1 {\n2 \"role\": \"user\",\n3 \"content\" :\"<code> package com.lmax.disruptor.\nsupport; import java.util.concurrent.\nThreadFactory; </code> <incomplete> public\nfinal </incomplete>\"\n4 }\nC2 - use of custom tags with explanation : We embed the\nmeaning of the custom tags in the prompt as shown in\nListing 3.\nListing 3: Fragment of a prompt including custom tags expla-\nnation.\n1 {\n2 \"role\": \"user\",\n3 \"content\" :\"The code to analyze is marked by\nthe <code> tag and the line to be\ncompleted is marked by the <incomplete>\ntag. <code> package com.lmax.disruptor.\nsupport; import java.util.concurrent.\nThreadFactory;</code><incomplete> public\nfinal </incomplete>\"\n4 }\nC3 - custom prompt explained in the system : Differently from\nconfiguration C2, the explanation of custom tags is given in\nthe system role part of the input prompt as shown in Listing\n4.\nListing 4: Example of a zero-shot prompt including the defi-\nnition of custom tags.\n1 {\n2 \"role\": \"system\",\n3 \"content\" : \"You are an AI assistant\nspecialized in code completion for Java.\nYour task is to complete the provided Java\ncode segment with one line. Give only the\ncode completion. The code to analyze is\nmarked by the <code> tag and the line to\nbe completed is marked by the <incomplete>\ntag.\",\n4 },{\n5 \"role\": \"user\",\n6 \"content\": \"<code> package com.lmax.disruptor.\nsupport; import java.util.concurrent.\nThreadFactory;</code><incomplete> public\nfinal </incomplete>\"\n7 }\nC4 - no system definition : With this configuration, we want to\nassess the effect of the complete absence of the system role\ndefinition. Therefore, we provide only the incomplete input\nsnippet and a task definition directly in the prompt without\nany customization as illustrated in Listing 5.\nListing 5: Fragment of a prompt including custom tags.\n1{\n2\"role\": \"system\",\n3\"content\" : \"\",\n4},{\n5\"role\": \"user\",\n6\"content\" :\"Hi, complete the following snippet\nadding one line please: package com.lmax.\ndisruptor.support; import java.util.\nconcurrent.ThreadFactory; public final\"\n7}\nThe process ends with the generation of three different arti-\nfacts, i.e., questions, answers, and measurements. A question\nis a copy of the query given to the LLM and it is stored\nfor subsequent analysis. The measurement is the outcome of\nthe Llama 3 process monitored by CodeCarbon to solve the\ncode completion task. Meanwhile, an answer is just a sequence\nof Java statements to complete the input snippet. In some\ncases, the LLM answer is verbose. Therefore, we can notice\na sequence of several lines of code.\nC. Metrics\nConcerning the metrics, we rely on CodeCarbon predefined\nformat4 to avoid any bias in the comparison. Since our study\nfocuses on the energy effects on the GPU, we rely on the\ngpu energy value to support the evaluation.\nDuring our investigation, we evaluate the effects of prompt-\ning techniques and customization of the prompts. Therefore,\nwe employ the following metrics:\n➤ Energy Consumption: This metric quantifies the energy\nconsumed during the inference phase of Llama excluding the\nmodel loading. We rely on the calculation provided by Code-\nCarbon. In its report, we focus on the value of gpu energy\nwhich calculates the energy consumed during in the inference,\nexpressed in kWh. To reduce biases related to unprecise mon-\nitoring, we repeated the tests 5 times, calculating eventually\nthe average.\n➤ Execution Time: The execution time calculates the du-\nration needed by Llama 3 to perform the inference. The\nmonitoring is limited only on the inference phase, excluding\nthe model loading time. The time is excerpted from the\nCodeCarbon report similarly for the energy value.\n➤ Edit Distance: The edit distance metric calculates how\nsimilar the proposed answer is to the ground truth, by counting\nthe number of characters that need to be substituted, inserted,\nor deleted to transform an input string into a target one. We\nused the nltk edit distance, which implements the well-known\nLevenshtein Distance [32].\n➤ Exact Match The exact match metric measures whether\nthe answer of the LLM has an edit distance of 0, meaning\nthat the ground truth and answer are the same. Since LLMs\nare generally verbose, we fixed the exact match threshold to\nedit distance less or equal to 2. The rationale is that Llama\nproduces the results by adding several random characters\nto the answer, e.g. extra spaces, single and double quotes,\nsemicolons.\nD. Execution process\nThe experiments have been performed by considering the\nsettings shown in Table I. In particular, we tested 1,000 random\n4https://mlco2.github.io/codecarbon/output.html\n\nTABLE I: Summary of the Experimental Settings\nModel Llama3 8B - Instruct\nSnippets 1,000\nPETs 3\nCustom Prompts 5\nRepetitions 5\nPause 10 seconds\nMetrics (Performance) Energy Consumption, Execution Time\nMetrics (Accuracy) Exact Match, Edit Distance\nincomplete Java snippets retrieved from the code-completion\ndataset of CodeXGLUE. As discussed in Section IV the overall\nexecution requires more than 250 hours. We calculated an\naverage test time per snippet of about 900 seconds. Therefore,\nwe limit ourselves to 1,000 snippets. with the abovementioned\nPETs\nAs discussed in Section III-B, we defined five distinct\nconfigurations for each query. Consequently, we tested every\ncombination of prompting techniques and the use of custom\ntags. To ensure experimental reliability, each test is repeated\nfive times [33], [34], with a ten-second pause between each test\nto mitigate potential tail effects [34], [35]. We use two metrics\nto evaluate energy consumption and execution time, and two\nprimary metrics (exact match and edit distance) to assess the\nimpact of different configurations on accuracy. These metrics\nalign with those used in the original evaluation of the code\ncompletion benchmark suite by the authors of CodeXGLUE.\nAll the experiments have been conducted on an isolated\ndesktop equipped with an AMD Ryzen 7 5800X 3.8GHz CPU\nand an Nvidia Geforce RTX 4060 TI (8 GB VRAM). 5 The\noperating system is Xubuntu 23.04. Since the GPU provided\nonly 8GB of RAM, we used the quantized version of the\nLlama model i.e., we used 16-bit float rather than the default\n32-bit.\nIV. E XPERIMENTAL RESULTS\nAnswering RQ1: Figure 3a shows the energy consumption\nof the three prompt techniques applied to the five different\nconfigurations. In particular, with the default configuration C0,\nzero-shot is the most energy-efficient, with an average cost of\nabout 0.000016 kWh. one-shot and a few-shots consumed an\naverage of 0.000035 kWh and 0.000054 kWh, respectively.\nCustom tags can contribute to reducing the energy consump-\ntion of the video card. As shown in Fig. 3a, the best config-\nuration is the C2 (explanation in prompts). While the zero-\nshot technique passed from 0.0000157 (of C0) to 0.0000146\n(-7%), one-shot and few-shots reduced the consumption from\n0.0000347 to 0.0000174 (-99%) and from 0.0000537 to\n0.0000293 (-83%) comparing with the default configuration\nC0, respectively. It is also interesting to see the results of C4,\nin which we do not specify any role in the system token. The\nconsumption increased from 0.0000157 to 0.000189 kWh for\nzero-shot and from 0.0000347 to 0.000181 kWh for one-shot.\n5https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4060-\n4060ti/\nThe reason is that the model started to generate completely\nnew code snippets when asked to finalize the code given as\ninput. The few-shots technique seems to be less affected by\nthis problem. The sequence of example questions and answers\ninstructed the model on the behaviour despite the lack of the\nsystem role specification.\nConcerning the execution time, Figure 3b reports the results\nobtained for all the prompt configurations. Similar to energy\nconsumption, the usage of custom tags provides a general\nimprovement in performance. In particular, the one-shot and\nfew-shots reduced the average time from 1.54 seconds of\nconfiguration C0 to 0.74 (-52%) and from 2.1 to 1.09 (-48%),\nrespectively, using configuration C2. The zero-shot technique\nperformed better using C1, reporting an improvement from\n0.74 seconds to 0.63 (-14.8%). Similarly, for the energy\nconsumption, in the case of C4, we can notice a remarkable\nincrease in execution time for zero-shot and one-shot.\nAnswer to RQ 1: Our study reveals that custom tags\ncan reduce the energy consumption of LLMs across the\nthree prompt engineering techniques tested for source\ncode completion tasks.\nAnswering RQ2: Figure 4 depicts the obtained results in\nterms of accuracy metrics. In particular, Figure 4a shows the\neffects of custom tags on exact match performance across\ndifferent prompt engineering techniques. Overall, we observe\nan increase in exact matches for configuration C1-C3 in com-\nparison with the default configuration C0. Notably, zero-shot\nshows the greatest improvement with C1, where exact matches\nrise from 63 to 82, reflecting a 23% increase. Both one-\nshot and few-shots see substantial gains with C3, achieving\napproximately a 44% improvement. Interestingly, with C4,\nzero-shot fails to achieve any exact matches.\nFigure 4b shows the impact of custom tags on edit distance\nmetrics, where an edit distance of 0 indicates a perfect result.\nOverall, custom tags contributed to a reduction in edit distance,\nwith C2 emerging as the most effective configuration across all\nprompt engineering techniques. Specifically, zero-shot showed\na 24% improvement, one-shot achieved a 64% reduction, and\nfew-shots improved by 70%. Results for zero-shot and one-\nshot are omitted for C4 because, with this configuration,\nthe LLM produced uncontrolled responses. As a result, it\nwas impossible to calculate edit distance accurately, as the\noutputs included both code and explanatory text. Despite\nlacking explicit role definitions, few-shots continued to yield\nsatisfactory results.\nAnswer to RQ 2: Prompt customizations enhanced\nthe accuracy of the tested PETs, showing a positive\ntrend with increased exact matches and reduced edit\ndistances.\n\nC0 C1 C2 C3 C4\n0.000000\n0.000025\n0.000050\n0.000075\n0.000100\n0.000125\n0.000150\n0.000175Energy Consumption (KWh)\nPET\nZeroShot\nOneShot\nFewShot\n(a) Energy Consumption in (kWh).\nC0 C1 C2 C3 C4\n0\n2\n4\n6\n8Execution Time (seconds)\nPET\nZeroShot\nOneShot\nFewShot (b) Execution Time.\nFig. 3: Energy consumption with different prompt configurations.\nC0 C1 C2 C3 C4\n0\n20\n40\n60\n80\n100\n120\n140Exatch Match Absolute Number\nPET\nZeroShot\nOneShot\nFewShot\n(a) Exact Match.\nC0 C1 C2 C3 C4\n0\n20\n40\n60\n80\n100\n120Edit Distance\nPET\nZeroShot\nOneShot\nFewShot (b) Edit Distance.\nFig. 4: LLMs accuracy with different prompt configurations.\nV. R ELATED WORK\nAssessing LLMs energy consumption: Jagannadharao et al.\n[36] investigate the usage of time-shifting technique to reduce\nthe energy consumption of LLMs during long-running training\nsessions. Concretely, the authors estimates the consumption\nof Llama model by pausing and resuming the training when\nthe carbon emission is below a certain threshold. The results\nshows that the proposed approach succeed in reducing the\ncarbon emission even though the region may impact the ob-\ntained results. Liu and Yin [37] investigate how to reduce and\nmeasure the consumption of pre-trained models by combining\nfine-tuning and efficient tokenizers. In particular, BERT, Distil-\nBERT, and T5 models are compared using SQuAD benchmark\n[38] in terms of accuracy and carbon emissions. The experi-\nmental results reveal that both the T5 and BERT models emit-\nted considerably more CO2 compared to DistilBERT and the\nT4 GPU contributes in reducing the overall carbon emissions.\nSamsi et al. [13] compare the inference performance in terms\nof watts of different Llama models, i.e., evaluating smaller\nmodels (7B, 13B) against the largest available version (65B) at\nthe time of writing. In addition, the authors consider different\nGPUs, i.e., V100 and A100. The study reveals that 8 V100\nGPUs each with 32 GB of RAM or 4 A100 GPUs each with\n80GB of memory are required for any meaningful inferences\nwith the 65B LLaMA model, thus making small models a\nsuitable choice for energy-efficient applications. Cursaro et al.\n\n[39] conduct a controlled experiment in which code generated\nby CodeLlama is compared with the human one considering\ndifferent languages, i.e., C++, Java, and Python, tested on a\ndedicated platform. The results show that explicitly asking to\ngenerate energy-efficient code results in an equal or worse\nenergy efficiency. In our work, we focus on reducing energy\nconsumption of Llama by customizing the prompt and using\na dedicated GPU.\nPrompt customization: Fagadau et al. [40] explored the\ninfluence of eight prompt features on Copilot’s code outputs,\nanalyzing 124,800 prompts designed to implement 200 Java\nmethods. The findings indicate that prompts including concise\nmethod summaries and examples lead to higher accuracy in\ngenerated code while additional details as boundary cases\nhave a negative impact. Reynolds and McDonell [41] ex-\nplored example-free strategies in prompt engineering, aiming\nto enhance results by refining prompt structure. In particular,\nthey embody analogies and synonyms during task specifica-\ntion and limit undesired outputs with negative prompting. Li\net al. [42] investigate prompt modifications using metamorphic\ntesting. Using Copilot as baseline model, code fragments are\ninjected in the prompts instead of natural language. Then,\nsemantic mutations are introducted to modify the prompts.\nSimilar to our approach, Wang et al. [28] proposes prompt\ntuning, a novel PET executed during the fine-tuning process.\nThis technique involves the soft prompting in which task-\nrelated knowledge are tagged using virtual tokens instead of\nusing fixed annotation, i.e., hard prompting . The empirical\nevaluation conducted on CodeBERT and CodeT5 shows that\nprompt tuning consistently outperforms fine-tuning in three\ncode-related tasks, i.e., defect prediction, code summarization,\nand code translation. Compared to those works, we introduce\nexplanations in prompts to reduce the energy consumption of\nLlama 3 model in code generation task.\nVI. T HREATS TO VALIDITY\nThis section discusses threats that may hamper the results\nof our study and corresponding mitigation strategies.\nInternal validity concerns factors that may impact the\nmeasurements, i.e., noise interference, background processes,\nand voltage fluctuations. To mitigate these issues, all the\nexperiments have been conducted in an isolated Linux-based\nsystem without parallel or background tasks running on the\nGPU. In addition, we repeated each experiment five times and\na 10-second pause between each query execution to prevent\npotential performance degradation and statistical anomalies,\nthus increasing the reliability of measurements.\nThreats to external validity are related to the generalizability\nof the performed experiments, i.e., the obtained results in terms\nof energy consumption and accuracy may vary considering\ndifferent tasks and LLMs. Concerning the data, we employed\nCodeXGLUE, a well-known dataset exploited in several stud-\nies. We were forced to cap our dataset to 1,000 snippets, since\nthe time needed to test one snippet has been evaluated to 900\nseconds. Finally, the measurements calculated on the inference\nwithout any customization are strictly related to the particular\ntask that we decided to study, thus code generation or text\nsummarization might require different energy resources. We\nmitigated this threat focusing on the effects of the customiza-\ntion.\nVII. C ONCLUSION AND FUTURE WORK\nMotivated by the increasing carbon emissions of LLMs, we\nproposed a preliminary investigation on the effects of prompt\ncustomizations on Llama 3 model for the specific task of code\ncompletion. Our results show that augmenting prompts with\ndedicated custom tags and explanations succeed in reducing\nthe energy consumption yet preserving adequate accuracy.\nIn particular, with the best configuration, zero-shot reduced\nthe consumption of about 7%, whereas one-shot and few-\nshots decreased their consumption of about 99% and 83%,\nrespectively. For future work, we plan to extend the study\nto additional LLMs and code-related tasks. In addition, we\nwill investigate advanced techniques, e.g., retrieval augmented\ngeneration (RAG) or fine-tuning, to further reduce the carbon\nemissions of LLMs. Finally, we plan to investigate the effects\nof custom prompts in different software engineering tasks.\nACKNOWLEDGMENTS\nThis work has been partially supported by the EMELIOT\nnational research project, which has been funded by the MUR\nunder the PRIN 2020 program grant n. 2020W3A5FY , the\nEuropean Union–NextGenerationEU through the Italian Min-\nistry of University and Research, Projects PRIN 2022 PNRR\n“FRINGE: context-aware FaiRness engineerING in complex\nsoftware systEms” grant n. P2022553SL, and the Italian\n“PRIN 2022” project “TRex-SE: Trustworthy Recommenders\nfor Software Engineers, ” grant n. 2022LKJWHC.\nREFERENCES\n[1] R. Verdecchia, P. Lago, C. Ebert et al., “Green it and green software,”\nIEEE Software, vol. 38, no. 6, pp. 7–15, 2021.\n[2] S. Georgiou, M. Kechagia, and D. Spinellis, “Analyzing programming\nlanguages’ energy consumption: An empirical study,” in Proceedings of\nthe 21st Pan-Hellenic Conference on Informatics , 2017, pp. 1–6.\n[3] C. Calero and M. Piattini, Eds., Green in Software Engineering .\nCham: Springer International Publishing, 2015. [Online]. Available:\nhttps://link.springer.com/10.1007/978-3-319-08581-4\n[4] A. Guldner, R. Bender, C. Calero et al. , “Development and evaluation\nof a reference measurement model for assessing the resource\nand energy efficiency of software products and components—green\nsoftware measurement model (gsmm),” Future Generation Computer\nSystems, vol. 155, pp. 402–418, 2024. [Online]. Available: https:\n//www.sciencedirect.com/science/article/pii/S0167739X24000384\n[5] PowerAPI, “pyrapl: A python library for measuring energy\nconsumption,” 2023, accessed: 2024-03-05. [Online]. Available:\nhttps://github.com/powerapi-ng/pyRAPL/tree/master\n[6] A. Noureddine, “Powerjoular and joularjx: Multi-platform software\npower monitoring tools,” in 18th International Conference on Intelligent\nEnvironments (IE2022), Biarritz, France, Jun 2022.\n[7] J. Mancebo, C. Calero, F. Garcia et al. , “Feetings: Framework\nfor energy efficiency testing to improve environmental goal of the\nsoftware,” Sustainable Computing: Informatics and Systems , vol. 30,\np. 100558, 2021. [Online]. Available: https://www.sciencedirect.com/\nscience/article/pii/S2210537921000494\n[8] E. Strubell, A. Ganesh, and A. McCallum, “Energy and policy\nconsiderations for modern deep learning research,” Proceedings of\nthe AAAI Conference on Artificial Intelligence , vol. 34, no. 09,\npp. 13 693–13 696, Apr. 2020. [Online]. Available: https://ojs.aaai.org/\nindex.php/AAAI/article/view/7123\n\n[9] R. Tufano, S. Masiero, A. Mastropaolo et al. , “Using pre-trained\nmodels to boost code review automation,” in Proceedings of\nthe 44th International Conference on Software Engineering , ser.\nICSE ’22. New York, NY , USA: Association for Computing\nMachinery, Jul. 2022, pp. 2291–2302. [Online]. Available: https:\n//dl.acm.org/doi/10.1145/3510003.3510621\n[10] A. Mastropaolo, S. Scalabrino, N. Cooper et al. , “Studying the\nUsage of Text-To-Text Transfer Transformer to Support Code-Related\nTasks,” in 2021 IEEE/ACM 43rd International Conference on Software\nEngineering (ICSE) . Madrid, ES: IEEE, May 2021, pp. 336–347.\n[Online]. Available: https://ieeexplore.ieee.org/document/9401982/\n[11] D. Wang, Z. Jia, S. Li et al. , “Bridging pre-trained models and\ndownstream tasks for source code understanding,” in Proceedings\nof the 44th International Conference on Software Engineering , ser.\nICSE ’22. New York, NY , USA: Association for Computing\nMachinery, Jul. 2022, pp. 287–298. [Online]. Available: https:\n//dl.acm.org/doi/10.1145/3510003.3510062\n[12] J. Casta ˜no, S. Mart ´ınez-Fern´andez, X. Franch et al. , “Exploring\nthe Carbon Footprint of Hugging Face’s ML Models: A Repository\nMining Study,” in 2023 ACM/IEEE International Symposium on\nEmpirical Software Engineering and Measurement (ESEM) , Oct.\n2023, pp. 1–12, arXiv:2305.11164 [cs, stat]. [Online]. Available:\nhttp://arxiv.org/abs/2305.11164\n[13] S. Samsi, D. Zhao, J. McDonald, B. Li, A. Michaleas, M. Jones,\nW. Bergeron, J. Kepner, D. Tiwari, and V . Gadepally, “From words\nto watts: Benchmarking the energy costs of large language model\ninference,” in IEEE High Performance Extreme Computing Conference,\nHPEC 2023, Boston, MA, USA, September 25-29, 2023 . IEEE, 2023,\npp. 1–9. [Online]. Available: https://doi.org/10.1109/HPEC58863.2023.\n10363447\n[14] S. Lu, D. Guo, S. Ren, J. Huang, A. Svyatkovskiy, A. Blanco,\nC. Clement, D. Drain, D. Jiang, D. Tang et al., “Codexglue: A machine\nlearning benchmark dataset for code understanding and generation,”\nin Thirty-fifth Conference on Neural Information Processing Systems\nDatasets and Benchmarks Track (Round 1) .\n[15] A. Dubey, A. Jauhri, A. Pandey et al. , “The llama 3 herd of models,”\n2024. [Online]. Available: https://arxiv.org/abs/2407.21783\n[16] M. C. Impact, “Codecarbon: A tool to estimate the carbon emissions\nof machine learning models,” 2024, accessed: 2024-03-05. [Online].\nAvailable: https://mlco2.github.io/codecarbon/\n[17] R. A. Husein, H. Aburajouh, and C. Catal, “Large language\nmodels for code completion: A systematic literature review,” Comput.\nStand. Interfaces , vol. 92, p. 103917, 2025. [Online]. Available:\nhttps://doi.org/10.1016/j.csi.2024.103917\n[18] S. T. Footprint, “Carbon footprint of training gpt-\n3 and large language models,” 2023, accessed:\n2024-07-22. [Online]. Available: https://shrinkthatfootprint.com/\ncarbon-footprint-of-training-gpt-3-and-large-language-models/\n[19] Trustbit, “Llm benchmarks,” 2024, accessed: 2024-07-22. [Online].\nAvailable: https://www.trustbit.tech/en/llm-benchmarks\n[20] L. Arena, “Lm arena leaderboard,” 2024, accessed: 2024-07-22.\n[Online]. Available: https://lmarena.ai/?leaderboard\n[21] Oobabooga, “Oobabooga benchmark,” 2024, accessed: 2024-07-22.\n[Online]. Available: https://oobabooga.github.io/benchmark.html\n[22] E. Strubell, A. Ganesh, and A. McCallum, “Energy and policy\nconsiderations for deep learning in nlp,” 2019. [Online]. Available:\nhttps://arxiv.org/abs/1906.02243\n[23] B. Romera-Paredes and P. H. S. Torr, “An embarrassingly simple\napproach to zero-shot learning,” inProceedings of the 32nd International\nConference on International Conference on Machine Learning - Volume\n37, ser. ICML’15. JMLR.org, 2015, p. 2152–2161.\n[24] R. L. L. I. au2, I. Bala ˇzevi´c, E. Wallace, F. Petroni, S. Singh,\nand S. Riedel, “Cutting down on prompts and parameters: Simple\nfew-shot learning with language models,” 2021. [Online]. Available:\nhttps://arxiv.org/abs/2106.13353\n[25] X. Li, S. Yuan, X. Gu et al. , “Few-shot code translation via\ntask-adapted prompt learning,” Journal of Systems and Software , vol.\n212, p. 112002, 2024. [Online]. Available: https://www.sciencedirect.\ncom/science/article/pii/S0164121224000451\n[26] A. Gholami, S. Kim, Z. Dong, Z. Yao, M. W. Mahoney, and K. Keutzer,\n“A survey of quantization methods for efficient neural network\ninference,” 2021. [Online]. Available: https://arxiv.org/abs/2103.13630\n[27] A. Faiz, S. Kaneda, R. Wang, R. Osi, P. Sharma, F. Chen, and L. Jiang,\n“Llmcarbon: Modeling the end-to-end carbon footprint of large language\nmodels,” arXiv preprint arXiv:2309.14393 , 2023.\n[28] C. Wang, Y . Yang, C. Gao, Y . Peng, H. Zhang, and M. R. Lyu,\n“No more fine-tuning? an experimental evaluation of prompt tuning in\ncode intelligence,” in Proceedings of the 30th ACM Joint European\nSoftware Engineering Conference and Symposium on the Foundations\nof Software Engineering , ser. ESEC/FSE 2022. New York, NY , USA:\nAssociation for Computing Machinery, 2022, p. 382–394. [Online].\nAvailable: https://doi.org/10.1145/3540250.3549113\n[29] X. Hou, Y . Zhao, Y . Liu, Z. Yang, K. Wang, L. Li, X. Luo,\nD. Lo, J. Grundy, and H. Wang, “Large language models for\nsoftware engineering: A systematic literature review,” ACM Trans.\nSoftw. Eng. Methodol. , Sep. 2024, just Accepted. [Online]. Available:\nhttps://doi.org/10.1145/3695988\n[30] C. Di Sipio, R. Rubei, J. Di Rocco, D. Di Ruscio, and P. T.\nNguyen, “Automated categorization of pre-trained models in software\nengineering: A case study with a hugging face dataset,” in Proceedings\nof the 28th International Conference on Evaluation and Assessment\nin Software Engineering , ser. EASE ’24. New York, NY , USA:\nAssociation for Computing Machinery, 2024, p. 351–356. [Online].\nAvailable: https://doi.org/10.1145/3661167.3661215\n[31] T. Ahmed and P. Devanbu, “Few-shot training llms for project-\nspecific code-summarization,” in Proceedings of the 37th IEEE/ACM\nInternational Conference on Automated Software Engineering , ser. ASE\n’22. New York, NY , USA: Association for Computing Machinery,\n2023. [Online]. Available: https://doi.org/10.1145/3551349.3559555\n[32] G. Navarro, “A guided tour to approximate string matching,” ACM\nComputing Surveys, vol. 33, no. 1, pp. 31–88, 2001.\n[33] S. Georgiou, M. Kechagia, T. Sharma, F. Sarro, and Y . Zou, “Green\nai: Do deep learning frameworks have different costs?” in Proceedings\nof the 44th International Conference on Software Engineering ,\nser. ICSE ’22, Springer. New York, NY , USA: Association for\nComputing Machinery, 2022, p. 1082–1094. [Online]. Available:\nhttps://doi.org/10.1145/3510003.3510221\n[34] S. Shanbhag and S. Chimalakonda, “An exploratory study on energy\nconsumption of dataframe processing libraries,” in 2023 IEEE/ACM\n20th International Conference on Mining Software Repositories (MSR) .\nSpringer, 2023, pp. 284–295.\n[35] J. Bornholt, T. Mytkowicz, and K. S. McKinley, “The model is not\nenough: Understanding energy consumption in mobile devices,” in 2012\nIEEE Hot Chips 24 Symposium (HCS) . IEEE, 2012, pp. 1–3.\n[36] A. Jagannadharao, N. Beckage, D. Nafus, and S. Chamberlin,\n“Timeshifting strategies for carbon-efficient long-running large language\nmodel training,” Innovations in Systems and Software Engineering, Dec.\n2023. [Online]. Available: https://doi.org/10.1007/s11334-023-00546-x\n[37] V . Liu and Y . Yin, “Green AI: exploring carbon footprints, mitigation\nstrategies, and trade offs in large language model training,” Discover\nArtificial Intelligence, vol. 4, no. 1, p. 49, Jul. 2024. [Online]. Available:\nhttps://doi.org/10.1007/s44163-024-00149-w\n[38] P. Rajpurkar, J. Zhang, K. Lopyrev et al., “Squad: 100,000+ questions\nfor machine comprehension of text,” arXiv preprint arXiv:1606.05250 ,\n2016.\n[39] V .-A. Cursaru, L. Duits, J. Milligan, D. Ural, B. R. Sanchez, V . Stoico,\nand I. Malavolta, “A controlled experiment on the energy efficiency\nof the source code generated by code llama,” in Quality of Information\nand Communications Technology, A. Bertolino, J. Pascoal Faria, P. Lago,\nand L. Semini, Eds. Cham: Springer Nature Switzerland, 2024, pp.\n161–176.\n[40] I. D. Fagadau, L. Mariani, D. Micucci, and O. Riganelli, “Analyzing\nprompt influence on automated method generation: An empirical study\nwith copilot,” in Proceedings of the 32nd IEEE/ACM International\nConference on Program Comprehension , ser. ICPC ’24. New York,\nNY , USA: Association for Computing Machinery, 2024, p. 24–34.\n[Online]. Available: https://doi.org/10.1145/3643916.3644409\n[41] L. Reynolds and K. McDonell, “Prompt programming for large\nlanguage models: Beyond the few-shot paradigm,” in Extended\nAbstracts of the 2021 CHI Conference on Human Factors in\nComputing Systems , ser. CHI EA ’21. New York, NY , USA:\nAssociation for Computing Machinery, 2021. [Online]. Available:\nhttps://doi.org/10.1145/3411763.3451760\n[42] Z. Li, C. Wang, Z. Liu, H. Wang, D. Chen, S. Wang, and C. Gao,\n“Cctest: Testing and repairing code completion systems,” 2023.\n[Online]. Available: https://arxiv.org/abs/2208.08289", "metadata": {"url": "https://arxiv.org/pdf/2501.05899", "type": "paper", "year": "2025"}, "sections": [{"title": "Page 1", "paragraphs": [{"text": "Prompt engineering and its implications on the\nenergy consumption of Large Language Models\nRiccardo Rubei\nUniversity of L’Aquila\nL’Aquila, Italy\nriccardo.rubei@univaq.it\nAicha Moussaid\nUniversity of L’Aquila\nL’Aquila, Italy\naicha.moussaid@student.univaq.it\nClaudio Di Sipio\nUniversity of L’Aquila\nL’Aquila, Italy\nclaudio.disipio@univaq.it\nDavide Di Ruscio\nUniversity of L’Aquila\nL’Aquila, Italy\ndavide.diruscio@univaq.it\nAbstract—Reducing the environmental impact of AI-based\nsoftware systems has become critical. The intensive use of large\nlanguage models (LLMs) in software engineering poses severe\nchallenges regarding computational resources, data centers, and\ncarbon emissions. In this paper, we investigate how prompt\nengineering techniques (PETs) can impact the carbon emission of\nthe Llama 3 model for the code generation task. We experimented\nwith the CodeXGLUE benchmark to evaluate both energy\nconsumption and the accuracy of the generated code using an\nisolated testing environment. Our initial results show that the\nenergy consumption of LLMs can be reduced by using specific\ntags that distinguish different prompt parts. Even though a\nmore in-depth evaluation is needed to confirm our findings, this\nwork suggests that prompt engineering can reduce LLMs’ energy\nconsumption during the inference phase without compromising\nperformance, paving the way for further investigations.\nIndex Terms —LLMs, Generative AI, Prompt Engineering,\nEnergy Consumption.\nI. I NTRODUCTION\nThe environmental impact of software systems has been\na growing concern in recent years [1], [2], thus fostering\nthe development of green software engineering (GSE) [3] by\nproposing dedicated methodologies [4], frameworks [5], [6],\nand guidelines [7]. Nevertheless, the rise of AI-intensive sys-\ntems has posed new challenges regarding energy consumption\nand carbon emissions [8].\nIn particular, both training and querying large language\nmodels (LLMs) to outperform traditional techniques in code-\nrelated tasks [9]–[11] is computationally expensive and re-\nquires large amounts of resources and has a significant carbon\nfootprint [12]. Moreover, assessing them is challenging due\nto i) higher variability in the generated code and ii) the\nlack of standardized guidelines and information for measur-\ning carbon emissions even in dedicated model repositories\n[12]. While a plethora of approaches have been proposed to\nmeasure the impact on the hardware [13], we focus on the\nusage of prompt engineering techniques (PETs) to mitigate\nthe energy consumption of LLMs during the inference phase\nwhile supporting the code completion task. By relying on\nthe CodeXGLUE [14] dataset, we first devise a dedicated\ncomponent that selects and tests different prompts on Llama\n3 [15] to assess their impact on the energy consumption using\nthe CodeCarbon tool [16]. Concretely, we used traditional\nPETs as baselines and devise four additional configurations\nusing additional tags and explanations to enhance the baseline\nprompts. In particular, we aim to answer the following research\nquestions:\n➢ RQ1: To what extent does the usage of custom tags\nin prompts improve the energy efficiency of Llama 3 while\nperforming code completion tasks? We explore the effects of\nspecifically introduced custom tags on the energy consump-\ntion of LLMs during the inference phase to support code\ncompletion tasks. To this end, we first calculate the energy\nconsumption of three well-known PETs, i.e., zero-shot, one-\nshot, and few-shots, without any modifications. Afterward, we\ncompare these baseline prompts with an enhanced version\nusing additional tags that we introduced to help the inference\nphase of the model. In addition, we also measure the overall\ntime required to perform the assigned task.\n➢ RQ2: How do custom tags influence predictive accuracy of\nLlama 3 while performing code completion tasks? We aim\nto analyze the impact of custom tags on the performance\nof Llama 3, focusing on well-established accuracy metrics,\ni.e., exact matches and edit distance. We chose to use these\nmetrics because they have been successfully applied in the\nCodeXGLUE benchmark and are recognized as effective tools\nfor evaluating code completion when using LLMs [17].\nOur findings reveal that the energy consumption of LLMs\nfor the inference phase can be reduced by using the introduced\ncustom tags. Moreover, we show that the energy consumption\nof LLMs is highly dependent on the used PETs. Although\nfurther experimentation involving additional tasks and LLMs\nis needed, the presented work suggests that prompt engineering\ncan play a key role in reducing the energy consumption of\nLLMs without compromising their performance.\nThe main contributions of this work are as follows:\n• We investigate the effects of several prompt engineering\ntechniques and custom tags on the energy consumption\nof LLMs while performing code completion tasks;\n• Our research examines the trade-offs between energy\nconsumption in terms of carbon emission, execution time,\nand generated code accuracy to investigate the balance\nbetween energy efficiency and model accuracy;\n• We provide a replication package 1 to foster further re-\nsearch on the topic.\n1https://github.com/riccardoRubei/Greens-2025-Replication-Package\narXiv:2501.05899v1  [cs.SE]  10 Jan 2025", "sentences": [{"text": "Prompt engineering and its implications on the\nenergy consumption of Large Language Models\nRiccardo Rubei\nUniversity of L’Aquila\nL’Aquila, Italy\nriccardo.rubei@univaq.it\nAicha Moussaid\nUniversity of L’Aquila\nL’Aquila, Italy\naicha.moussaid@student.univaq.it\nClaudio Di Sipio\nUniversity of L’Aquila\nL’Aquila, Italy\nclaudio.disipio@univaq.it\nDavide Di Ruscio\nUniversity of L’Aquila\nL’Aquila, Italy\ndavide.diruscio@univaq.it\nAbstract—Reducing the environmental impact of AI-based\nsoftware systems has become critical.", "metadata": {}}, {"text": "The intensive use of large\nlanguage models (LLMs) in software engineering poses severe\nchallenges regarding computational resources, data centers, and\ncarbon emissions.", "metadata": {}}, {"text": "In this paper, we investigate how prompt\nengineering techniques (PETs) can impact the carbon emission of\nthe Llama 3 model for the code generation task.", "metadata": {}}, {"text": "We experimented\nwith the CodeXGLUE benchmark to evaluate both energy\nconsumption and the accuracy of the generated code using an\nisolated testing environment.", "metadata": {}}, {"text": "Our initial results show that the\nenergy consumption of LLMs can be reduced by using specific\ntags that distinguish different prompt parts.", "metadata": {}}, {"text": "Even though a\nmore in-depth evaluation is needed to confirm our findings, this\nwork suggests that prompt engineering can reduce LLMs’ energy\nconsumption during the inference phase without compromising\nperformance, paving the way for further investigations.", "metadata": {}}, {"text": "Index Terms —LLMs, Generative AI, Prompt Engineering,\nEnergy Consumption.", "metadata": {}}, {"text": "I.", "metadata": {}}, {"text": "I NTRODUCTION\nThe environmental impact of software systems has been\na growing concern in recent years [1], [2], thus fostering\nthe development of green software engineering (GSE) [3] by\nproposing dedicated methodologies [4], frameworks [5], [6],\nand guidelines [7].", "metadata": {}}, {"text": "Nevertheless, the rise of AI-intensive sys-\ntems has posed new challenges regarding energy consumption\nand carbon emissions [8].", "metadata": {}}, {"text": "In particular, both training and querying large language\nmodels (LLMs) to outperform traditional techniques in code-\nrelated tasks [9]–[11] is computationally expensive and re-\nquires large amounts of resources and has a significant carbon\nfootprint [12].", "metadata": {}}, {"text": "Moreover, assessing them is challenging due\nto i) higher variability in the generated code and ii) the\nlack of standardized guidelines and information for measur-\ning carbon emissions even in dedicated model repositories\n[12].", "metadata": {}}, {"text": "While a plethora of approaches have been proposed to\nmeasure the impact on the hardware [13], we focus on the\nusage of prompt engineering techniques (PETs) to mitigate\nthe energy consumption of LLMs during the inference phase\nwhile supporting the code completion task.", "metadata": {}}, {"text": "By relying on\nthe CodeXGLUE [14] dataset, we first devise a dedicated\ncomponent that selects and tests different prompts on Llama\n3 [15] to assess their impact on the energy consumption using\nthe CodeCarbon tool [16].", "metadata": {}}, {"text": "Concretely, we used traditional\nPETs as baselines and devise four additional configurations\nusing additional tags and explanations to enhance the baseline\nprompts.", "metadata": {}}, {"text": "In particular, we aim to answer the following research\nquestions:\n➢ RQ1: To what extent does the usage of custom tags\nin prompts improve the energy efficiency of Llama 3 while\nperforming code completion tasks?", "metadata": {}}, {"text": "We explore the effects of\nspecifically introduced custom tags on the energy consump-\ntion of LLMs during the inference phase to support code\ncompletion tasks.", "metadata": {}}, {"text": "To this end, we first calculate the energy\nconsumption of three well-known PETs, i.e., zero-shot, one-\nshot, and few-shots, without any modifications.", "metadata": {}}, {"text": "Afterward, we\ncompare these baseline prompts with an enhanced version\nusing additional tags that we introduced to help the inference\nphase of the model.", "metadata": {}}, {"text": "In addition, we also measure the overall\ntime required to perform the assigned task.", "metadata": {}}, {"text": "➢ RQ2: How do custom tags influence predictive accuracy of\nLlama 3 while performing code completion tasks?", "metadata": {}}, {"text": "We aim\nto analyze the impact of custom tags on the performance\nof Llama 3, focusing on well-established accuracy metrics,\ni.e., exact matches and edit distance.", "metadata": {}}, {"text": "We chose to use these\nmetrics because they have been successfully applied in the\nCodeXGLUE benchmark and are recognized as effective tools\nfor evaluating code completion when using LLMs [17].", "metadata": {}}, {"text": "Our findings reveal that the energy consumption of LLMs\nfor the inference phase can be reduced by using the introduced\ncustom tags.", "metadata": {}}, {"text": "Moreover, we show that the energy consumption\nof LLMs is highly dependent on the used PETs.", "metadata": {}}, {"text": "Although\nfurther experimentation involving additional tasks and LLMs\nis needed, the presented work suggests that prompt engineering\ncan play a key role in reducing the energy consumption of\nLLMs without compromising their performance.", "metadata": {}}, {"text": "The main contributions of this work are as follows:\n• We investigate the effects of several prompt engineering\ntechniques and custom tags on the energy consumption\nof LLMs while performing code completion tasks;", "metadata": {}}, {"text": "• Our research examines the trade-offs between energy\nconsumption in terms of carbon emission, execution time,\nand generated code accuracy to investigate the balance\nbetween energy efficiency and model accuracy;", "metadata": {}}, {"text": "• We provide a replication package 1 to foster further re-\nsearch on the topic.", "metadata": {}}, {"text": "1https://github.com/riccardoRubei/Greens-2025-Replication-Package\narXiv:2501.05899v1  [cs.SE]  10 Jan 2025", "metadata": {}}], "metadata": {"page": 1}}], "metadata": {"page": 1}}, {"title": "Page 2", "paragraphs": [{"text": "Fig. 1: Carbon emissions of GPT-3 models as reported in [18].\nII. B ACKGROUND\nWhile measuring traditional software impact in terms of\nemissions is well-established [1], [7], assessing LLMs con-\nsumption is still challenging, as High-Performance Computing\n(HPC) clusters are often required to run the training process,\nwhich can last for weeks or even months. Therefore, measuring\nthe energy consumption in terms of carbon emissions is\nparticularly challenging in those environments due to several\nfactors, e.g., parallel jobs or the non-exclusive use of the\ncluster.\nMoreover, even well-maintained LLMs leaderboard bench-\nmarks [19]–[21] do not report energy consumption, focusing\ninstead on accuracy metrics. Figure 1 shows the carbon\nemissions of the GPT-3 model in different server regions for\nthree big IT players, i.e., Google, Amazon, and Microsoft. For\ninstance, some models emit carbon that is equivalent to the\naverage of five cars over their lifetimes [22], thus underlining\nsignificant sustainability concerns, especially when consider-\ning the growing scope of LLM-based implementations and\ntheir integration into everyday life. This highlights the need\nto reduce the carbon footprint of LLMs and to examine the\ndetails that contribute to the reported figures.\nTo address the environmental impact of software, a range of\nenergy monitoring tools [5], [6] has been recently developed to\nmeasure the carbon emissions associated with code execution.\nAmong these, the CodeCarbon tool [16] is a widely adopted\nPython library that estimates the energy consumption of code\nexecutions. It can also calculate the carbon footprint by\nmeasuring the electricity power consumption of the underlying\nhardware architecture, i.e., GPU, CPU, and RAM. In addition,\nit can estimate the carbon intensity of the region where\nthe computing is done. This study focuses on the energy\nconsumption related to GPU usage without considering the\ncarbon emission.\nConcerning the inference phase of LLMs, prompt engineer-\ning is pivotal to enhancing LLMs’ generation capabilities. The\nmost basic PET is zero-shot, in which the LLM is given a\nquery without any example of outputs, which are expected\nfrom the given inputs [23]. In contrast, one-shot prompting\nprovides the model with a single example, offering a minimal\ncontext to guide responses. The few-shots prompting [24]\ninvolves multiple examples, allowing the model to generalize\nmore effectively with limited supervision [25]. In the scope of\nthis paper, we focus on different shot techniques i.e., zero-shot,\none-shot, and few-shots given their efficiency and success in\nimproving the performance of LLMs in source code-related\ntasks.\nQuantization [26] is a technique that reduces the compu-\ntational and memory requirements of LLMs by lowering the\nprecision of their numerical representations (e.g., from 32-bit\nto 8-bit). This compression speeds up inference, making LLMs\nmore efficient with minimal impact on accuracy. In this paper,\nwe leverage quantization alongside PETs to minimize the\ncomputational cost while maintaining performance in code-\nrelated tasks.\nWhile developing a comprehensive methodology for mea-\nsuring LLM energy consumption is beyond this paper’s scope,\nwe focus on reducing these emissions through efficient PETs.\nBy utilizing custom tags, we aim to lower energy consumption\nin LLMs used for code-related tasks, offering an approach that\nbalances sustainability with performance.", "sentences": [{"text": "Fig.", "metadata": {}}, {"text": "1: Carbon emissions of GPT-3 models as reported in [18].", "metadata": {}}, {"text": "II.", "metadata": {}}, {"text": "B ACKGROUND\nWhile measuring traditional software impact in terms of\nemissions is well-established [1], [7], assessing LLMs con-\nsumption is still challenging, as High-Performance Computing\n(HPC) clusters are often required to run the training process,\nwhich can last for weeks or even months.", "metadata": {}}, {"text": "Therefore, measuring\nthe energy consumption in terms of carbon emissions is\nparticularly challenging in those environments due to several\nfactors, e.g., parallel jobs or the non-exclusive use of the\ncluster.", "metadata": {}}, {"text": "Moreover, even well-maintained LLMs leaderboard bench-\nmarks [19]–[21] do not report energy consumption, focusing\ninstead on accuracy metrics.", "metadata": {}}, {"text": "Figure 1 shows the carbon\nemissions of the GPT-3 model in different server regions for\nthree big IT players, i.e., Google, Amazon, and Microsoft.", "metadata": {}}, {"text": "For\ninstance, some models emit carbon that is equivalent to the\naverage of five cars over their lifetimes [22], thus underlining\nsignificant sustainability concerns, especially when consider-\ning the growing scope of LLM-based implementations and\ntheir integration into everyday life.", "metadata": {}}, {"text": "This highlights the need\nto reduce the carbon footprint of LLMs and to examine the\ndetails that contribute to the reported figures.", "metadata": {}}, {"text": "To address the environmental impact of software, a range of\nenergy monitoring tools [5], [6] has been recently developed to\nmeasure the carbon emissions associated with code execution.", "metadata": {}}, {"text": "Among these, the CodeCarbon tool [16] is a widely adopted\nPython library that estimates the energy consumption of code\nexecutions.", "metadata": {}}, {"text": "It can also calculate the carbon footprint by\nmeasuring the electricity power consumption of the underlying\nhardware architecture, i.e., GPU, CPU, and RAM.", "metadata": {}}, {"text": "In addition,\nit can estimate the carbon intensity of the region where\nthe computing is done.", "metadata": {}}, {"text": "This study focuses on the energy\nconsumption related to GPU usage without considering the\ncarbon emission.", "metadata": {}}, {"text": "Concerning the inference phase of LLMs, prompt engineer-\ning is pivotal to enhancing LLMs’ generation capabilities.", "metadata": {}}, {"text": "The\nmost basic PET is zero-shot, in which the LLM is given a\nquery without any example of outputs, which are expected\nfrom the given inputs [23].", "metadata": {}}, {"text": "In contrast, one-shot prompting\nprovides the model with a single example, offering a minimal\ncontext to guide responses.", "metadata": {}}, {"text": "The few-shots prompting [24]\ninvolves multiple examples, allowing the model to generalize\nmore effectively with limited supervision [25].", "metadata": {}}, {"text": "In the scope of\nthis paper, we focus on different shot techniques i.e., zero-shot,\none-shot, and few-shots given their efficiency and success in\nimproving the performance of LLMs in source code-related\ntasks.", "metadata": {}}, {"text": "Quantization [26] is a technique that reduces the compu-\ntational and memory requirements of LLMs by lowering the\nprecision of their numerical representations (e.g., from 32-bit\nto 8-bit).", "metadata": {}}, {"text": "This compression speeds up inference, making LLMs\nmore efficient with minimal impact on accuracy.", "metadata": {}}, {"text": "In this paper,\nwe leverage quantization alongside PETs to minimize the\ncomputational cost while maintaining performance in code-\nrelated tasks.", "metadata": {}}, {"text": "While developing a comprehensive methodology for mea-\nsuring LLM energy consumption is beyond this paper’s scope,\nwe focus on reducing these emissions through efficient PETs.", "metadata": {}}, {"text": "By utilizing custom tags, we aim to lower energy consumption\nin LLMs used for code-related tasks, offering an approach that\nbalances sustainability with performance.", "metadata": {}}], "metadata": {"page": 2}}, {"text": "[Image page=2 idx=1 name=Im0.png] Size: 2048x1025, Data: 691912 bytes", "sentences": [{"text": "[Image page=2 idx=1 name=Im0.png] Size: 2048x1025, Data: 691912 bytes", "metadata": {}}], "metadata": {"page": 2, "image_index": 1, "image_name": "Im0.png", "image_width": 2048, "image_height": 1025, "attachment_type": "image", "has_image_data": true, "image_data_size": 691912}}], "metadata": {"page": 2}}, {"title": "Page 3", "paragraphs": [{"text": "CodeXGlueDataset\n1\nLlama 3PET Selector Prompt Augmenter\n2 3\n 4\nCode Carbon \nEnergy Measurer\n5\nMonitors\nLLM Answers\nEnergy Measurements\n6\n7\nPrompt Creator\nProduces\nGeneratesSnippets PET Query\nFig. 2: Workflow of the performed experiments.\nIII. P ERFORMED EXPERIMENTS\nFigure 2 depicts the workflow of the experiments we per-\nformed to answer the two research questions. Starting from the\nCodeXGLUE dataset [14] 1 , prompt creator 2 translates\ninput prompts into a format that Llama 3 can understand,\nbefore augmenting them with tags that we specifically in-\ntroduced 3 . Afterward, the crafted prompts are used to\nquery the LLM locally deployed 4 . For each snippet, we\nexecuted 75 queries.2 Each Llama run is monitored 5 by the\nCodeCarbon energy monitoring tool. For each execution, we\nstore three artifacts (question, answer 6 , and measurement\n7 ), to enable both efficiency and accuracy analysis.\nA. Dataset\nAmong different benchmarks, we select CodeXGLUE as it\nis tailored for supporting and evaluating LLMs in code-related\ntasks [27], [28]. In this paper, we consider the code completion\ntask as it is widely supported by LLMs as recently investigated\n[29], [30]. This task leverages established evaluation method-\nologies in the literature, enabling straightforward comparisons\nwith ground truth data.\nB. Prompt Creator\nThis component is responsible for defining and augmenting\nprompts that have been used to query the model under analysis.\nIn particular, we use standard PETs, i.e., zero-shot, one-shot,\nand few-shots, as a baseline to evaluate the effect of custom\ntags in terms of energy impact. The Llama 3 model card 3\ndefines several tokens which form the model’s input. We aim to\ninvestigate the impact of custom tags on energy consumption\nand performance metrics for Llama 3. To this end, we define\nfive distinct prompt configurations. Each prompt comprises\ntwo key components: a role attribute and content speci-\nfication, as illustrated in Listing 1. The role attribute can be\nassigned as either system or user. In the case of system,\nthe accompanying content attribute specifies the task to be\n2Three prompting techniques (i.e., zero-shot, one-shot, and few-shots) ×\nfive prompt configurations × five repetitions to mitigate possible energy\nmeasurement inaccuracies.\n3www.llama.com/docs/model-cards-and-prompt-formats/meta-llama-3/\nperformed, thus clarifying the expected contribution from the\nmodel. For example, in Listing 1, the system role is configured\nto instruct the model on a code completion task for given code\nfragments. The user role, on the other hand, introduces the\ninput code snippet that the model is expected to complete.\nAccording to the different configurations, the content can\nbe enhanced with custom tags or explanations related to the\ntask. The configurations are defined as follows:\nC0 - default : We define the model’s role and provide the\nincomplete snippet without any customization. In the case of\none-shot and few-shots, we describe one and five examples,\nrespectively. We fix the number of examples equal to five for\nthe few-shots technique since it obtains adequate accuracy with\nlimited token size [31]. Nonetheless, we acknowledge that\na deep study concerning the different shot sizes is needed.\nListing 1 depicts an example of prompt in its default repre-\nsentation.\nListing 1: Example of a zero-shot prompt.\n1{\n2\"role\": \"system\",\n3\"content\" : \"You are an AI assistant\nspecialized in code completion for Java.\nYour task is to complete the provided Java\ncode segment with one line. Give only the\ncode completion.\",\n4},{\n5\"role\": \"user\",\n6\"content\": \"package com.lmax.disruptor.support\n; import java.util.concurrent.\nThreadFactory; public final\"\n7}\nC1 - use of custom tags without explanation : We augment\nprompts by using custom tags i.e., <code> and <incomplete>\nto support the inference phase to distinguish the input source\ncode, and the fragment that needs to be completed. We do not\nprovide any explanation of what is the meaning of such custom\ntags. Therefore, we aim to explore the LLM’s capability to\nunderstand the customization. Listing 2 is an example of a\ncode fragment augmented with custom tags.", "sentences": [{"text": "CodeXGlueDataset\n1\nLlama 3PET Selector Prompt Augmenter\n2 3\n 4\nCode Carbon \nEnergy Measurer\n5\nMonitors\nLLM Answers\nEnergy Measurements\n6\n7\nPrompt Creator\nProduces\nGeneratesSnippets PET Query\nFig.", "metadata": {}}, {"text": "2: Workflow of the performed experiments.", "metadata": {}}, {"text": "III.", "metadata": {}}, {"text": "P ERFORMED EXPERIMENTS\nFigure 2 depicts the workflow of the experiments we per-\nformed to answer the two research questions.", "metadata": {}}, {"text": "Starting from the\nCodeXGLUE dataset [14] 1 , prompt creator 2 translates\ninput prompts into a format that Llama 3 can understand,\nbefore augmenting them with tags that we specifically in-\ntroduced 3 .", "metadata": {}}, {"text": "Afterward, the crafted prompts are used to\nquery the LLM locally deployed 4 .", "metadata": {}}, {"text": "For each snippet, we\nexecuted 75 queries.2 Each Llama run is monitored 5 by the\nCodeCarbon energy monitoring tool.", "metadata": {}}, {"text": "For each execution, we\nstore three artifacts (question, answer 6 , and measurement\n7 ), to enable both efficiency and accuracy analysis.", "metadata": {}}, {"text": "A.", "metadata": {}}, {"text": "Dataset\nAmong different benchmarks, we select CodeXGLUE as it\nis tailored for supporting and evaluating LLMs in code-related\ntasks [27], [28].", "metadata": {}}, {"text": "In this paper, we consider the code completion\ntask as it is widely supported by LLMs as recently investigated\n[29], [30].", "metadata": {}}, {"text": "This task leverages established evaluation method-\nologies in the literature, enabling straightforward comparisons\nwith ground truth data.", "metadata": {}}, {"text": "B.", "metadata": {}}, {"text": "Prompt Creator\nThis component is responsible for defining and augmenting\nprompts that have been used to query the model under analysis.", "metadata": {}}, {"text": "In particular, we use standard PETs, i.e., zero-shot, one-shot,\nand few-shots, as a baseline to evaluate the effect of custom\ntags in terms of energy impact.", "metadata": {}}, {"text": "The Llama 3 model card 3\ndefines several tokens which form the model’s input.", "metadata": {}}, {"text": "We aim to\ninvestigate the impact of custom tags on energy consumption\nand performance metrics for Llama 3.", "metadata": {}}, {"text": "To this end, we define\nfive distinct prompt configurations.", "metadata": {}}, {"text": "Each prompt comprises\ntwo key components: a role attribute and content speci-\nfication, as illustrated in Listing 1.", "metadata": {}}, {"text": "The role attribute can be\nassigned as either system or user.", "metadata": {}}, {"text": "In the case of system,\nthe accompanying content attribute specifies the task to be\n2Three prompting techniques (i.e., zero-shot, one-shot, and few-shots) ×\nfive prompt configurations × five repetitions to mitigate possible energy\nmeasurement inaccuracies.", "metadata": {}}, {"text": "3www.llama.com/docs/model-cards-and-prompt-formats/meta-llama-3/\nperformed, thus clarifying the expected contribution from the\nmodel.", "metadata": {}}, {"text": "For example, in Listing 1, the system role is configured\nto instruct the model on a code completion task for given code\nfragments.", "metadata": {}}, {"text": "The user role, on the other hand, introduces the\ninput code snippet that the model is expected to complete.", "metadata": {}}, {"text": "According to the different configurations, the content can\nbe enhanced with custom tags or explanations related to the\ntask.", "metadata": {}}, {"text": "The configurations are defined as follows:\nC0 - default : We define the model’s role and provide the\nincomplete snippet without any customization.", "metadata": {}}, {"text": "In the case of\none-shot and few-shots, we describe one and five examples,\nrespectively.", "metadata": {}}, {"text": "We fix the number of examples equal to five for\nthe few-shots technique since it obtains adequate accuracy with\nlimited token size [31].", "metadata": {}}, {"text": "Nonetheless, we acknowledge that\na deep study concerning the different shot sizes is needed.", "metadata": {}}, {"text": "Listing 1 depicts an example of prompt in its default repre-\nsentation.", "metadata": {}}, {"text": "Listing 1: Example of a zero-shot prompt.", "metadata": {}}, {"text": "1{\n2\"role\": \"system\",\n3\"content\" : \"You are an AI assistant\nspecialized in code completion for Java.", "metadata": {}}, {"text": "Your task is to complete the provided Java\ncode segment with one line.", "metadata": {}}, {"text": "Give only the\ncode completion.\",\n4},{\n5\"role\": \"user\",\n6\"content\": \"package com.lmax.disruptor.support\n;", "metadata": {}}, {"text": "import java.util.concurrent.", "metadata": {}}, {"text": "ThreadFactory;", "metadata": {}}, {"text": "public final\"\n7}\nC1 - use of custom tags without explanation : We augment\nprompts by using custom tags i.e., <code> and <incomplete>\nto support the inference phase to distinguish the input source\ncode, and the fragment that needs to be completed.", "metadata": {}}, {"text": "We do not\nprovide any explanation of what is the meaning of such custom\ntags.", "metadata": {}}, {"text": "Therefore, we aim to explore the LLM’s capability to\nunderstand the customization.", "metadata": {}}, {"text": "Listing 2 is an example of a\ncode fragment augmented with custom tags.", "metadata": {}}], "metadata": {"page": 3}}, {"text": "[Image page=3 idx=1 name=X11.png] Size: 500x500, Data: 16883 bytes", "sentences": [{"text": "[Image page=3 idx=1 name=X11.png] Size: 500x500, Data: 16883 bytes", "metadata": {}}], "metadata": {"page": 3, "image_index": 1, "image_name": "X11.png", "image_width": 500, "image_height": 500, "attachment_type": "image", "has_image_data": true, "image_data_size": 16883}}, {"text": "[Image page=3 idx=2 name=X8.png] Size: 200x200, Data: 18037 bytes", "sentences": [{"text": "[Image page=3 idx=2 name=X8.png] Size: 200x200, Data: 18037 bytes", "metadata": {}}], "metadata": {"page": 3, "image_index": 2, "image_name": "X8.png", "image_width": 200, "image_height": 200, "attachment_type": "image", "has_image_data": true, "image_data_size": 18037}}], "metadata": {"page": 3}}, {"title": "Page 4", "paragraphs": [{"text": "Listing 2: Fragment of a prompt including custom tags.\n1 {\n2 \"role\": \"user\",\n3 \"content\" :\"<code> package com.lmax.disruptor.\nsupport; import java.util.concurrent.\nThreadFactory; </code> <incomplete> public\nfinal </incomplete>\"\n4 }\nC2 - use of custom tags with explanation : We embed the\nmeaning of the custom tags in the prompt as shown in\nListing 3.\nListing 3: Fragment of a prompt including custom tags expla-\nnation.\n1 {\n2 \"role\": \"user\",\n3 \"content\" :\"The code to analyze is marked by\nthe <code> tag and the line to be\ncompleted is marked by the <incomplete>\ntag. <code> package com.lmax.disruptor.\nsupport; import java.util.concurrent.\nThreadFactory;</code><incomplete> public\nfinal </incomplete>\"\n4 }\nC3 - custom prompt explained in the system : Differently from\nconfiguration C2, the explanation of custom tags is given in\nthe system role part of the input prompt as shown in Listing\n4.\nListing 4: Example of a zero-shot prompt including the defi-\nnition of custom tags.\n1 {\n2 \"role\": \"system\",\n3 \"content\" : \"You are an AI assistant\nspecialized in code completion for Java.\nYour task is to complete the provided Java\ncode segment with one line. Give only the\ncode completion. The code to analyze is\nmarked by the <code> tag and the line to\nbe completed is marked by the <incomplete>\ntag.\",\n4 },{\n5 \"role\": \"user\",\n6 \"content\": \"<code> package com.lmax.disruptor.\nsupport; import java.util.concurrent.\nThreadFactory;</code><incomplete> public\nfinal </incomplete>\"\n7 }\nC4 - no system definition : With this configuration, we want to\nassess the effect of the complete absence of the system role\ndefinition. Therefore, we provide only the incomplete input\nsnippet and a task definition directly in the prompt without\nany customization as illustrated in Listing 5.\nListing 5: Fragment of a prompt including custom tags.\n1{\n2\"role\": \"system\",\n3\"content\" : \"\",\n4},{\n5\"role\": \"user\",\n6\"content\" :\"Hi, complete the following snippet\nadding one line please: package com.lmax.\ndisruptor.support; import java.util.\nconcurrent.ThreadFactory; public final\"\n7}\nThe process ends with the generation of three different arti-\nfacts, i.e., questions, answers, and measurements. A question\nis a copy of the query given to the LLM and it is stored\nfor subsequent analysis. The measurement is the outcome of\nthe Llama 3 process monitored by CodeCarbon to solve the\ncode completion task. Meanwhile, an answer is just a sequence\nof Java statements to complete the input snippet. In some\ncases, the LLM answer is verbose. Therefore, we can notice\na sequence of several lines of code.\nC. Metrics\nConcerning the metrics, we rely on CodeCarbon predefined\nformat4 to avoid any bias in the comparison. Since our study\nfocuses on the energy effects on the GPU, we rely on the\ngpu energy value to support the evaluation.\nDuring our investigation, we evaluate the effects of prompt-\ning techniques and customization of the prompts. Therefore,\nwe employ the following metrics:\n➤ Energy Consumption: This metric quantifies the energy\nconsumed during the inference phase of Llama excluding the\nmodel loading. We rely on the calculation provided by Code-\nCarbon. In its report, we focus on the value of gpu energy\nwhich calculates the energy consumed during in the inference,\nexpressed in kWh. To reduce biases related to unprecise mon-\nitoring, we repeated the tests 5 times, calculating eventually\nthe average.\n➤ Execution Time: The execution time calculates the du-\nration needed by Llama 3 to perform the inference. The\nmonitoring is limited only on the inference phase, excluding\nthe model loading time. The time is excerpted from the\nCodeCarbon report similarly for the energy value.\n➤ Edit Distance: The edit distance metric calculates how\nsimilar the proposed answer is to the ground truth, by counting\nthe number of characters that need to be substituted, inserted,\nor deleted to transform an input string into a target one. We\nused the nltk edit distance, which implements the well-known\nLevenshtein Distance [32].\n➤ Exact Match The exact match metric measures whether\nthe answer of the LLM has an edit distance of 0, meaning\nthat the ground truth and answer are the same. Since LLMs\nare generally verbose, we fixed the exact match threshold to\nedit distance less or equal to 2. The rationale is that Llama\nproduces the results by adding several random characters\nto the answer, e.g. extra spaces, single and double quotes,\nsemicolons.\nD. Execution process\nThe experiments have been performed by considering the\nsettings shown in Table I. In particular, we tested 1,000 random\n4https://mlco2.github.io/codecarbon/output.html", "sentences": [{"text": "Listing 2: Fragment of a prompt including custom tags.", "metadata": {}}, {"text": "1 {\n2 \"role\": \"user\",\n3 \"content\" :\"<code> package com.lmax.disruptor.", "metadata": {}}, {"text": "support;", "metadata": {}}, {"text": "import java.util.concurrent.", "metadata": {}}, {"text": "ThreadFactory;", "metadata": {}}, {"text": "</code> <incomplete> public\nfinal </incomplete>\"\n4 }\nC2 - use of custom tags with explanation : We embed the\nmeaning of the custom tags in the prompt as shown in\nListing 3.", "metadata": {}}, {"text": "Listing 3: Fragment of a prompt including custom tags expla-\nnation.", "metadata": {}}, {"text": "1 {\n2 \"role\": \"user\",\n3 \"content\" :\"The code to analyze is marked by\nthe <code> tag and the line to be\ncompleted is marked by the <incomplete>\ntag.", "metadata": {}}, {"text": "<code> package com.lmax.disruptor.", "metadata": {}}, {"text": "support;", "metadata": {}}, {"text": "import java.util.concurrent.", "metadata": {}}, {"text": "ThreadFactory;</code><incomplete> public\nfinal </incomplete>\"\n4 }\nC3 - custom prompt explained in the system : Differently from\nconfiguration C2, the explanation of custom tags is given in\nthe system role part of the input prompt as shown in Listing\n4.", "metadata": {}}, {"text": "Listing 4: Example of a zero-shot prompt including the defi-\nnition of custom tags.", "metadata": {}}, {"text": "1 {\n2 \"role\": \"system\",\n3 \"content\" : \"You are an AI assistant\nspecialized in code completion for Java.", "metadata": {}}, {"text": "Your task is to complete the provided Java\ncode segment with one line.", "metadata": {}}, {"text": "Give only the\ncode completion.", "metadata": {}}, {"text": "The code to analyze is\nmarked by the <code> tag and the line to\nbe completed is marked by the <incomplete>\ntag.\",\n4 },{\n5 \"role\": \"user\",\n6 \"content\": \"<code> package com.lmax.disruptor.", "metadata": {}}, {"text": "support;", "metadata": {}}, {"text": "import java.util.concurrent.", "metadata": {}}, {"text": "ThreadFactory;</code><incomplete> public\nfinal </incomplete>\"\n7 }\nC4 - no system definition : With this configuration, we want to\nassess the effect of the complete absence of the system role\ndefinition.", "metadata": {}}, {"text": "Therefore, we provide only the incomplete input\nsnippet and a task definition directly in the prompt without\nany customization as illustrated in Listing 5.", "metadata": {}}, {"text": "Listing 5: Fragment of a prompt including custom tags.", "metadata": {}}, {"text": "1{\n2\"role\": \"system\",\n3\"content\" : \"\",\n4},{\n5\"role\": \"user\",\n6\"content\" :\"Hi, complete the following snippet\nadding one line please: package com.lmax.", "metadata": {}}, {"text": "disruptor.support;", "metadata": {}}, {"text": "import java.util.", "metadata": {}}, {"text": "concurrent.ThreadFactory;", "metadata": {}}, {"text": "public final\"\n7}\nThe process ends with the generation of three different arti-\nfacts, i.e., questions, answers, and measurements.", "metadata": {}}, {"text": "A question\nis a copy of the query given to the LLM and it is stored\nfor subsequent analysis.", "metadata": {}}, {"text": "The measurement is the outcome of\nthe Llama 3 process monitored by CodeCarbon to solve the\ncode completion task.", "metadata": {}}, {"text": "Meanwhile, an answer is just a sequence\nof Java statements to complete the input snippet.", "metadata": {}}, {"text": "In some\ncases, the LLM answer is verbose.", "metadata": {}}, {"text": "Therefore, we can notice\na sequence of several lines of code.", "metadata": {}}, {"text": "C.", "metadata": {}}, {"text": "Metrics\nConcerning the metrics, we rely on CodeCarbon predefined\nformat4 to avoid any bias in the comparison.", "metadata": {}}, {"text": "Since our study\nfocuses on the energy effects on the GPU, we rely on the\ngpu energy value to support the evaluation.", "metadata": {}}, {"text": "During our investigation, we evaluate the effects of prompt-\ning techniques and customization of the prompts.", "metadata": {}}, {"text": "Therefore,\nwe employ the following metrics:\n➤ Energy Consumption: This metric quantifies the energy\nconsumed during the inference phase of Llama excluding the\nmodel loading.", "metadata": {}}, {"text": "We rely on the calculation provided by Code-\nCarbon.", "metadata": {}}, {"text": "In its report, we focus on the value of gpu energy\nwhich calculates the energy consumed during in the inference,\nexpressed in kWh.", "metadata": {}}, {"text": "To reduce biases related to unprecise mon-\nitoring, we repeated the tests 5 times, calculating eventually\nthe average.", "metadata": {}}, {"text": "➤ Execution Time: The execution time calculates the du-\nration needed by Llama 3 to perform the inference.", "metadata": {}}, {"text": "The\nmonitoring is limited only on the inference phase, excluding\nthe model loading time.", "metadata": {}}, {"text": "The time is excerpted from the\nCodeCarbon report similarly for the energy value.", "metadata": {}}, {"text": "➤ Edit Distance: The edit distance metric calculates how\nsimilar the proposed answer is to the ground truth, by counting\nthe number of characters that need to be substituted, inserted,\nor deleted to transform an input string into a target one.", "metadata": {}}, {"text": "We\nused the nltk edit distance, which implements the well-known\nLevenshtein Distance [32].", "metadata": {}}, {"text": "➤ Exact Match The exact match metric measures whether\nthe answer of the LLM has an edit distance of 0, meaning\nthat the ground truth and answer are the same.", "metadata": {}}, {"text": "Since LLMs\nare generally verbose, we fixed the exact match threshold to\nedit distance less or equal to 2.", "metadata": {}}, {"text": "The rationale is that Llama\nproduces the results by adding several random characters\nto the answer, e.g.", "metadata": {}}, {"text": "extra spaces, single and double quotes,\nsemicolons.", "metadata": {}}, {"text": "D.", "metadata": {}}, {"text": "Execution process\nThe experiments have been performed by considering the\nsettings shown in Table I.", "metadata": {}}, {"text": "In particular, we tested 1,000 random\n4https://mlco2.github.io/codecarbon/output.html", "metadata": {}}], "metadata": {"page": 4}}], "metadata": {"page": 4}}, {"title": "Page 5", "paragraphs": [{"text": "TABLE I: Summary of the Experimental Settings\nModel Llama3 8B - Instruct\nSnippets 1,000\nPETs 3\nCustom Prompts 5\nRepetitions 5\nPause 10 seconds\nMetrics (Performance) Energy Consumption, Execution Time\nMetrics (Accuracy) Exact Match, Edit Distance\nincomplete Java snippets retrieved from the code-completion\ndataset of CodeXGLUE. As discussed in Section IV the overall\nexecution requires more than 250 hours. We calculated an\naverage test time per snippet of about 900 seconds. Therefore,\nwe limit ourselves to 1,000 snippets. with the abovementioned\nPETs\nAs discussed in Section III-B, we defined five distinct\nconfigurations for each query. Consequently, we tested every\ncombination of prompting techniques and the use of custom\ntags. To ensure experimental reliability, each test is repeated\nfive times [33], [34], with a ten-second pause between each test\nto mitigate potential tail effects [34], [35]. We use two metrics\nto evaluate energy consumption and execution time, and two\nprimary metrics (exact match and edit distance) to assess the\nimpact of different configurations on accuracy. These metrics\nalign with those used in the original evaluation of the code\ncompletion benchmark suite by the authors of CodeXGLUE.\nAll the experiments have been conducted on an isolated\ndesktop equipped with an AMD Ryzen 7 5800X 3.8GHz CPU\nand an Nvidia Geforce RTX 4060 TI (8 GB VRAM). 5 The\noperating system is Xubuntu 23.04. Since the GPU provided\nonly 8GB of RAM, we used the quantized version of the\nLlama model i.e., we used 16-bit float rather than the default\n32-bit.\nIV. E XPERIMENTAL RESULTS\nAnswering RQ1: Figure 3a shows the energy consumption\nof the three prompt techniques applied to the five different\nconfigurations. In particular, with the default configuration C0,\nzero-shot is the most energy-efficient, with an average cost of\nabout 0.000016 kWh. one-shot and a few-shots consumed an\naverage of 0.000035 kWh and 0.000054 kWh, respectively.\nCustom tags can contribute to reducing the energy consump-\ntion of the video card. As shown in Fig. 3a, the best config-\nuration is the C2 (explanation in prompts). While the zero-\nshot technique passed from 0.0000157 (of C0) to 0.0000146\n(-7%), one-shot and few-shots reduced the consumption from\n0.0000347 to 0.0000174 (-99%) and from 0.0000537 to\n0.0000293 (-83%) comparing with the default configuration\nC0, respectively. It is also interesting to see the results of C4,\nin which we do not specify any role in the system token. The\nconsumption increased from 0.0000157 to 0.000189 kWh for\nzero-shot and from 0.0000347 to 0.000181 kWh for one-shot.\n5https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4060-\n4060ti/\nThe reason is that the model started to generate completely\nnew code snippets when asked to finalize the code given as\ninput. The few-shots technique seems to be less affected by\nthis problem. The sequence of example questions and answers\ninstructed the model on the behaviour despite the lack of the\nsystem role specification.\nConcerning the execution time, Figure 3b reports the results\nobtained for all the prompt configurations. Similar to energy\nconsumption, the usage of custom tags provides a general\nimprovement in performance. In particular, the one-shot and\nfew-shots reduced the average time from 1.54 seconds of\nconfiguration C0 to 0.74 (-52%) and from 2.1 to 1.09 (-48%),\nrespectively, using configuration C2. The zero-shot technique\nperformed better using C1, reporting an improvement from\n0.74 seconds to 0.63 (-14.8%). Similarly, for the energy\nconsumption, in the case of C4, we can notice a remarkable\nincrease in execution time for zero-shot and one-shot.\nAnswer to RQ 1: Our study reveals that custom tags\ncan reduce the energy consumption of LLMs across the\nthree prompt engineering techniques tested for source\ncode completion tasks.\nAnswering RQ2: Figure 4 depicts the obtained results in\nterms of accuracy metrics. In particular, Figure 4a shows the\neffects of custom tags on exact match performance across\ndifferent prompt engineering techniques. Overall, we observe\nan increase in exact matches for configuration C1-C3 in com-\nparison with the default configuration C0. Notably, zero-shot\nshows the greatest improvement with C1, where exact matches\nrise from 63 to 82, reflecting a 23% increase. Both one-\nshot and few-shots see substantial gains with C3, achieving\napproximately a 44% improvement. Interestingly, with C4,\nzero-shot fails to achieve any exact matches.\nFigure 4b shows the impact of custom tags on edit distance\nmetrics, where an edit distance of 0 indicates a perfect result.\nOverall, custom tags contributed to a reduction in edit distance,\nwith C2 emerging as the most effective configuration across all\nprompt engineering techniques. Specifically, zero-shot showed\na 24% improvement, one-shot achieved a 64% reduction, and\nfew-shots improved by 70%. Results for zero-shot and one-\nshot are omitted for C4 because, with this configuration,\nthe LLM produced uncontrolled responses. As a result, it\nwas impossible to calculate edit distance accurately, as the\noutputs included both code and explanatory text. Despite\nlacking explicit role definitions, few-shots continued to yield\nsatisfactory results.\nAnswer to RQ 2: Prompt customizations enhanced\nthe accuracy of the tested PETs, showing a positive\ntrend with increased exact matches and reduced edit\ndistances.", "sentences": [{"text": "TABLE I: Summary of the Experimental Settings\nModel Llama3 8B - Instruct\nSnippets 1,000\nPETs 3\nCustom Prompts 5\nRepetitions 5\nPause 10 seconds\nMetrics (Performance) Energy Consumption, Execution Time\nMetrics (Accuracy) Exact Match, Edit Distance\nincomplete Java snippets retrieved from the code-completion\ndataset of CodeXGLUE.", "metadata": {}}, {"text": "As discussed in Section IV the overall\nexecution requires more than 250 hours.", "metadata": {}}, {"text": "We calculated an\naverage test time per snippet of about 900 seconds.", "metadata": {}}, {"text": "Therefore,\nwe limit ourselves to 1,000 snippets.", "metadata": {}}, {"text": "with the abovementioned\nPETs\nAs discussed in Section III-B, we defined five distinct\nconfigurations for each query.", "metadata": {}}, {"text": "Consequently, we tested every\ncombination of prompting techniques and the use of custom\ntags.", "metadata": {}}, {"text": "To ensure experimental reliability, each test is repeated\nfive times [33], [34], with a ten-second pause between each test\nto mitigate potential tail effects [34], [35].", "metadata": {}}, {"text": "We use two metrics\nto evaluate energy consumption and execution time, and two\nprimary metrics (exact match and edit distance) to assess the\nimpact of different configurations on accuracy.", "metadata": {}}, {"text": "These metrics\nalign with those used in the original evaluation of the code\ncompletion benchmark suite by the authors of CodeXGLUE.", "metadata": {}}, {"text": "All the experiments have been conducted on an isolated\ndesktop equipped with an AMD Ryzen 7 5800X 3.8GHz CPU\nand an Nvidia Geforce RTX 4060 TI (8 GB VRAM).", "metadata": {}}, {"text": "5 The\noperating system is Xubuntu 23.04.", "metadata": {}}, {"text": "Since the GPU provided\nonly 8GB of RAM, we used the quantized version of the\nLlama model i.e., we used 16-bit float rather than the default\n32-bit.", "metadata": {}}, {"text": "IV.", "metadata": {}}, {"text": "E XPERIMENTAL RESULTS\nAnswering RQ1: Figure 3a shows the energy consumption\nof the three prompt techniques applied to the five different\nconfigurations.", "metadata": {}}, {"text": "In particular, with the default configuration C0,\nzero-shot is the most energy-efficient, with an average cost of\nabout 0.000016 kWh.", "metadata": {}}, {"text": "one-shot and a few-shots consumed an\naverage of 0.000035 kWh and 0.000054 kWh, respectively.", "metadata": {}}, {"text": "Custom tags can contribute to reducing the energy consump-\ntion of the video card.", "metadata": {}}, {"text": "As shown in Fig.", "metadata": {}}, {"text": "3a, the best config-\nuration is the C2 (explanation in prompts).", "metadata": {}}, {"text": "While the zero-\nshot technique passed from 0.0000157 (of C0) to 0.0000146\n(-7%), one-shot and few-shots reduced the consumption from\n0.0000347 to 0.0000174 (-99%) and from 0.0000537 to\n0.0000293 (-83%) comparing with the default configuration\nC0, respectively.", "metadata": {}}, {"text": "It is also interesting to see the results of C4,\nin which we do not specify any role in the system token.", "metadata": {}}, {"text": "The\nconsumption increased from 0.0000157 to 0.000189 kWh for\nzero-shot and from 0.0000347 to 0.000181 kWh for one-shot.", "metadata": {}}, {"text": "5https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4060-\n4060ti/\nThe reason is that the model started to generate completely\nnew code snippets when asked to finalize the code given as\ninput.", "metadata": {}}, {"text": "The few-shots technique seems to be less affected by\nthis problem.", "metadata": {}}, {"text": "The sequence of example questions and answers\ninstructed the model on the behaviour despite the lack of the\nsystem role specification.", "metadata": {}}, {"text": "Concerning the execution time, Figure 3b reports the results\nobtained for all the prompt configurations.", "metadata": {}}, {"text": "Similar to energy\nconsumption, the usage of custom tags provides a general\nimprovement in performance.", "metadata": {}}, {"text": "In particular, the one-shot and\nfew-shots reduced the average time from 1.54 seconds of\nconfiguration C0 to 0.74 (-52%) and from 2.1 to 1.09 (-48%),\nrespectively, using configuration C2.", "metadata": {}}, {"text": "The zero-shot technique\nperformed better using C1, reporting an improvement from\n0.74 seconds to 0.63 (-14.8%).", "metadata": {}}, {"text": "Similarly, for the energy\nconsumption, in the case of C4, we can notice a remarkable\nincrease in execution time for zero-shot and one-shot.", "metadata": {}}, {"text": "Answer to RQ 1: Our study reveals that custom tags\ncan reduce the energy consumption of LLMs across the\nthree prompt engineering techniques tested for source\ncode completion tasks.", "metadata": {}}, {"text": "Answering RQ2: Figure 4 depicts the obtained results in\nterms of accuracy metrics.", "metadata": {}}, {"text": "In particular, Figure 4a shows the\neffects of custom tags on exact match performance across\ndifferent prompt engineering techniques.", "metadata": {}}, {"text": "Overall, we observe\nan increase in exact matches for configuration C1-C3 in com-\nparison with the default configuration C0.", "metadata": {}}, {"text": "Notably, zero-shot\nshows the greatest improvement with C1, where exact matches\nrise from 63 to 82, reflecting a 23% increase.", "metadata": {}}, {"text": "Both one-\nshot and few-shots see substantial gains with C3, achieving\napproximately a 44% improvement.", "metadata": {}}, {"text": "Interestingly, with C4,\nzero-shot fails to achieve any exact matches.", "metadata": {}}, {"text": "Figure 4b shows the impact of custom tags on edit distance\nmetrics, where an edit distance of 0 indicates a perfect result.", "metadata": {}}, {"text": "Overall, custom tags contributed to a reduction in edit distance,\nwith C2 emerging as the most effective configuration across all\nprompt engineering techniques.", "metadata": {}}, {"text": "Specifically, zero-shot showed\na 24% improvement, one-shot achieved a 64% reduction, and\nfew-shots improved by 70%.", "metadata": {}}, {"text": "Results for zero-shot and one-\nshot are omitted for C4 because, with this configuration,\nthe LLM produced uncontrolled responses.", "metadata": {}}, {"text": "As a result, it\nwas impossible to calculate edit distance accurately, as the\noutputs included both code and explanatory text.", "metadata": {}}, {"text": "Despite\nlacking explicit role definitions, few-shots continued to yield\nsatisfactory results.", "metadata": {}}, {"text": "Answer to RQ 2: Prompt customizations enhanced\nthe accuracy of the tested PETs, showing a positive\ntrend with increased exact matches and reduced edit\ndistances.", "metadata": {}}], "metadata": {"page": 5}}], "metadata": {"page": 5}}, {"title": "Page 6", "paragraphs": [{"text": "C0 C1 C2 C3 C4\n0.000000\n0.000025\n0.000050\n0.000075\n0.000100\n0.000125\n0.000150\n0.000175Energy Consumption (KWh)\nPET\nZeroShot\nOneShot\nFewShot\n(a) Energy Consumption in (kWh).\nC0 C1 C2 C3 C4\n0\n2\n4\n6\n8Execution Time (seconds)\nPET\nZeroShot\nOneShot\nFewShot (b) Execution Time.\nFig. 3: Energy consumption with different prompt configurations.\nC0 C1 C2 C3 C4\n0\n20\n40\n60\n80\n100\n120\n140Exatch Match Absolute Number\nPET\nZeroShot\nOneShot\nFewShot\n(a) Exact Match.\nC0 C1 C2 C3 C4\n0\n20\n40\n60\n80\n100\n120Edit Distance\nPET\nZeroShot\nOneShot\nFewShot (b) Edit Distance.\nFig. 4: LLMs accuracy with different prompt configurations.\nV. R ELATED WORK\nAssessing LLMs energy consumption: Jagannadharao et al.\n[36] investigate the usage of time-shifting technique to reduce\nthe energy consumption of LLMs during long-running training\nsessions. Concretely, the authors estimates the consumption\nof Llama model by pausing and resuming the training when\nthe carbon emission is below a certain threshold. The results\nshows that the proposed approach succeed in reducing the\ncarbon emission even though the region may impact the ob-\ntained results. Liu and Yin [37] investigate how to reduce and\nmeasure the consumption of pre-trained models by combining\nfine-tuning and efficient tokenizers. In particular, BERT, Distil-\nBERT, and T5 models are compared using SQuAD benchmark\n[38] in terms of accuracy and carbon emissions. The experi-\nmental results reveal that both the T5 and BERT models emit-\nted considerably more CO2 compared to DistilBERT and the\nT4 GPU contributes in reducing the overall carbon emissions.\nSamsi et al. [13] compare the inference performance in terms\nof watts of different Llama models, i.e., evaluating smaller\nmodels (7B, 13B) against the largest available version (65B) at\nthe time of writing. In addition, the authors consider different\nGPUs, i.e., V100 and A100. The study reveals that 8 V100\nGPUs each with 32 GB of RAM or 4 A100 GPUs each with\n80GB of memory are required for any meaningful inferences\nwith the 65B LLaMA model, thus making small models a\nsuitable choice for energy-efficient applications. Cursaro et al.", "sentences": [{"text": "C0 C1 C2 C3 C4\n0.000000\n0.000025\n0.000050\n0.000075\n0.000100\n0.000125\n0.000150\n0.000175Energy Consumption (KWh)\nPET\nZeroShot\nOneShot\nFewShot\n(a) Energy Consumption in (kWh).", "metadata": {}}, {"text": "C0 C1 C2 C3 C4\n0\n2\n4\n6\n8Execution Time (seconds)\nPET\nZeroShot\nOneShot\nFewShot (b) Execution Time.", "metadata": {}}, {"text": "Fig.", "metadata": {}}, {"text": "3: Energy consumption with different prompt configurations.", "metadata": {}}, {"text": "C0 C1 C2 C3 C4\n0\n20\n40\n60\n80\n100\n120\n140Exatch Match Absolute Number\nPET\nZeroShot\nOneShot\nFewShot\n(a) Exact Match.", "metadata": {}}, {"text": "C0 C1 C2 C3 C4\n0\n20\n40\n60\n80\n100\n120Edit Distance\nPET\nZeroShot\nOneShot\nFewShot (b) Edit Distance.", "metadata": {}}, {"text": "Fig.", "metadata": {}}, {"text": "4: LLMs accuracy with different prompt configurations.", "metadata": {}}, {"text": "V.", "metadata": {}}, {"text": "R ELATED WORK\nAssessing LLMs energy consumption: Jagannadharao et al.", "metadata": {}}, {"text": "[36] investigate the usage of time-shifting technique to reduce\nthe energy consumption of LLMs during long-running training\nsessions.", "metadata": {}}, {"text": "Concretely, the authors estimates the consumption\nof Llama model by pausing and resuming the training when\nthe carbon emission is below a certain threshold.", "metadata": {}}, {"text": "The results\nshows that the proposed approach succeed in reducing the\ncarbon emission even though the region may impact the ob-\ntained results.", "metadata": {}}, {"text": "Liu and Yin [37] investigate how to reduce and\nmeasure the consumption of pre-trained models by combining\nfine-tuning and efficient tokenizers.", "metadata": {}}, {"text": "In particular, BERT, Distil-\nBERT, and T5 models are compared using SQuAD benchmark\n[38] in terms of accuracy and carbon emissions.", "metadata": {}}, {"text": "The experi-\nmental results reveal that both the T5 and BERT models emit-\nted considerably more CO2 compared to DistilBERT and the\nT4 GPU contributes in reducing the overall carbon emissions.", "metadata": {}}, {"text": "Samsi et al.", "metadata": {}}, {"text": "[13] compare the inference performance in terms\nof watts of different Llama models, i.e., evaluating smaller\nmodels (7B, 13B) against the largest available version (65B) at\nthe time of writing.", "metadata": {}}, {"text": "In addition, the authors consider different\nGPUs, i.e., V100 and A100.", "metadata": {}}, {"text": "The study reveals that 8 V100\nGPUs each with 32 GB of RAM or 4 A100 GPUs each with\n80GB of memory are required for any meaningful inferences\nwith the 65B LLaMA model, thus making small models a\nsuitable choice for energy-efficient applications.", "metadata": {}}, {"text": "Cursaro et al.", "metadata": {}}], "metadata": {"page": 6}}], "metadata": {"page": 6}}, {"title": "Page 7", "paragraphs": [{"text": "[39] conduct a controlled experiment in which code generated\nby CodeLlama is compared with the human one considering\ndifferent languages, i.e., C++, Java, and Python, tested on a\ndedicated platform. The results show that explicitly asking to\ngenerate energy-efficient code results in an equal or worse\nenergy efficiency. In our work, we focus on reducing energy\nconsumption of Llama by customizing the prompt and using\na dedicated GPU.\nPrompt customization: Fagadau et al. [40] explored the\ninfluence of eight prompt features on Copilot’s code outputs,\nanalyzing 124,800 prompts designed to implement 200 Java\nmethods. The findings indicate that prompts including concise\nmethod summaries and examples lead to higher accuracy in\ngenerated code while additional details as boundary cases\nhave a negative impact. Reynolds and McDonell [41] ex-\nplored example-free strategies in prompt engineering, aiming\nto enhance results by refining prompt structure. In particular,\nthey embody analogies and synonyms during task specifica-\ntion and limit undesired outputs with negative prompting. Li\net al. [42] investigate prompt modifications using metamorphic\ntesting. Using Copilot as baseline model, code fragments are\ninjected in the prompts instead of natural language. Then,\nsemantic mutations are introducted to modify the prompts.\nSimilar to our approach, Wang et al. [28] proposes prompt\ntuning, a novel PET executed during the fine-tuning process.\nThis technique involves the soft prompting in which task-\nrelated knowledge are tagged using virtual tokens instead of\nusing fixed annotation, i.e., hard prompting . The empirical\nevaluation conducted on CodeBERT and CodeT5 shows that\nprompt tuning consistently outperforms fine-tuning in three\ncode-related tasks, i.e., defect prediction, code summarization,\nand code translation. Compared to those works, we introduce\nexplanations in prompts to reduce the energy consumption of\nLlama 3 model in code generation task.\nVI. T HREATS TO VALIDITY\nThis section discusses threats that may hamper the results\nof our study and corresponding mitigation strategies.\nInternal validity concerns factors that may impact the\nmeasurements, i.e., noise interference, background processes,\nand voltage fluctuations. To mitigate these issues, all the\nexperiments have been conducted in an isolated Linux-based\nsystem without parallel or background tasks running on the\nGPU. In addition, we repeated each experiment five times and\na 10-second pause between each query execution to prevent\npotential performance degradation and statistical anomalies,\nthus increasing the reliability of measurements.\nThreats to external validity are related to the generalizability\nof the performed experiments, i.e., the obtained results in terms\nof energy consumption and accuracy may vary considering\ndifferent tasks and LLMs. Concerning the data, we employed\nCodeXGLUE, a well-known dataset exploited in several stud-\nies. We were forced to cap our dataset to 1,000 snippets, since\nthe time needed to test one snippet has been evaluated to 900\nseconds. Finally, the measurements calculated on the inference\nwithout any customization are strictly related to the particular\ntask that we decided to study, thus code generation or text\nsummarization might require different energy resources. We\nmitigated this threat focusing on the effects of the customiza-\ntion.\nVII. C ONCLUSION AND FUTURE WORK\nMotivated by the increasing carbon emissions of LLMs, we\nproposed a preliminary investigation on the effects of prompt\ncustomizations on Llama 3 model for the specific task of code\ncompletion. Our results show that augmenting prompts with\ndedicated custom tags and explanations succeed in reducing\nthe energy consumption yet preserving adequate accuracy.\nIn particular, with the best configuration, zero-shot reduced\nthe consumption of about 7%, whereas one-shot and few-\nshots decreased their consumption of about 99% and 83%,\nrespectively. For future work, we plan to extend the study\nto additional LLMs and code-related tasks. In addition, we\nwill investigate advanced techniques, e.g., retrieval augmented\ngeneration (RAG) or fine-tuning, to further reduce the carbon\nemissions of LLMs. Finally, we plan to investigate the effects\nof custom prompts in different software engineering tasks.\nACKNOWLEDGMENTS\nThis work has been partially supported by the EMELIOT\nnational research project, which has been funded by the MUR\nunder the PRIN 2020 program grant n. 2020W3A5FY , the\nEuropean Union–NextGenerationEU through the Italian Min-\nistry of University and Research, Projects PRIN 2022 PNRR\n“FRINGE: context-aware FaiRness engineerING in complex\nsoftware systEms” grant n. P2022553SL, and the Italian\n“PRIN 2022” project “TRex-SE: Trustworthy Recommenders\nfor Software Engineers, ” grant n. 2022LKJWHC.\nREFERENCES\n[1] R. Verdecchia, P. Lago, C. Ebert et al., “Green it and green software,”\nIEEE Software, vol. 38, no. 6, pp. 7–15, 2021.\n[2] S. Georgiou, M. Kechagia, and D. Spinellis, “Analyzing programming\nlanguages’ energy consumption: An empirical study,” in Proceedings of\nthe 21st Pan-Hellenic Conference on Informatics , 2017, pp. 1–6.\n[3] C. Calero and M. Piattini, Eds., Green in Software Engineering .\nCham: Springer International Publishing, 2015. [Online]. Available:\nhttps://link.springer.com/10.1007/978-3-319-08581-4\n[4] A. Guldner, R. Bender, C. Calero et al. , “Development and evaluation\nof a reference measurement model for assessing the resource\nand energy efficiency of software products and components—green\nsoftware measurement model (gsmm),” Future Generation Computer\nSystems, vol. 155, pp. 402–418, 2024. [Online]. Available: https:\n//www.sciencedirect.com/science/article/pii/S0167739X24000384\n[5] PowerAPI, “pyrapl: A python library for measuring energy\nconsumption,” 2023, accessed: 2024-03-05. [Online]. Available:\nhttps://github.com/powerapi-ng/pyRAPL/tree/master\n[6] A. Noureddine, “Powerjoular and joularjx: Multi-platform software\npower monitoring tools,” in 18th International Conference on Intelligent\nEnvironments (IE2022), Biarritz, France, Jun 2022.\n[7] J. Mancebo, C. Calero, F. Garcia et al. , “Feetings: Framework\nfor energy efficiency testing to improve environmental goal of the\nsoftware,” Sustainable Computing: Informatics and Systems , vol. 30,\np. 100558, 2021. [Online]. Available: https://www.sciencedirect.com/\nscience/article/pii/S2210537921000494\n[8] E. Strubell, A. Ganesh, and A. McCallum, “Energy and policy\nconsiderations for modern deep learning research,” Proceedings of\nthe AAAI Conference on Artificial Intelligence , vol. 34, no. 09,\npp. 13 693–13 696, Apr. 2020. [Online]. Available: https://ojs.aaai.org/\nindex.php/AAAI/article/view/7123", "sentences": [{"text": "[39] conduct a controlled experiment in which code generated\nby CodeLlama is compared with the human one considering\ndifferent languages, i.e., C++, Java, and Python, tested on a\ndedicated platform.", "metadata": {}}, {"text": "The results show that explicitly asking to\ngenerate energy-efficient code results in an equal or worse\nenergy efficiency.", "metadata": {}}, {"text": "In our work, we focus on reducing energy\nconsumption of Llama by customizing the prompt and using\na dedicated GPU.", "metadata": {}}, {"text": "Prompt customization: Fagadau et al.", "metadata": {}}, {"text": "[40] explored the\ninfluence of eight prompt features on Copilot’s code outputs,\nanalyzing 124,800 prompts designed to implement 200 Java\nmethods.", "metadata": {}}, {"text": "The findings indicate that prompts including concise\nmethod summaries and examples lead to higher accuracy in\ngenerated code while additional details as boundary cases\nhave a negative impact.", "metadata": {}}, {"text": "Reynolds and McDonell [41] ex-\nplored example-free strategies in prompt engineering, aiming\nto enhance results by refining prompt structure.", "metadata": {}}, {"text": "In particular,\nthey embody analogies and synonyms during task specifica-\ntion and limit undesired outputs with negative prompting.", "metadata": {}}, {"text": "Li\net al.", "metadata": {}}, {"text": "[42] investigate prompt modifications using metamorphic\ntesting.", "metadata": {}}, {"text": "Using Copilot as baseline model, code fragments are\ninjected in the prompts instead of natural language.", "metadata": {}}, {"text": "Then,\nsemantic mutations are introducted to modify the prompts.", "metadata": {}}, {"text": "Similar to our approach, Wang et al.", "metadata": {}}, {"text": "[28] proposes prompt\ntuning, a novel PET executed during the fine-tuning process.", "metadata": {}}, {"text": "This technique involves the soft prompting in which task-\nrelated knowledge are tagged using virtual tokens instead of\nusing fixed annotation, i.e., hard prompting .", "metadata": {}}, {"text": "The empirical\nevaluation conducted on CodeBERT and CodeT5 shows that\nprompt tuning consistently outperforms fine-tuning in three\ncode-related tasks, i.e., defect prediction, code summarization,\nand code translation.", "metadata": {}}, {"text": "Compared to those works, we introduce\nexplanations in prompts to reduce the energy consumption of\nLlama 3 model in code generation task.", "metadata": {}}, {"text": "VI.", "metadata": {}}, {"text": "T HREATS TO VALIDITY\nThis section discusses threats that may hamper the results\nof our study and corresponding mitigation strategies.", "metadata": {}}, {"text": "Internal validity concerns factors that may impact the\nmeasurements, i.e., noise interference, background processes,\nand voltage fluctuations.", "metadata": {}}, {"text": "To mitigate these issues, all the\nexperiments have been conducted in an isolated Linux-based\nsystem without parallel or background tasks running on the\nGPU.", "metadata": {}}, {"text": "In addition, we repeated each experiment five times and\na 10-second pause between each query execution to prevent\npotential performance degradation and statistical anomalies,\nthus increasing the reliability of measurements.", "metadata": {}}, {"text": "Threats to external validity are related to the generalizability\nof the performed experiments, i.e., the obtained results in terms\nof energy consumption and accuracy may vary considering\ndifferent tasks and LLMs.", "metadata": {}}, {"text": "Concerning the data, we employed\nCodeXGLUE, a well-known dataset exploited in several stud-\nies.", "metadata": {}}, {"text": "We were forced to cap our dataset to 1,000 snippets, since\nthe time needed to test one snippet has been evaluated to 900\nseconds.", "metadata": {}}, {"text": "Finally, the measurements calculated on the inference\nwithout any customization are strictly related to the particular\ntask that we decided to study, thus code generation or text\nsummarization might require different energy resources.", "metadata": {}}, {"text": "We\nmitigated this threat focusing on the effects of the customiza-\ntion.", "metadata": {}}, {"text": "VII.", "metadata": {}}, {"text": "C ONCLUSION AND FUTURE WORK\nMotivated by the increasing carbon emissions of LLMs, we\nproposed a preliminary investigation on the effects of prompt\ncustomizations on Llama 3 model for the specific task of code\ncompletion.", "metadata": {}}, {"text": "Our results show that augmenting prompts with\ndedicated custom tags and explanations succeed in reducing\nthe energy consumption yet preserving adequate accuracy.", "metadata": {}}, {"text": "In particular, with the best configuration, zero-shot reduced\nthe consumption of about 7%, whereas one-shot and few-\nshots decreased their consumption of about 99% and 83%,\nrespectively.", "metadata": {}}, {"text": "For future work, we plan to extend the study\nto additional LLMs and code-related tasks.", "metadata": {}}, {"text": "In addition, we\nwill investigate advanced techniques, e.g., retrieval augmented\ngeneration (RAG) or fine-tuning, to further reduce the carbon\nemissions of LLMs.", "metadata": {}}, {"text": "Finally, we plan to investigate the effects\nof custom prompts in different software engineering tasks.", "metadata": {}}, {"text": "ACKNOWLEDGMENTS\nThis work has been partially supported by the EMELIOT\nnational research project, which has been funded by the MUR\nunder the PRIN 2020 program grant n.", "metadata": {}}, {"text": "2020W3A5FY , the\nEuropean Union–NextGenerationEU through the Italian Min-\nistry of University and Research, Projects PRIN 2022 PNRR\n“FRINGE: context-aware FaiRness engineerING in complex\nsoftware systEms” grant n.", "metadata": {}}, {"text": "P2022553SL, and the Italian\n“PRIN 2022” project “TRex-SE: Trustworthy Recommenders\nfor Software Engineers, ” grant n.", "metadata": {}}, {"text": "2022LKJWHC.", "metadata": {}}, {"text": "REFERENCES\n[1] R.", "metadata": {}}, {"text": "Verdecchia, P.", "metadata": {}}, {"text": "Lago, C.", "metadata": {}}, {"text": "Ebert et al., “Green it and green software,”\nIEEE Software, vol.", "metadata": {}}, {"text": "38, no.", "metadata": {}}, {"text": "6, pp.", "metadata": {}}, {"text": "7–15, 2021.", "metadata": {}}, {"text": "[2] S.", "metadata": {}}, {"text": "Georgiou, M.", "metadata": {}}, {"text": "Kechagia, and D.", "metadata": {}}, {"text": "Spinellis, “Analyzing programming\nlanguages’ energy consumption: An empirical study,” in Proceedings of\nthe 21st Pan-Hellenic Conference on Informatics , 2017, pp.", "metadata": {}}, {"text": "1–6.", "metadata": {}}, {"text": "[3] C.", "metadata": {}}, {"text": "Calero and M.", "metadata": {}}, {"text": "Piattini, Eds., Green in Software Engineering .", "metadata": {}}, {"text": "Cham: Springer International Publishing, 2015.", "metadata": {}}, {"text": "[Online].", "metadata": {}}, {"text": "Available:\nhttps://link.springer.com/10.1007/978-3-319-08581-4\n[4] A.", "metadata": {}}, {"text": "Guldner, R.", "metadata": {}}, {"text": "Bender, C.", "metadata": {}}, {"text": "Calero et al.", "metadata": {}}, {"text": ", “Development and evaluation\nof a reference measurement model for assessing the resource\nand energy efficiency of software products and components—green\nsoftware measurement model (gsmm),” Future Generation Computer\nSystems, vol.", "metadata": {}}, {"text": "155, pp.", "metadata": {}}, {"text": "402–418, 2024.", "metadata": {}}, {"text": "[Online].", "metadata": {}}, {"text": "Available: https:\n//www.sciencedirect.com/science/article/pii/S0167739X24000384\n[5] PowerAPI, “pyrapl: A python library for measuring energy\nconsumption,” 2023, accessed: 2024-03-05.", "metadata": {}}, {"text": "[Online].", "metadata": {}}, {"text": "Available:\nhttps://github.com/powerapi-ng/pyRAPL/tree/master\n[6] A.", "metadata": {}}, {"text": "Noureddine, “Powerjoular and joularjx: Multi-platform software\npower monitoring tools,” in 18th International Conference on Intelligent\nEnvironments (IE2022), Biarritz, France, Jun 2022.", "metadata": {}}, {"text": "[7] J.", "metadata": {}}, {"text": "Mancebo, C.", "metadata": {}}, {"text": "Calero, F.", "metadata": {}}, {"text": "Garcia et al.", "metadata": {}}, {"text": ", “Feetings: Framework\nfor energy efficiency testing to improve environmental goal of the\nsoftware,” Sustainable Computing: Informatics and Systems , vol.", "metadata": {}}, {"text": "30,\np.", "metadata": {}}, {"text": "100558, 2021.", "metadata": {}}, {"text": "[Online].", "metadata": {}}, {"text": "Available: https://www.sciencedirect.com/\nscience/article/pii/S2210537921000494\n[8] E.", "metadata": {}}, {"text": "Strubell, A.", "metadata": {}}, {"text": "Ganesh, and A.", "metadata": {}}, {"text": "McCallum, “Energy and policy\nconsiderations for modern deep learning research,” Proceedings of\nthe AAAI Conference on Artificial Intelligence , vol.", "metadata": {}}, {"text": "34, no.", "metadata": {}}, {"text": "09,\npp.", "metadata": {}}, {"text": "13 693–13 696, Apr.", "metadata": {}}, {"text": "2020.", "metadata": {}}, {"text": "[Online].", "metadata": {}}, {"text": "Available: https://ojs.aaai.org/\nindex.php/AAAI/article/view/7123", "metadata": {}}], "metadata": {"page": 7}}], "metadata": {"page": 7}}, {"title": "Page 8", "paragraphs": [{"text": "[9] R. Tufano, S. Masiero, A. Mastropaolo et al. , “Using pre-trained\nmodels to boost code review automation,” in Proceedings of\nthe 44th International Conference on Software Engineering , ser.\nICSE ’22. New York, NY , USA: Association for Computing\nMachinery, Jul. 2022, pp. 2291–2302. [Online]. Available: https:\n//dl.acm.org/doi/10.1145/3510003.3510621\n[10] A. Mastropaolo, S. Scalabrino, N. Cooper et al. , “Studying the\nUsage of Text-To-Text Transfer Transformer to Support Code-Related\nTasks,” in 2021 IEEE/ACM 43rd International Conference on Software\nEngineering (ICSE) . Madrid, ES: IEEE, May 2021, pp. 336–347.\n[Online]. Available: https://ieeexplore.ieee.org/document/9401982/\n[11] D. Wang, Z. Jia, S. Li et al. , “Bridging pre-trained models and\ndownstream tasks for source code understanding,” in Proceedings\nof the 44th International Conference on Software Engineering , ser.\nICSE ’22. New York, NY , USA: Association for Computing\nMachinery, Jul. 2022, pp. 287–298. [Online]. Available: https:\n//dl.acm.org/doi/10.1145/3510003.3510062\n[12] J. Casta ˜no, S. Mart ´ınez-Fern´andez, X. Franch et al. , “Exploring\nthe Carbon Footprint of Hugging Face’s ML Models: A Repository\nMining Study,” in 2023 ACM/IEEE International Symposium on\nEmpirical Software Engineering and Measurement (ESEM) , Oct.\n2023, pp. 1–12, arXiv:2305.11164 [cs, stat]. [Online]. Available:\nhttp://arxiv.org/abs/2305.11164\n[13] S. Samsi, D. Zhao, J. McDonald, B. Li, A. Michaleas, M. Jones,\nW. Bergeron, J. Kepner, D. Tiwari, and V . Gadepally, “From words\nto watts: Benchmarking the energy costs of large language model\ninference,” in IEEE High Performance Extreme Computing Conference,\nHPEC 2023, Boston, MA, USA, September 25-29, 2023 . IEEE, 2023,\npp. 1–9. [Online]. Available: https://doi.org/10.1109/HPEC58863.2023.\n10363447\n[14] S. Lu, D. Guo, S. Ren, J. Huang, A. Svyatkovskiy, A. Blanco,\nC. Clement, D. Drain, D. Jiang, D. Tang et al., “Codexglue: A machine\nlearning benchmark dataset for code understanding and generation,”\nin Thirty-fifth Conference on Neural Information Processing Systems\nDatasets and Benchmarks Track (Round 1) .\n[15] A. Dubey, A. Jauhri, A. Pandey et al. , “The llama 3 herd of models,”\n2024. [Online]. Available: https://arxiv.org/abs/2407.21783\n[16] M. C. Impact, “Codecarbon: A tool to estimate the carbon emissions\nof machine learning models,” 2024, accessed: 2024-03-05. [Online].\nAvailable: https://mlco2.github.io/codecarbon/\n[17] R. A. Husein, H. Aburajouh, and C. Catal, “Large language\nmodels for code completion: A systematic literature review,” Comput.\nStand. Interfaces , vol. 92, p. 103917, 2025. [Online]. Available:\nhttps://doi.org/10.1016/j.csi.2024.103917\n[18] S. T. Footprint, “Carbon footprint of training gpt-\n3 and large language models,” 2023, accessed:\n2024-07-22. [Online]. Available: https://shrinkthatfootprint.com/\ncarbon-footprint-of-training-gpt-3-and-large-language-models/\n[19] Trustbit, “Llm benchmarks,” 2024, accessed: 2024-07-22. [Online].\nAvailable: https://www.trustbit.tech/en/llm-benchmarks\n[20] L. Arena, “Lm arena leaderboard,” 2024, accessed: 2024-07-22.\n[Online]. Available: https://lmarena.ai/?leaderboard\n[21] Oobabooga, “Oobabooga benchmark,” 2024, accessed: 2024-07-22.\n[Online]. Available: https://oobabooga.github.io/benchmark.html\n[22] E. Strubell, A. Ganesh, and A. McCallum, “Energy and policy\nconsiderations for deep learning in nlp,” 2019. [Online]. Available:\nhttps://arxiv.org/abs/1906.02243\n[23] B. Romera-Paredes and P. H. S. Torr, “An embarrassingly simple\napproach to zero-shot learning,” inProceedings of the 32nd International\nConference on International Conference on Machine Learning - Volume\n37, ser. ICML’15. JMLR.org, 2015, p. 2152–2161.\n[24] R. L. L. I. au2, I. Bala ˇzevi´c, E. Wallace, F. Petroni, S. Singh,\nand S. Riedel, “Cutting down on prompts and parameters: Simple\nfew-shot learning with language models,” 2021. [Online]. Available:\nhttps://arxiv.org/abs/2106.13353\n[25] X. Li, S. Yuan, X. Gu et al. , “Few-shot code translation via\ntask-adapted prompt learning,” Journal of Systems and Software , vol.\n212, p. 112002, 2024. [Online]. Available: https://www.sciencedirect.\ncom/science/article/pii/S0164121224000451\n[26] A. Gholami, S. Kim, Z. Dong, Z. Yao, M. W. Mahoney, and K. Keutzer,\n“A survey of quantization methods for efficient neural network\ninference,” 2021. [Online]. Available: https://arxiv.org/abs/2103.13630\n[27] A. Faiz, S. Kaneda, R. Wang, R. Osi, P. Sharma, F. Chen, and L. Jiang,\n“Llmcarbon: Modeling the end-to-end carbon footprint of large language\nmodels,” arXiv preprint arXiv:2309.14393 , 2023.\n[28] C. Wang, Y . Yang, C. Gao, Y . Peng, H. Zhang, and M. R. Lyu,\n“No more fine-tuning? an experimental evaluation of prompt tuning in\ncode intelligence,” in Proceedings of the 30th ACM Joint European\nSoftware Engineering Conference and Symposium on the Foundations\nof Software Engineering , ser. ESEC/FSE 2022. New York, NY , USA:\nAssociation for Computing Machinery, 2022, p. 382–394. [Online].\nAvailable: https://doi.org/10.1145/3540250.3549113\n[29] X. Hou, Y . Zhao, Y . Liu, Z. Yang, K. Wang, L. Li, X. Luo,\nD. Lo, J. Grundy, and H. Wang, “Large language models for\nsoftware engineering: A systematic literature review,” ACM Trans.\nSoftw. Eng. Methodol. , Sep. 2024, just Accepted. [Online]. Available:\nhttps://doi.org/10.1145/3695988\n[30] C. Di Sipio, R. Rubei, J. Di Rocco, D. Di Ruscio, and P. T.\nNguyen, “Automated categorization of pre-trained models in software\nengineering: A case study with a hugging face dataset,” in Proceedings\nof the 28th International Conference on Evaluation and Assessment\nin Software Engineering , ser. EASE ’24. New York, NY , USA:\nAssociation for Computing Machinery, 2024, p. 351–356. [Online].\nAvailable: https://doi.org/10.1145/3661167.3661215\n[31] T. Ahmed and P. Devanbu, “Few-shot training llms for project-\nspecific code-summarization,” in Proceedings of the 37th IEEE/ACM\nInternational Conference on Automated Software Engineering , ser. ASE\n’22. New York, NY , USA: Association for Computing Machinery,\n2023. [Online]. Available: https://doi.org/10.1145/3551349.3559555\n[32] G. Navarro, “A guided tour to approximate string matching,” ACM\nComputing Surveys, vol. 33, no. 1, pp. 31–88, 2001.\n[33] S. Georgiou, M. Kechagia, T. Sharma, F. Sarro, and Y . Zou, “Green\nai: Do deep learning frameworks have different costs?” in Proceedings\nof the 44th International Conference on Software Engineering ,\nser. ICSE ’22, Springer. New York, NY , USA: Association for\nComputing Machinery, 2022, p. 1082–1094. [Online]. Available:\nhttps://doi.org/10.1145/3510003.3510221\n[34] S. Shanbhag and S. Chimalakonda, “An exploratory study on energy\nconsumption of dataframe processing libraries,” in 2023 IEEE/ACM\n20th International Conference on Mining Software Repositories (MSR) .\nSpringer, 2023, pp. 284–295.\n[35] J. Bornholt, T. Mytkowicz, and K. S. McKinley, “The model is not\nenough: Understanding energy consumption in mobile devices,” in 2012\nIEEE Hot Chips 24 Symposium (HCS) . IEEE, 2012, pp. 1–3.\n[36] A. Jagannadharao, N. Beckage, D. Nafus, and S. Chamberlin,\n“Timeshifting strategies for carbon-efficient long-running large language\nmodel training,” Innovations in Systems and Software Engineering, Dec.\n2023. [Online]. Available: https://doi.org/10.1007/s11334-023-00546-x\n[37] V . Liu and Y . Yin, “Green AI: exploring carbon footprints, mitigation\nstrategies, and trade offs in large language model training,” Discover\nArtificial Intelligence, vol. 4, no. 1, p. 49, Jul. 2024. [Online]. Available:\nhttps://doi.org/10.1007/s44163-024-00149-w\n[38] P. Rajpurkar, J. Zhang, K. Lopyrev et al., “Squad: 100,000+ questions\nfor machine comprehension of text,” arXiv preprint arXiv:1606.05250 ,\n2016.\n[39] V .-A. Cursaru, L. Duits, J. Milligan, D. Ural, B. R. Sanchez, V . Stoico,\nand I. Malavolta, “A controlled experiment on the energy efficiency\nof the source code generated by code llama,” in Quality of Information\nand Communications Technology, A. Bertolino, J. Pascoal Faria, P. Lago,\nand L. Semini, Eds. Cham: Springer Nature Switzerland, 2024, pp.\n161–176.\n[40] I. D. Fagadau, L. Mariani, D. Micucci, and O. Riganelli, “Analyzing\nprompt influence on automated method generation: An empirical study\nwith copilot,” in Proceedings of the 32nd IEEE/ACM International\nConference on Program Comprehension , ser. ICPC ’24. New York,\nNY , USA: Association for Computing Machinery, 2024, p. 24–34.\n[Online]. Available: https://doi.org/10.1145/3643916.3644409\n[41] L. Reynolds and K. McDonell, “Prompt programming for large\nlanguage models: Beyond the few-shot paradigm,” in Extended\nAbstracts of the 2021 CHI Conference on Human Factors in\nComputing Systems , ser. CHI EA ’21. New York, NY , USA:\nAssociation for Computing Machinery, 2021. [Online]. Available:\nhttps://doi.org/10.1145/3411763.3451760\n[42] Z. Li, C. Wang, Z. Liu, H. Wang, D. Chen, S. Wang, and C. Gao,\n“Cctest: Testing and repairing code completion systems,” 2023.\n[Online]. Available: https://arxiv.org/abs/2208.08289", "sentences": [{"text": "[9] R.", "metadata": {}}, {"text": "Tufano, S.", "metadata": {}}, {"text": "Masiero, A.", "metadata": {}}, {"text": "Mastropaolo et al.", "metadata": {}}, {"text": ", “Using pre-trained\nmodels to boost code review automation,” in Proceedings of\nthe 44th International Conference on Software Engineering , ser.", "metadata": {}}, {"text": "ICSE ’22.", "metadata": {}}, {"text": "New York, NY , USA: Association for Computing\nMachinery, Jul.", "metadata": {}}, {"text": "2022, pp.", "metadata": {}}, {"text": "2291–2302.", "metadata": {}}, {"text": "[Online].", "metadata": {}}, {"text": "Available: https:\n//dl.acm.org/doi/10.1145/3510003.3510621\n[10] A.", "metadata": {}}, {"text": "Mastropaolo, S.", "metadata": {}}, {"text": "Scalabrino, N.", "metadata": {}}, {"text": "Cooper et al.", "metadata": {}}, {"text": ", “Studying the\nUsage of Text-To-Text Transfer Transformer to Support Code-Related\nTasks,” in 2021 IEEE/ACM 43rd International Conference on Software\nEngineering (ICSE) .", "metadata": {}}, {"text": "Madrid, ES: IEEE, May 2021, pp.", "metadata": {}}, {"text": "336–347.", "metadata": {}}, {"text": "[Online].", "metadata": {}}, {"text": "Available: https://ieeexplore.ieee.org/document/9401982/\n[11] D.", "metadata": {}}, {"text": "Wang, Z.", "metadata": {}}, {"text": "Jia, S.", "metadata": {}}, {"text": "Li et al.", "metadata": {}}, {"text": ", “Bridging pre-trained models and\ndownstream tasks for source code understanding,” in Proceedings\nof the 44th International Conference on Software Engineering , ser.", "metadata": {}}, {"text": "ICSE ’22.", "metadata": {}}, {"text": "New York, NY , USA: Association for Computing\nMachinery, Jul.", "metadata": {}}, {"text": "2022, pp.", "metadata": {}}, {"text": "287–298.", "metadata": {}}, {"text": "[Online].", "metadata": {}}, {"text": "Available: https:\n//dl.acm.org/doi/10.1145/3510003.3510062\n[12] J.", "metadata": {}}, {"text": "Casta ˜no, S.", "metadata": {}}, {"text": "Mart ´ınez-Fern´andez, X.", "metadata": {}}, {"text": "Franch et al.", "metadata": {}}, {"text": ", “Exploring\nthe Carbon Footprint of Hugging Face’s ML Models: A Repository\nMining Study,” in 2023 ACM/IEEE International Symposium on\nEmpirical Software Engineering and Measurement (ESEM) , Oct.", "metadata": {}}, {"text": "2023, pp.", "metadata": {}}, {"text": "1–12, arXiv:2305.11164 [cs, stat].", "metadata": {}}, {"text": "[Online].", "metadata": {}}, {"text": "Available:\nhttp://arxiv.org/abs/2305.11164\n[13] S.", "metadata": {}}, {"text": "Samsi, D.", "metadata": {}}, {"text": "Zhao, J.", "metadata": {}}, {"text": "McDonald, B.", "metadata": {}}, {"text": "Li, A.", "metadata": {}}, {"text": "Michaleas, M.", "metadata": {}}, {"text": "Jones,\nW.", "metadata": {}}, {"text": "Bergeron, J.", "metadata": {}}, {"text": "Kepner, D.", "metadata": {}}, {"text": "Tiwari, and V .", "metadata": {}}, {"text": "Gadepally, “From words\nto watts: Benchmarking the energy costs of large language model\ninference,” in IEEE High Performance Extreme Computing Conference,\nHPEC 2023, Boston, MA, USA, September 25-29, 2023 .", "metadata": {}}, {"text": "IEEE, 2023,\npp.", "metadata": {}}, {"text": "1–9.", "metadata": {}}, {"text": "[Online].", "metadata": {}}, {"text": "Available: https://doi.org/10.1109/HPEC58863.2023.", "metadata": {}}, {"text": "10363447\n[14] S.", "metadata": {}}, {"text": "Lu, D.", "metadata": {}}, {"text": "Guo, S.", "metadata": {}}, {"text": "Ren, J.", "metadata": {}}, {"text": "Huang, A.", "metadata": {}}, {"text": "Svyatkovskiy, A.", "metadata": {}}, {"text": "Blanco,\nC.", "metadata": {}}, {"text": "Clement, D.", "metadata": {}}, {"text": "Drain, D.", "metadata": {}}, {"text": "Jiang, D.", "metadata": {}}, {"text": "Tang et al., “Codexglue: A machine\nlearning benchmark dataset for code understanding and generation,”\nin Thirty-fifth Conference on Neural Information Processing Systems\nDatasets and Benchmarks Track (Round 1) .", "metadata": {}}, {"text": "[15] A.", "metadata": {}}, {"text": "Dubey, A.", "metadata": {}}, {"text": "Jauhri, A.", "metadata": {}}, {"text": "Pandey et al.", "metadata": {}}, {"text": ", “The llama 3 herd of models,”\n2024.", "metadata": {}}, {"text": "[Online].", "metadata": {}}, {"text": "Available: https://arxiv.org/abs/2407.21783\n[16] M.", "metadata": {}}, {"text": "C.", "metadata": {}}, {"text": "Impact, “Codecarbon: A tool to estimate the carbon emissions\nof machine learning models,” 2024, accessed: 2024-03-05.", "metadata": {}}, {"text": "[Online].", "metadata": {}}, {"text": "Available: https://mlco2.github.io/codecarbon/\n[17] R.", "metadata": {}}, {"text": "A.", "metadata": {}}, {"text": "Husein, H.", "metadata": {}}, {"text": "Aburajouh, and C.", "metadata": {}}, {"text": "Catal, “Large language\nmodels for code completion: A systematic literature review,” Comput.", "metadata": {}}, {"text": "Stand.", "metadata": {}}, {"text": "Interfaces , vol.", "metadata": {}}, {"text": "92, p.", "metadata": {}}, {"text": "103917, 2025.", "metadata": {}}, {"text": "[Online].", "metadata": {}}, {"text": "Available:\nhttps://doi.org/10.1016/j.csi.2024.103917\n[18] S.", "metadata": {}}, {"text": "T.", "metadata": {}}, {"text": "Footprint, “Carbon footprint of training gpt-\n3 and large language models,” 2023, accessed:\n2024-07-22.", "metadata": {}}, {"text": "[Online].", "metadata": {}}, {"text": "Available: https://shrinkthatfootprint.com/\ncarbon-footprint-of-training-gpt-3-and-large-language-models/\n[19] Trustbit, “Llm benchmarks,” 2024, accessed: 2024-07-22.", "metadata": {}}, {"text": "[Online].", "metadata": {}}, {"text": "Available: https://www.trustbit.tech/en/llm-benchmarks\n[20] L.", "metadata": {}}, {"text": "Arena, “Lm arena leaderboard,” 2024, accessed: 2024-07-22.", "metadata": {}}, {"text": "[Online].", "metadata": {}}, {"text": "Available: https://lmarena.ai/?leaderboard\n[21] Oobabooga, “Oobabooga benchmark,” 2024, accessed: 2024-07-22.", "metadata": {}}, {"text": "[Online].", "metadata": {}}, {"text": "Available: https://oobabooga.github.io/benchmark.html\n[22] E.", "metadata": {}}, {"text": "Strubell, A.", "metadata": {}}, {"text": "Ganesh, and A.", "metadata": {}}, {"text": "McCallum, “Energy and policy\nconsiderations for deep learning in nlp,” 2019.", "metadata": {}}, {"text": "[Online].", "metadata": {}}, {"text": "Available:\nhttps://arxiv.org/abs/1906.02243\n[23] B.", "metadata": {}}, {"text": "Romera-Paredes and P.", "metadata": {}}, {"text": "H.", "metadata": {}}, {"text": "S.", "metadata": {}}, {"text": "Torr, “An embarrassingly simple\napproach to zero-shot learning,” inProceedings of the 32nd International\nConference on International Conference on Machine Learning - Volume\n37, ser.", "metadata": {}}, {"text": "ICML’15.", "metadata": {}}, {"text": "JMLR.org, 2015, p.", "metadata": {}}, {"text": "2152–2161.", "metadata": {}}, {"text": "[24] R.", "metadata": {}}, {"text": "L.", "metadata": {}}, {"text": "L.", "metadata": {}}, {"text": "I.", "metadata": {}}, {"text": "au2, I.", "metadata": {}}, {"text": "Bala ˇzevi´c, E.", "metadata": {}}, {"text": "Wallace, F.", "metadata": {}}, {"text": "Petroni, S.", "metadata": {}}, {"text": "Singh,\nand S.", "metadata": {}}, {"text": "Riedel, “Cutting down on prompts and parameters: Simple\nfew-shot learning with language models,” 2021.", "metadata": {}}, {"text": "[Online].", "metadata": {}}, {"text": "Available:\nhttps://arxiv.org/abs/2106.13353\n[25] X.", "metadata": {}}, {"text": "Li, S.", "metadata": {}}, {"text": "Yuan, X.", "metadata": {}}, {"text": "Gu et al.", "metadata": {}}, {"text": ", “Few-shot code translation via\ntask-adapted prompt learning,” Journal of Systems and Software , vol.", "metadata": {}}, {"text": "212, p.", "metadata": {}}, {"text": "112002, 2024.", "metadata": {}}, {"text": "[Online].", "metadata": {}}, {"text": "Available: https://www.sciencedirect.", "metadata": {}}, {"text": "com/science/article/pii/S0164121224000451\n[26] A.", "metadata": {}}, {"text": "Gholami, S.", "metadata": {}}, {"text": "Kim, Z.", "metadata": {}}, {"text": "Dong, Z.", "metadata": {}}, {"text": "Yao, M.", "metadata": {}}, {"text": "W.", "metadata": {}}, {"text": "Mahoney, and K.", "metadata": {}}, {"text": "Keutzer,\n“A survey of quantization methods for efficient neural network\ninference,” 2021.", "metadata": {}}, {"text": "[Online].", "metadata": {}}, {"text": "Available: https://arxiv.org/abs/2103.13630\n[27] A.", "metadata": {}}, {"text": "Faiz, S.", "metadata": {}}, {"text": "Kaneda, R.", "metadata": {}}, {"text": "Wang, R.", "metadata": {}}, {"text": "Osi, P.", "metadata": {}}, {"text": "Sharma, F.", "metadata": {}}, {"text": "Chen, and L.", "metadata": {}}, {"text": "Jiang,\n“Llmcarbon: Modeling the end-to-end carbon footprint of large language\nmodels,” arXiv preprint arXiv:2309.14393 , 2023.", "metadata": {}}, {"text": "[28] C.", "metadata": {}}, {"text": "Wang, Y .", "metadata": {}}, {"text": "Yang, C.", "metadata": {}}, {"text": "Gao, Y .", "metadata": {}}, {"text": "Peng, H.", "metadata": {}}, {"text": "Zhang, and M.", "metadata": {}}, {"text": "R.", "metadata": {}}, {"text": "Lyu,\n“No more fine-tuning?", "metadata": {}}, {"text": "an experimental evaluation of prompt tuning in\ncode intelligence,” in Proceedings of the 30th ACM Joint European\nSoftware Engineering Conference and Symposium on the Foundations\nof Software Engineering , ser.", "metadata": {}}, {"text": "ESEC/FSE 2022.", "metadata": {}}, {"text": "New York, NY , USA:\nAssociation for Computing Machinery, 2022, p.", "metadata": {}}, {"text": "382–394.", "metadata": {}}, {"text": "[Online].", "metadata": {}}, {"text": "Available: https://doi.org/10.1145/3540250.3549113\n[29] X.", "metadata": {}}, {"text": "Hou, Y .", "metadata": {}}, {"text": "Zhao, Y .", "metadata": {}}, {"text": "Liu, Z.", "metadata": {}}, {"text": "Yang, K.", "metadata": {}}, {"text": "Wang, L.", "metadata": {}}, {"text": "Li, X.", "metadata": {}}, {"text": "Luo,\nD.", "metadata": {}}, {"text": "Lo, J.", "metadata": {}}, {"text": "Grundy, and H.", "metadata": {}}, {"text": "Wang, “Large language models for\nsoftware engineering: A systematic literature review,” ACM Trans.", "metadata": {}}, {"text": "Softw.", "metadata": {}}, {"text": "Eng.", "metadata": {}}, {"text": "Methodol.", "metadata": {}}, {"text": ", Sep.", "metadata": {}}, {"text": "2024, just Accepted.", "metadata": {}}, {"text": "[Online].", "metadata": {}}, {"text": "Available:\nhttps://doi.org/10.1145/3695988\n[30] C.", "metadata": {}}, {"text": "Di Sipio, R.", "metadata": {}}, {"text": "Rubei, J.", "metadata": {}}, {"text": "Di Rocco, D.", "metadata": {}}, {"text": "Di Ruscio, and P.", "metadata": {}}, {"text": "T.", "metadata": {}}, {"text": "Nguyen, “Automated categorization of pre-trained models in software\nengineering: A case study with a hugging face dataset,” in Proceedings\nof the 28th International Conference on Evaluation and Assessment\nin Software Engineering , ser.", "metadata": {}}, {"text": "EASE ’24.", "metadata": {}}, {"text": "New York, NY , USA:\nAssociation for Computing Machinery, 2024, p.", "metadata": {}}, {"text": "351–356.", "metadata": {}}, {"text": "[Online].", "metadata": {}}, {"text": "Available: https://doi.org/10.1145/3661167.3661215\n[31] T.", "metadata": {}}, {"text": "Ahmed and P.", "metadata": {}}, {"text": "Devanbu, “Few-shot training llms for project-\nspecific code-summarization,” in Proceedings of the 37th IEEE/ACM\nInternational Conference on Automated Software Engineering , ser.", "metadata": {}}, {"text": "ASE\n’22.", "metadata": {}}, {"text": "New York, NY , USA: Association for Computing Machinery,\n2023.", "metadata": {}}, {"text": "[Online].", "metadata": {}}, {"text": "Available: https://doi.org/10.1145/3551349.3559555\n[32] G.", "metadata": {}}, {"text": "Navarro, “A guided tour to approximate string matching,” ACM\nComputing Surveys, vol.", "metadata": {}}, {"text": "33, no.", "metadata": {}}, {"text": "1, pp.", "metadata": {}}, {"text": "31–88, 2001.", "metadata": {}}, {"text": "[33] S.", "metadata": {}}, {"text": "Georgiou, M.", "metadata": {}}, {"text": "Kechagia, T.", "metadata": {}}, {"text": "Sharma, F.", "metadata": {}}, {"text": "Sarro, and Y .", "metadata": {}}, {"text": "Zou, “Green\nai: Do deep learning frameworks have different costs?” in Proceedings\nof the 44th International Conference on Software Engineering ,\nser.", "metadata": {}}, {"text": "ICSE ’22, Springer.", "metadata": {}}, {"text": "New York, NY , USA: Association for\nComputing Machinery, 2022, p.", "metadata": {}}, {"text": "1082–1094.", "metadata": {}}, {"text": "[Online].", "metadata": {}}, {"text": "Available:\nhttps://doi.org/10.1145/3510003.3510221\n[34] S.", "metadata": {}}, {"text": "Shanbhag and S.", "metadata": {}}, {"text": "Chimalakonda, “An exploratory study on energy\nconsumption of dataframe processing libraries,” in 2023 IEEE/ACM\n20th International Conference on Mining Software Repositories (MSR) .", "metadata": {}}, {"text": "Springer, 2023, pp.", "metadata": {}}, {"text": "284–295.", "metadata": {}}, {"text": "[35] J.", "metadata": {}}, {"text": "Bornholt, T.", "metadata": {}}, {"text": "Mytkowicz, and K.", "metadata": {}}, {"text": "S.", "metadata": {}}, {"text": "McKinley, “The model is not\nenough: Understanding energy consumption in mobile devices,” in 2012\nIEEE Hot Chips 24 Symposium (HCS) .", "metadata": {}}, {"text": "IEEE, 2012, pp.", "metadata": {}}, {"text": "1–3.", "metadata": {}}, {"text": "[36] A.", "metadata": {}}, {"text": "Jagannadharao, N.", "metadata": {}}, {"text": "Beckage, D.", "metadata": {}}, {"text": "Nafus, and S.", "metadata": {}}, {"text": "Chamberlin,\n“Timeshifting strategies for carbon-efficient long-running large language\nmodel training,” Innovations in Systems and Software Engineering, Dec.", "metadata": {}}, {"text": "2023.", "metadata": {}}, {"text": "[Online].", "metadata": {}}, {"text": "Available: https://doi.org/10.1007/s11334-023-00546-x\n[37] V .", "metadata": {}}, {"text": "Liu and Y .", "metadata": {}}, {"text": "Yin, “Green AI: exploring carbon footprints, mitigation\nstrategies, and trade offs in large language model training,” Discover\nArtificial Intelligence, vol.", "metadata": {}}, {"text": "4, no.", "metadata": {}}, {"text": "1, p.", "metadata": {}}, {"text": "49, Jul.", "metadata": {}}, {"text": "2024.", "metadata": {}}, {"text": "[Online].", "metadata": {}}, {"text": "Available:\nhttps://doi.org/10.1007/s44163-024-00149-w\n[38] P.", "metadata": {}}, {"text": "Rajpurkar, J.", "metadata": {}}, {"text": "Zhang, K.", "metadata": {}}, {"text": "Lopyrev et al., “Squad: 100,000+ questions\nfor machine comprehension of text,” arXiv preprint arXiv:1606.05250 ,\n2016.", "metadata": {}}, {"text": "[39] V .-A.", "metadata": {}}, {"text": "Cursaru, L.", "metadata": {}}, {"text": "Duits, J.", "metadata": {}}, {"text": "Milligan, D.", "metadata": {}}, {"text": "Ural, B.", "metadata": {}}, {"text": "R.", "metadata": {}}, {"text": "Sanchez, V .", "metadata": {}}, {"text": "Stoico,\nand I.", "metadata": {}}, {"text": "Malavolta, “A controlled experiment on the energy efficiency\nof the source code generated by code llama,” in Quality of Information\nand Communications Technology, A.", "metadata": {}}, {"text": "Bertolino, J.", "metadata": {}}, {"text": "Pascoal Faria, P.", "metadata": {}}, {"text": "Lago,\nand L.", "metadata": {}}, {"text": "Semini, Eds.", "metadata": {}}, {"text": "Cham: Springer Nature Switzerland, 2024, pp.", "metadata": {}}, {"text": "161–176.", "metadata": {}}, {"text": "[40] I.", "metadata": {}}, {"text": "D.", "metadata": {}}, {"text": "Fagadau, L.", "metadata": {}}, {"text": "Mariani, D.", "metadata": {}}, {"text": "Micucci, and O.", "metadata": {}}, {"text": "Riganelli, “Analyzing\nprompt influence on automated method generation: An empirical study\nwith copilot,” in Proceedings of the 32nd IEEE/ACM International\nConference on Program Comprehension , ser.", "metadata": {}}, {"text": "ICPC ’24.", "metadata": {}}, {"text": "New York,\nNY , USA: Association for Computing Machinery, 2024, p.", "metadata": {}}, {"text": "24–34.", "metadata": {}}, {"text": "[Online].", "metadata": {}}, {"text": "Available: https://doi.org/10.1145/3643916.3644409\n[41] L.", "metadata": {}}, {"text": "Reynolds and K.", "metadata": {}}, {"text": "McDonell, “Prompt programming for large\nlanguage models: Beyond the few-shot paradigm,” in Extended\nAbstracts of the 2021 CHI Conference on Human Factors in\nComputing Systems , ser.", "metadata": {}}, {"text": "CHI EA ’21.", "metadata": {}}, {"text": "New York, NY , USA:\nAssociation for Computing Machinery, 2021.", "metadata": {}}, {"text": "[Online].", "metadata": {}}, {"text": "Available:\nhttps://doi.org/10.1145/3411763.3451760\n[42] Z.", "metadata": {}}, {"text": "Li, C.", "metadata": {}}, {"text": "Wang, Z.", "metadata": {}}, {"text": "Liu, H.", "metadata": {}}, {"text": "Wang, D.", "metadata": {}}, {"text": "Chen, S.", "metadata": {}}, {"text": "Wang, and C.", "metadata": {}}, {"text": "Gao,\n“Cctest: Testing and repairing code completion systems,” 2023.", "metadata": {}}, {"text": "[Online].", "metadata": {}}, {"text": "Available: https://arxiv.org/abs/2208.08289", "metadata": {}}], "metadata": {"page": 8}}], "metadata": {"page": 8}}]}