# Sample environment variables for KohakuRAG_UI
# Copy this file to .env and fill in your values

# =============================================================================
# AWS Configuration (for Bedrock branch)
# =============================================================================

# Option 1: Use AWS SSO profile (recommended)
# After running `aws configure sso`, set your profile name here
AWS_PROFILE=your-sso-profile-name

# Option 2: Direct credentials (not recommended for shared environments)
# AWS_ACCESS_KEY_ID=your-access-key
# AWS_SECRET_ACCESS_KEY=your-secret-key
# AWS_SESSION_TOKEN=your-session-token

# AWS Region (Bedrock endpoint)
AWS_REGION=us-east-2

# Bedrock Model ID
# Options:
#   - anthropic.claude-3-haiku-20240307-v1:0 (fast, cheap)
#   - anthropic.claude-3-sonnet-20240229-v1:0 (balanced)
#   - anthropic.claude-3-5-sonnet-20241022-v2:0 (best quality)
BEDROCK_MODEL_ID=anthropic.claude-3-sonnet-20240229-v1:0

# =============================================================================
# OpenRouter Configuration (for local development fallback)
# =============================================================================

# OPENROUTER_API_KEY=your-openrouter-key

# =============================================================================
# Jina Embeddings
# =============================================================================

JINA_API_KEY=your-jina-key

# =============================================================================
# HuggingFace Local Settings (for fully local inference)
# =============================================================================

# HuggingFace local LLM model
# HF_MODEL_ID=Qwen/Qwen2.5-7B-Instruct
# HF_DTYPE=bf16

# Local embedding model (sentence-transformers)
# EMBED_MODEL_ID=BAAI/bge-base-en-v1.5

# Cache locations (optional)
# HF_HOME=/path/to/cache
# TRANSFORMERS_CACHE=/path/to/cache

# =============================================================================
# Application Settings
# =============================================================================

# LLM Provider: "bedrock", "openrouter", "openai", or "hf_local"
LLM_PROVIDER=bedrock

# Streamlit settings
# STREAMLIT_SERVER_PORT=8501
